
================================================================================
BLUQ: Benchmarking Language models via Uncertainty Quantification
================================================================================
Mode: long (10000 samples per task)
Models: 1 | Tasks: 5 | Dtypes: 1
Total configurations: 5
Log file: outputs/results/logs/benchmark_20251207_234559.log
================================================================================

23:45:59 - INFO - Starting benchmark run
23:45:59 - INFO - Log file: outputs/results/logs/benchmark_20251207_234559.log
23:45:59 - INFO - Mode: long, Samples: 10000
23:45:59 - INFO - Models: ['stablelm-2-1.6b']
23:45:59 - INFO - Tasks: ['qa', 'rc', 'ci', 'drs', 'ds']
23:45:59 - INFO - Dtypes: ['float16']
23:46:01 - INFO - Running on: Device: NVIDIA A100 80GB PCIe (cuda)
  Total Memory: 79.25 GB
  Available Memory: 79.25 GB
23:46:01 - INFO - Detected A100 GPU: NVIDIA A100 80GB PCIe - using optimized A100 settings
23:46:01 - INFO - GPU Tier: a100 | Auto max_batch_size: 192 | Safety margin: 0.93
23:46:01 - INFO - Using user-specified max_batch_size: 32
23:46:01 - INFO - NVML initialized for GPU utilization monitoring
23:46:01 - INFO - GPUProfiler initialized (CUDA: True, NVML: True)
23:46:01 - INFO - Started GPU monitoring
23:46:01 - INFO - GPU profiling enabled
23:46:01 - INFO - 
================================================================================
23:46:01 - INFO - FULL BENCHMARK CONFIGURATION
23:46:01 - INFO - ================================================================================
23:46:01 - INFO - Models (1): ['stablelm-2-1.6b']
23:46:01 - INFO - Tasks (5): ['qa', 'rc', 'ci', 'drs', 'ds']
23:46:01 - INFO - Data types: ['float16']
23:46:01 - INFO - Samples per task: 10000
23:46:01 - INFO - Alpha (error rate): 0.1
23:46:01 - INFO - Strategies: ['base']
23:46:01 - INFO - Conformal methods: ['lac', 'aps']
23:46:01 - INFO - Dynamic batch sizing: False
23:46:01 - INFO - Max batch size: 32 (GPU tier: a100)
23:46:01 - INFO - Output directory: outputs/results
23:46:01 - INFO - 
================================================================================
23:46:01 - INFO - Run 1/5: stablelm-2-1.6b | qa | float16
23:46:01 - INFO - ================================================================================
23:46:05 - INFO - [start_stablelm-2-1.6b_qa] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 100.0%
23:46:05 - INFO - Loading qa dataset (10000 samples)...
23:46:05 - INFO - Loading MMLU dataset with 10000 samples...
23:46:09 - INFO - Loaded 10000 MMLU instances
23:46:09 - INFO - [dataset_loading] Duration: 4576.21ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
23:46:09 - INFO - Processing qa dataset to 6-option format...
23:46:10 - INFO - Processed 10000 instances for qa
23:46:10 - INFO - Splitting qa dataset (calibration: 50%, test: 50%)
23:46:10 - INFO - Split complete:
23:46:10 - INFO -   Calibration: 4998 instances
23:46:10 - INFO -   Test: 5002 instances
23:46:10 - WARNING - Calibration size 4998 differs from expected 5000
23:46:10 - INFO - Answer distribution:
23:46:10 - INFO -   Calibration: {'A': 1174, 'B': 1230, 'C': 1242, 'D': 1352}
23:46:10 - INFO -   Test: {'A': 1175, 'B': 1231, 'C': 1243, 'D': 1353}
23:46:10 - INFO - [dataset_processing] Duration: 271.22ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
23:46:10 - INFO - Initialized DemonstrationSelector
23:46:10 - INFO -   Strategy: random
23:46:10 - INFO -   Num demonstrations: 5
23:46:10 - INFO - Initialized DemonstrationManager
23:46:10 - INFO - Selecting 5 demonstrations using 'random' strategy
23:46:10 - INFO - Selected and cached 5 demonstrations for qa
23:46:10 - INFO - Loading model: stablelm-2-1.6b (float16)
23:46:10 - INFO - Loading model: stablelm-2-1.6b_float16 (stabilityai/stablelm-2-1_6b)
23:46:10 - INFO - Loading tokenizer from stabilityai/stablelm-2-1_6b
23:46:11 - INFO - Tokenizer loaded successfully
23:46:11 - INFO -   Vocab size: 100289
23:46:11 - INFO -   Padding side: left
23:46:11 - INFO -   PAD token: <|endoftext|> (ID: 100257)
23:46:11 - INFO - Loading model from stabilityai/stablelm-2-1_6b
`torch_dtype` is deprecated! Use `dtype` instead!
23:46:16 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
23:46:18 - INFO - Model loaded successfully
23:46:18 - INFO -   GPU Memory: 3.06GB allocated, 3.25GB reserved

Model: stablelm-2-1.6b_float16
  ID: stabilityai/stablelm-2-1_6b
  Type: causal
  Parameters: 1,644,515,328
  Vocab size: 100,289
  Max length: 4096
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: True
23:46:18 - INFO - [model_loading] Duration: 8112.90ms | GPU Memory: 0.0MB -> 3136.7MB (delta +3136.7MB)
23:46:18 - INFO - [after_model_load_stablelm-2-1.6b] GPU State: Allocated: 3136.7MB | Reserved: 3328.0MB | Free: 78019.1MB | Utilization: 100.0%
23:46:18 - INFO - Using batch size: 32
23:46:18 - INFO -   Strategy: base
23:46:18 - INFO - Initialized PromptBuilder for task: qa
23:46:18 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
23:46:18 - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
23:46:18 - INFO - Initialized InferenceEngine for stablelm-2-1.6b_float16
23:46:18 - INFO -   Device: cuda:0
23:46:18 - INFO -   Batch size: 32
23:46:18 - INFO -   Option tokens: {'A': 362, 'B': 426, 'C': 356, 'D': 423, 'E': 469, 'F': 435}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]/root/BLUQ/src/models/inference_engine.py:433: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Running inference:   1%|          | 1/157 [00:02<06:16,  2.41s/it]Running inference:   1%|▏         | 2/157 [00:04<05:34,  2.16s/it]Running inference:   2%|▏         | 3/157 [00:06<05:29,  2.14s/it]Running inference:   3%|▎         | 4/157 [00:08<05:21,  2.10s/it]Running inference:   3%|▎         | 5/157 [00:11<05:48,  2.30s/it]Running inference:   4%|▍         | 6/157 [00:13<05:50,  2.32s/it]Running inference:   4%|▍         | 7/157 [00:16<06:31,  2.61s/it]Running inference:   5%|▌         | 8/157 [00:19<06:26,  2.59s/it]Running inference:   6%|▌         | 9/157 [00:22<06:47,  2.76s/it]Running inference:   6%|▋         | 10/157 [00:24<06:26,  2.63s/it]Running inference:   7%|▋         | 11/157 [00:27<06:14,  2.57s/it]Running inference:   8%|▊         | 12/157 [00:29<05:45,  2.38s/it]Running inference:   8%|▊         | 13/157 [00:31<05:39,  2.36s/it]Running inference:   9%|▉         | 14/157 [00:33<05:37,  2.36s/it]Running inference:  10%|▉         | 15/157 [00:36<06:00,  2.54s/it]Running inference:  10%|█         | 16/157 [00:39<06:06,  2.60s/it]Running inference:  11%|█         | 17/157 [00:42<06:00,  2.58s/it]Running inference:  11%|█▏        | 18/157 [00:44<06:09,  2.66s/it]Running inference:  12%|█▏        | 19/157 [00:47<05:46,  2.51s/it]Running inference:  13%|█▎        | 20/157 [00:50<06:08,  2.69s/it]Running inference:  13%|█▎        | 21/157 [00:52<05:53,  2.60s/it]Running inference:  14%|█▍        | 22/157 [00:54<05:41,  2.53s/it]Running inference:  15%|█▍        | 23/157 [00:57<05:22,  2.40s/it]Running inference:  15%|█▌        | 24/157 [00:59<05:24,  2.44s/it]Running inference:  16%|█▌        | 25/157 [01:01<05:17,  2.40s/it]Running inference:  17%|█▋        | 26/157 [01:03<04:58,  2.28s/it]Running inference:  17%|█▋        | 27/157 [01:06<05:09,  2.38s/it]Running inference:  18%|█▊        | 28/157 [01:09<05:25,  2.52s/it]Running inference:  18%|█▊        | 29/157 [01:11<05:04,  2.38s/it]Running inference:  19%|█▉        | 30/157 [01:13<04:51,  2.30s/it]Running inference:  20%|█▉        | 31/157 [01:16<05:02,  2.40s/it]Running inference:  20%|██        | 32/157 [01:18<04:44,  2.27s/it]Running inference:  21%|██        | 33/157 [01:20<04:42,  2.28s/it]Running inference:  22%|██▏       | 34/157 [01:22<04:39,  2.28s/it]Running inference:  22%|██▏       | 35/157 [01:25<04:56,  2.43s/it]Running inference:  23%|██▎       | 36/157 [01:28<05:04,  2.52s/it]Running inference:  24%|██▎       | 37/157 [01:30<04:59,  2.49s/it]Running inference:  24%|██▍       | 38/157 [01:32<04:51,  2.45s/it]Running inference:  25%|██▍       | 39/157 [01:35<04:38,  2.36s/it]Running inference:  25%|██▌       | 40/157 [01:37<04:43,  2.43s/it]Running inference:  26%|██▌       | 41/157 [01:39<04:35,  2.38s/it]Running inference:  27%|██▋       | 42/157 [01:42<04:51,  2.54s/it]Running inference:  27%|██▋       | 43/157 [01:44<04:30,  2.37s/it]Running inference:  28%|██▊       | 44/157 [01:46<04:19,  2.29s/it]Running inference:  29%|██▊       | 45/157 [01:49<04:31,  2.43s/it]Running inference:  29%|██▉       | 46/157 [01:52<04:25,  2.39s/it]Running inference:  30%|██▉       | 47/157 [01:54<04:15,  2.32s/it]Running inference:  31%|███       | 48/157 [01:56<04:21,  2.40s/it]Running inference:  31%|███       | 49/157 [01:58<04:13,  2.34s/it]Running inference:  32%|███▏      | 50/157 [02:01<04:11,  2.35s/it]Running inference:  32%|███▏      | 51/157 [02:03<04:13,  2.39s/it]Running inference:  33%|███▎      | 52/157 [02:06<04:30,  2.57s/it]Running inference:  34%|███▍      | 53/157 [02:09<04:20,  2.50s/it]Running inference:  34%|███▍      | 54/157 [02:11<04:14,  2.47s/it]Running inference:  35%|███▌      | 55/157 [02:13<04:09,  2.45s/it]Running inference:  36%|███▌      | 56/157 [02:16<04:12,  2.50s/it]Running inference:  36%|███▋      | 57/157 [02:19<04:11,  2.52s/it]Running inference:  37%|███▋      | 58/157 [02:21<04:14,  2.57s/it]Running inference:  38%|███▊      | 59/157 [02:24<04:26,  2.72s/it]Running inference:  38%|███▊      | 60/157 [02:27<04:15,  2.64s/it]Running inference:  39%|███▉      | 61/157 [02:30<04:18,  2.70s/it]Running inference:  39%|███▉      | 62/157 [02:32<04:05,  2.58s/it]Running inference:  40%|████      | 63/157 [02:34<03:54,  2.50s/it]Running inference:  41%|████      | 64/157 [02:37<03:45,  2.42s/it]Running inference:  41%|████▏     | 65/157 [02:39<03:54,  2.55s/it]Running inference:  42%|████▏     | 66/157 [02:41<03:36,  2.38s/it]Running inference:  43%|████▎     | 67/157 [02:44<03:45,  2.51s/it]Running inference:  43%|████▎     | 68/157 [02:46<03:26,  2.32s/it]Running inference:  44%|████▍     | 69/157 [02:48<03:19,  2.26s/it]Running inference:  45%|████▍     | 70/157 [02:51<03:33,  2.45s/it]Running inference:  45%|████▌     | 71/157 [02:53<03:28,  2.42s/it]Running inference:  46%|████▌     | 72/157 [02:56<03:27,  2.44s/it]Running inference:  46%|████▋     | 73/157 [02:58<03:21,  2.40s/it]Running inference:  47%|████▋     | 74/157 [03:01<03:18,  2.39s/it]Running inference:  48%|████▊     | 75/157 [03:03<03:10,  2.32s/it]Running inference:  48%|████▊     | 76/157 [03:05<03:02,  2.25s/it]Running inference:  49%|████▉     | 77/157 [03:08<03:23,  2.54s/it]Running inference:  50%|████▉     | 78/157 [03:10<03:13,  2.45s/it]Running inference:  50%|█████     | 79/157 [03:13<03:08,  2.41s/it]Running inference:  51%|█████     | 80/157 [03:15<02:59,  2.32s/it]Running inference:  52%|█████▏    | 81/157 [03:18<03:08,  2.49s/it]Running inference:  52%|█████▏    | 82/157 [03:20<02:57,  2.37s/it]Running inference:  53%|█████▎    | 83/157 [03:22<02:58,  2.41s/it]Running inference:  54%|█████▎    | 84/157 [03:25<03:09,  2.59s/it]Running inference:  54%|█████▍    | 85/157 [03:28<03:02,  2.53s/it]Running inference:  55%|█████▍    | 86/157 [03:30<03:02,  2.57s/it]Running inference:  55%|█████▌    | 87/157 [03:33<02:55,  2.51s/it]Running inference:  56%|█████▌    | 88/157 [03:35<02:46,  2.42s/it]Running inference:  57%|█████▋    | 89/157 [03:37<02:39,  2.35s/it]Running inference:  57%|█████▋    | 90/157 [03:39<02:30,  2.24s/it]Running inference:  58%|█████▊    | 91/157 [03:42<02:41,  2.44s/it]Running inference:  59%|█████▊    | 92/157 [03:45<02:43,  2.52s/it]Running inference:  59%|█████▉    | 93/157 [03:47<02:37,  2.46s/it]Running inference:  60%|█████▉    | 94/157 [03:49<02:27,  2.33s/it]Running inference:  61%|██████    | 95/157 [03:52<02:30,  2.42s/it]Running inference:  61%|██████    | 96/157 [03:54<02:23,  2.35s/it]Running inference:  62%|██████▏   | 97/157 [03:56<02:19,  2.33s/it]Running inference:  62%|██████▏   | 98/157 [03:59<02:23,  2.43s/it]Running inference:  63%|██████▎   | 99/157 [04:01<02:16,  2.35s/it]Running inference:  64%|██████▎   | 100/157 [04:03<02:09,  2.27s/it]Running inference:  64%|██████▍   | 101/157 [04:05<02:01,  2.17s/it]Running inference:  65%|██████▍   | 102/157 [04:07<01:56,  2.12s/it]Running inference:  66%|██████▌   | 103/157 [04:09<01:53,  2.11s/it]Running inference:  66%|██████▌   | 104/157 [04:12<02:04,  2.35s/it]Running inference:  67%|██████▋   | 105/157 [04:14<01:59,  2.29s/it]Running inference:  68%|██████▊   | 106/157 [04:17<02:00,  2.37s/it]Running inference:  68%|██████▊   | 107/157 [04:19<01:59,  2.39s/it]Running inference:  69%|██████▉   | 108/157 [04:21<01:54,  2.33s/it]Running inference:  69%|██████▉   | 109/157 [04:24<02:00,  2.50s/it]Running inference:  70%|███████   | 110/157 [04:26<01:54,  2.43s/it]Running inference:  71%|███████   | 111/157 [04:29<01:53,  2.47s/it]Running inference:  71%|███████▏  | 112/157 [04:31<01:48,  2.40s/it]Running inference:  72%|███████▏  | 113/157 [04:34<01:53,  2.58s/it]Running inference:  73%|███████▎  | 114/157 [04:36<01:43,  2.40s/it]Running inference:  73%|███████▎  | 115/157 [04:39<01:46,  2.54s/it]Running inference:  74%|███████▍  | 116/157 [04:41<01:41,  2.48s/it]Running inference:  75%|███████▍  | 117/157 [04:44<01:38,  2.47s/it]Running inference:  75%|███████▌  | 118/157 [04:46<01:31,  2.35s/it]Running inference:  76%|███████▌  | 119/157 [04:49<01:32,  2.44s/it]Running inference:  76%|███████▋  | 120/157 [04:51<01:28,  2.38s/it]Running inference:  77%|███████▋  | 121/157 [04:53<01:22,  2.29s/it]Running inference:  78%|███████▊  | 122/157 [04:55<01:19,  2.27s/it]Running inference:  78%|███████▊  | 123/157 [04:58<01:20,  2.35s/it]Running inference:  79%|███████▉  | 124/157 [05:00<01:17,  2.36s/it]Running inference:  80%|███████▉  | 125/157 [05:02<01:12,  2.25s/it]Running inference:  80%|████████  | 126/157 [05:05<01:13,  2.38s/it]Running inference:  81%|████████  | 127/157 [05:08<01:19,  2.63s/it]Running inference:  82%|████████▏ | 128/157 [05:10<01:14,  2.56s/it]Running inference:  82%|████████▏ | 129/157 [05:13<01:09,  2.49s/it]Running inference:  83%|████████▎ | 130/157 [05:15<01:04,  2.40s/it]Running inference:  83%|████████▎ | 131/157 [05:17<01:02,  2.40s/it]Running inference:  84%|████████▍ | 132/157 [05:20<01:01,  2.44s/it]Running inference:  85%|████████▍ | 133/157 [05:22<00:58,  2.43s/it]Running inference:  85%|████████▌ | 134/157 [05:25<00:58,  2.55s/it]Running inference:  86%|████████▌ | 135/157 [05:28<00:58,  2.66s/it]Running inference:  87%|████████▋ | 136/157 [05:30<00:55,  2.63s/it]Running inference:  87%|████████▋ | 137/157 [05:33<00:49,  2.50s/it]Running inference:  88%|████████▊ | 138/157 [05:35<00:45,  2.41s/it]Running inference:  89%|████████▊ | 139/157 [05:38<00:45,  2.51s/it]Running inference:  89%|████████▉ | 140/157 [05:40<00:41,  2.41s/it]Running inference:  90%|████████▉ | 141/157 [05:42<00:37,  2.34s/it]Running inference:  90%|█████████ | 142/157 [05:44<00:34,  2.33s/it]Running inference:  91%|█████████ | 143/157 [05:48<00:36,  2.61s/it]Running inference:  92%|█████████▏| 144/157 [05:50<00:34,  2.64s/it]Running inference:  92%|█████████▏| 145/157 [05:52<00:30,  2.52s/it]Running inference:  93%|█████████▎| 146/157 [05:55<00:26,  2.40s/it]Running inference:  94%|█████████▎| 147/157 [05:56<00:21,  2.13s/it]Running inference:  94%|█████████▍| 148/157 [05:58<00:19,  2.19s/it]Running inference:  95%|█████████▍| 149/157 [06:01<00:17,  2.17s/it]Running inference:  96%|█████████▌| 150/157 [06:03<00:15,  2.23s/it]Running inference:  96%|█████████▌| 151/157 [06:05<00:13,  2.30s/it]Running inference:  97%|█████████▋| 152/157 [06:08<00:11,  2.39s/it]Running inference:  97%|█████████▋| 153/157 [06:10<00:09,  2.38s/it]Running inference:  98%|█████████▊| 154/157 [06:13<00:07,  2.35s/it]Running inference:  99%|█████████▊| 155/157 [06:16<00:05,  2.56s/it]Running inference:  99%|█████████▉| 156/157 [06:18<00:02,  2.38s/it]Running inference: 100%|██████████| 157/157 [06:18<00:00,  1.78s/it]Running inference: 100%|██████████| 157/157 [06:18<00:00,  2.41s/it]
23:52:37 - INFO - [inference_calibration] Duration: 378518.81ms | GPU Memory: 3136.7MB -> 3145.8MB (delta +9.1MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:02<05:29,  2.11s/it]Running inference:   1%|▏         | 2/157 [00:04<05:43,  2.22s/it]Running inference:   2%|▏         | 3/157 [00:06<05:57,  2.32s/it]Running inference:   3%|▎         | 4/157 [00:09<05:51,  2.29s/it]Running inference:   3%|▎         | 5/157 [00:11<05:42,  2.25s/it]Running inference:   4%|▍         | 6/157 [00:13<05:41,  2.26s/it]Running inference:   4%|▍         | 7/157 [00:16<06:21,  2.54s/it]Running inference:   5%|▌         | 8/157 [00:18<05:59,  2.41s/it]Running inference:   6%|▌         | 9/157 [00:21<05:51,  2.37s/it]Running inference:   6%|▋         | 10/157 [00:23<05:53,  2.40s/it]Running inference:   7%|▋         | 11/157 [00:25<05:42,  2.34s/it]Running inference:   8%|▊         | 12/157 [00:27<05:29,  2.27s/it]Running inference:   8%|▊         | 13/157 [00:30<05:30,  2.30s/it]Running inference:   9%|▉         | 14/157 [00:32<05:27,  2.29s/it]Running inference:  10%|▉         | 15/157 [00:35<05:34,  2.35s/it]Running inference:  10%|█         | 16/157 [00:37<05:29,  2.33s/it]Running inference:  11%|█         | 17/157 [00:39<05:18,  2.27s/it]Running inference:  11%|█▏        | 18/157 [00:42<05:30,  2.38s/it]Running inference:  12%|█▏        | 19/157 [00:44<05:31,  2.40s/it]Running inference:  13%|█▎        | 20/157 [00:46<05:17,  2.32s/it]Running inference:  13%|█▎        | 21/157 [00:49<05:18,  2.34s/it]Running inference:  14%|█▍        | 22/157 [00:51<05:21,  2.38s/it]Running inference:  15%|█▍        | 23/157 [00:54<05:35,  2.51s/it]Running inference:  15%|█▌        | 24/157 [00:56<05:17,  2.39s/it]Running inference:  16%|█▌        | 25/157 [00:59<05:28,  2.49s/it]Running inference:  17%|█▋        | 26/157 [01:02<05:43,  2.62s/it]Running inference:  17%|█▋        | 27/157 [01:05<05:53,  2.72s/it]Running inference:  18%|█▊        | 28/157 [01:07<05:41,  2.65s/it]Running inference:  18%|█▊        | 29/157 [01:09<05:25,  2.54s/it]Running inference:  19%|█▉        | 30/157 [01:12<05:20,  2.52s/it]Running inference:  20%|█▉        | 31/157 [01:14<05:07,  2.44s/it]Running inference:  20%|██        | 32/157 [01:16<05:04,  2.44s/it]Running inference:  21%|██        | 33/157 [01:19<04:47,  2.32s/it]Running inference:  22%|██▏       | 34/157 [01:21<04:47,  2.33s/it]Running inference:  22%|██▏       | 35/157 [01:23<04:47,  2.35s/it]Running inference:  23%|██▎       | 36/157 [01:25<04:34,  2.27s/it]Running inference:  24%|██▎       | 37/157 [01:27<04:26,  2.22s/it]Running inference:  24%|██▍       | 38/157 [01:30<04:28,  2.26s/it]Running inference:  25%|██▍       | 39/157 [01:33<04:45,  2.42s/it]Running inference:  25%|██▌       | 40/157 [01:34<04:20,  2.22s/it]Running inference:  26%|██▌       | 41/157 [01:37<04:18,  2.23s/it]Running inference:  27%|██▋       | 42/157 [01:39<04:20,  2.27s/it]Running inference:  27%|██▋       | 43/157 [01:41<04:17,  2.26s/it]Running inference:  28%|██▊       | 44/157 [01:43<04:12,  2.24s/it]Running inference:  29%|██▊       | 45/157 [01:46<04:19,  2.31s/it]Running inference:  29%|██▉       | 46/157 [01:48<04:16,  2.31s/it]Running inference:  30%|██▉       | 47/157 [01:51<04:26,  2.42s/it]Running inference:  31%|███       | 48/157 [01:53<04:20,  2.39s/it]Running inference:  31%|███       | 49/157 [01:55<04:16,  2.37s/it]Running inference:  32%|███▏      | 50/157 [01:58<04:12,  2.36s/it]Running inference:  32%|███▏      | 51/157 [02:00<04:10,  2.37s/it]Running inference:  33%|███▎      | 52/157 [02:03<04:08,  2.37s/it]Running inference:  34%|███▍      | 53/157 [02:05<03:58,  2.29s/it]Running inference:  34%|███▍      | 54/157 [02:07<03:58,  2.31s/it]Running inference:  35%|███▌      | 55/157 [02:10<04:07,  2.43s/it]Running inference:  36%|███▌      | 56/157 [02:13<04:24,  2.62s/it]Running inference:  36%|███▋      | 57/157 [02:16<04:26,  2.66s/it]Running inference:  37%|███▋      | 58/157 [02:19<04:36,  2.80s/it]Running inference:  38%|███▊      | 59/157 [02:21<04:29,  2.75s/it]Running inference:  38%|███▊      | 60/157 [02:24<04:10,  2.58s/it]Running inference:  39%|███▉      | 61/157 [02:26<03:55,  2.46s/it]Running inference:  39%|███▉      | 62/157 [02:28<03:46,  2.39s/it]Running inference:  40%|████      | 63/157 [02:32<04:33,  2.91s/it]Running inference:  41%|████      | 64/157 [02:35<04:22,  2.83s/it]Running inference:  41%|████▏     | 65/157 [02:37<04:00,  2.62s/it]Running inference:  42%|████▏     | 66/157 [02:39<03:46,  2.49s/it]Running inference:  43%|████▎     | 67/157 [02:42<03:51,  2.57s/it]Running inference:  43%|████▎     | 68/157 [02:44<03:39,  2.46s/it]Running inference:  44%|████▍     | 69/157 [02:46<03:33,  2.42s/it]Running inference:  45%|████▍     | 70/157 [02:49<03:36,  2.48s/it]Running inference:  45%|████▌     | 71/157 [02:51<03:31,  2.46s/it]Running inference:  46%|████▌     | 72/157 [02:54<03:22,  2.38s/it]Running inference:  46%|████▋     | 73/157 [02:57<03:59,  2.85s/it]Running inference:  47%|████▋     | 74/157 [03:00<03:43,  2.69s/it]Running inference:  48%|████▊     | 75/157 [03:02<03:33,  2.60s/it]Running inference:  48%|████▊     | 76/157 [03:05<03:24,  2.53s/it]Running inference:  49%|████▉     | 77/157 [03:07<03:24,  2.55s/it]Running inference:  50%|████▉     | 78/157 [03:10<03:20,  2.53s/it]Running inference:  50%|█████     | 79/157 [03:12<03:14,  2.49s/it]Running inference:  51%|█████     | 80/157 [03:15<03:15,  2.54s/it]Running inference:  52%|█████▏    | 81/157 [03:17<03:12,  2.53s/it]Running inference:  52%|█████▏    | 82/157 [03:20<03:13,  2.58s/it]Running inference:  53%|█████▎    | 83/157 [03:22<03:07,  2.53s/it]Running inference:  54%|█████▎    | 84/157 [03:25<03:10,  2.62s/it]Running inference:  54%|█████▍    | 85/157 [03:28<03:18,  2.75s/it]Running inference:  55%|█████▍    | 86/157 [03:30<03:03,  2.58s/it]Running inference:  55%|█████▌    | 87/157 [03:33<02:52,  2.47s/it]Running inference:  56%|█████▌    | 88/157 [03:35<02:53,  2.52s/it]Running inference:  57%|█████▋    | 89/157 [03:37<02:38,  2.33s/it]Running inference:  57%|█████▋    | 90/157 [03:39<02:32,  2.28s/it]Running inference:  58%|█████▊    | 91/157 [03:42<02:35,  2.35s/it]Running inference:  59%|█████▊    | 92/157 [03:44<02:38,  2.44s/it]Running inference:  59%|█████▉    | 93/157 [03:47<02:41,  2.52s/it]Running inference:  60%|█████▉    | 94/157 [03:49<02:34,  2.46s/it]Running inference:  61%|██████    | 95/157 [03:52<02:30,  2.43s/it]Running inference:  61%|██████    | 96/157 [03:54<02:24,  2.36s/it]Running inference:  62%|██████▏   | 97/157 [03:57<02:27,  2.47s/it]Running inference:  62%|██████▏   | 98/157 [03:59<02:17,  2.34s/it]Running inference:  63%|██████▎   | 99/157 [04:01<02:12,  2.28s/it]Running inference:  64%|██████▎   | 100/157 [04:03<02:08,  2.26s/it]Running inference:  64%|██████▍   | 101/157 [04:05<02:03,  2.21s/it]Running inference:  65%|██████▍   | 102/157 [04:08<02:05,  2.28s/it]Running inference:  66%|██████▌   | 103/157 [04:10<02:04,  2.31s/it]Running inference:  66%|██████▌   | 104/157 [04:12<02:01,  2.30s/it]Running inference:  67%|██████▋   | 105/157 [04:14<01:57,  2.27s/it]Running inference:  68%|██████▊   | 106/157 [04:17<01:56,  2.28s/it]Running inference:  68%|██████▊   | 107/157 [04:20<02:11,  2.62s/it]Running inference:  69%|██████▉   | 108/157 [04:22<02:02,  2.50s/it]Running inference:  69%|██████▉   | 109/157 [04:24<01:53,  2.37s/it]Running inference:  70%|███████   | 110/157 [04:27<01:48,  2.30s/it]Running inference:  71%|███████   | 111/157 [04:29<01:49,  2.37s/it]Running inference:  71%|███████▏  | 112/157 [04:32<01:50,  2.45s/it]Running inference:  72%|███████▏  | 113/157 [04:34<01:48,  2.47s/it]Running inference:  73%|███████▎  | 114/157 [04:36<01:39,  2.32s/it]Running inference:  73%|███████▎  | 115/157 [04:39<01:39,  2.37s/it]Running inference:  74%|███████▍  | 116/157 [04:41<01:39,  2.43s/it]Running inference:  75%|███████▍  | 117/157 [04:43<01:33,  2.34s/it]Running inference:  75%|███████▌  | 118/157 [04:46<01:31,  2.34s/it]Running inference:  76%|███████▌  | 119/157 [04:49<01:35,  2.51s/it]Running inference:  76%|███████▋  | 120/157 [04:51<01:29,  2.42s/it]Running inference:  77%|███████▋  | 121/157 [04:54<01:29,  2.48s/it]Running inference:  78%|███████▊  | 122/157 [04:56<01:23,  2.37s/it]Running inference:  78%|███████▊  | 123/157 [04:58<01:17,  2.29s/it]Running inference:  79%|███████▉  | 124/157 [05:00<01:18,  2.39s/it]Running inference:  80%|███████▉  | 125/157 [05:02<01:12,  2.27s/it]Running inference:  80%|████████  | 126/157 [05:04<01:07,  2.19s/it]Running inference:  81%|████████  | 127/157 [05:08<01:14,  2.50s/it]Running inference:  82%|████████▏ | 128/157 [05:10<01:14,  2.56s/it]Running inference:  82%|████████▏ | 129/157 [05:12<01:07,  2.41s/it]Running inference:  83%|████████▎ | 130/157 [05:15<01:06,  2.45s/it]Running inference:  83%|████████▎ | 131/157 [05:17<01:02,  2.41s/it]Running inference:  84%|████████▍ | 132/157 [05:20<01:00,  2.43s/it]Running inference:  85%|████████▍ | 133/157 [05:22<00:57,  2.40s/it]Running inference:  85%|████████▌ | 134/157 [05:25<00:55,  2.43s/it]Running inference:  86%|████████▌ | 135/157 [05:27<00:55,  2.51s/it]Running inference:  87%|████████▋ | 136/157 [05:29<00:49,  2.36s/it]Running inference:  87%|████████▋ | 137/157 [05:32<00:47,  2.39s/it]Running inference:  88%|████████▊ | 138/157 [05:34<00:46,  2.44s/it]Running inference:  89%|████████▊ | 139/157 [05:37<00:45,  2.53s/it]Running inference:  89%|████████▉ | 140/157 [05:39<00:42,  2.49s/it]Running inference:  90%|████████▉ | 141/157 [05:43<00:43,  2.71s/it]Running inference:  90%|█████████ | 142/157 [05:45<00:39,  2.61s/it]Running inference:  91%|█████████ | 143/157 [05:49<00:42,  3.05s/it]Running inference:  92%|█████████▏| 144/157 [05:52<00:37,  2.86s/it]Running inference:  92%|█████████▏| 145/157 [05:54<00:33,  2.82s/it]Running inference:  93%|█████████▎| 146/157 [05:56<00:28,  2.57s/it]Running inference:  94%|█████████▎| 147/157 [05:59<00:24,  2.50s/it]Running inference:  94%|█████████▍| 148/157 [06:01<00:21,  2.41s/it]Running inference:  95%|█████████▍| 149/157 [06:03<00:18,  2.34s/it]Running inference:  96%|█████████▌| 150/157 [06:06<00:17,  2.47s/it]Running inference:  96%|█████████▌| 151/157 [06:09<00:15,  2.65s/it]Running inference:  97%|█████████▋| 152/157 [06:11<00:12,  2.45s/it]Running inference:  97%|█████████▋| 153/157 [06:13<00:09,  2.44s/it]Running inference:  98%|█████████▊| 154/157 [06:15<00:07,  2.39s/it]Running inference:  99%|█████████▊| 155/157 [06:17<00:04,  2.25s/it]Running inference:  99%|█████████▉| 156/157 [06:20<00:02,  2.36s/it]Running inference: 100%|██████████| 157/157 [06:21<00:00,  1.84s/it]Running inference: 100%|██████████| 157/157 [06:21<00:00,  2.43s/it]
23:58:58 - INFO - [inference_test] Duration: 381108.53ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
23:58:58 - INFO -     Inference: 759.63s for 10000 samples (13.16 samples/sec)
23:58:58 - INFO - Initialized ProbabilityExtractor
23:58:58 - INFO -   Temperature: 1.0
23:58:58 - INFO -   Calibration method: None
23:58:58 - INFO - [probability_extraction] Duration: 304.20ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
23:58:58 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_stablelm-2-1.6b_qa_float16_base_20251207_234559.npz
23:58:58 - INFO - Initialized LACScorer
23:58:58 - INFO -   Alpha: 0.1
23:58:58 - INFO -   Target coverage: 90.0%
23:58:58 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
23:58:58 - INFO - Initialized PredictionSetGenerator
23:58:58 - INFO -   Methods: ['lac']
23:58:58 - INFO -   Alpha: 0.1
23:58:58 - INFO -   Aggregation: separate
23:58:58 - INFO - Calibrating 1 conformal predictors...
23:58:58 - INFO -   Calibrating LAC...
23:58:58 - INFO - Calibrating with 4998 samples...
23:58:58 - INFO - Calibration complete
23:58:58 - INFO -   Threshold: 0.9900
23:58:58 - INFO -   Score range: [0.0000, 1.0000]
23:58:58 - INFO - Calibration complete
23:58:58 - INFO - Generating prediction sets using LAC...
23:58:58 - INFO - Generating prediction sets for 5002 test instances...
23:58:58 - INFO - Prediction complete
23:58:58 - INFO -   Average set size: 5.26
23:58:58 - INFO -   Coverage rate: 89.60%
23:58:58 - INFO -   Meets coverage guarantee: False
23:58:58 - WARNING - ✗ Coverage guarantee NOT met: 89.60% < 90.00%
23:58:58 - WARNING - LAC does not meet coverage guarantee: 89.60% < 90.00%
23:58:58 - INFO -     LAC: Acc=20.45%, CR=89.60%, SS=5.26
23:58:58 - INFO - Initialized APSScorer
23:58:58 - INFO -   Alpha: 0.1
23:58:58 - INFO -   Target coverage: 90.0%
23:58:58 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
23:58:58 - INFO - Initialized PredictionSetGenerator
23:58:58 - INFO -   Methods: ['aps']
23:58:58 - INFO -   Alpha: 0.1
23:58:58 - INFO -   Aggregation: separate
23:58:58 - INFO - Calibrating 1 conformal predictors...
23:58:58 - INFO -   Calibrating APS...
23:58:58 - INFO - Calibrating with 4998 samples...
23:58:58 - INFO - Calibration complete
23:58:58 - INFO -   Threshold: 1.0000
23:58:58 - INFO -   Score range: [0.2047, 1.0000]
23:58:58 - INFO - Calibration complete
23:58:58 - INFO - Generating prediction sets using APS...
23:58:58 - INFO - Generating prediction sets for 5002 test instances...
23:58:58 - INFO - Prediction complete
23:58:58 - INFO -   Average set size: 5.85
23:58:58 - INFO -   Coverage rate: 98.20%
23:58:58 - INFO -   Meets coverage guarantee: True
23:58:58 - INFO - [PASS] Coverage guarantee met: 98.20% >= 90.00%
23:58:58 - INFO -     APS: Acc=20.45%, CR=98.20%, SS=5.85
23:59:01 - INFO - Unloaded model: stablelm-2-1.6b_float16
23:59:02 - INFO - Checkpoint saved after completing: stablelm-2-1.6b | qa | float16
23:59:02 - INFO - 
================================================================================
23:59:02 - INFO - Run 2/5: stablelm-2-1.6b | rc | float16
23:59:02 - INFO - ================================================================================
23:59:02 - INFO - [start_stablelm-2-1.6b_rc] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 100.0%
23:59:02 - INFO - Loading rc dataset (10000 samples)...
23:59:02 - INFO - Loading CosmosQA dataset with 10000 samples...
23:59:03 - INFO - CosmosQA loaded successfully with standard method
23:59:04 - INFO - Loaded 10000 CosmosQA instances
23:59:04 - INFO - [dataset_loading] Duration: 1927.16ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:59:04 - INFO - Processing rc dataset to 6-option format...
23:59:04 - INFO - Processed 10000 instances for rc
23:59:04 - INFO - Splitting rc dataset (calibration: 50%, test: 50%)
23:59:04 - INFO - Split complete:
23:59:04 - INFO -   Calibration: 4999 instances
23:59:04 - INFO -   Test: 5001 instances
23:59:04 - INFO - Answer distribution:
23:59:04 - INFO -   Calibration: {'A': 1240, 'B': 1245, 'C': 1263, 'D': 1251}
23:59:04 - INFO -   Test: {'A': 1241, 'B': 1245, 'C': 1264, 'D': 1251}
23:59:04 - INFO - [dataset_processing] Duration: 272.13ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:59:04 - INFO - Initialized DemonstrationSelector
23:59:04 - INFO -   Strategy: random
23:59:04 - INFO -   Num demonstrations: 5
23:59:04 - INFO - Initialized DemonstrationManager
23:59:04 - INFO - Selecting 5 demonstrations using 'random' strategy
23:59:04 - INFO - Selected and cached 5 demonstrations for rc
23:59:04 - INFO - Loading model: stablelm-2-1.6b (float16)
23:59:04 - INFO - Loading model: stablelm-2-1.6b_float16 (stabilityai/stablelm-2-1_6b)
23:59:04 - INFO - Loading tokenizer from stabilityai/stablelm-2-1_6b
23:59:04 - INFO - Tokenizer loaded successfully
23:59:05 - INFO -   Vocab size: 100289
23:59:05 - INFO -   Padding side: left
23:59:05 - INFO -   PAD token: <|endoftext|> (ID: 100257)
23:59:05 - INFO - Loading model from stabilityai/stablelm-2-1_6b
23:59:05 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
23:59:06 - INFO - Model loaded successfully
23:59:06 - INFO -   GPU Memory: 3.07GB allocated, 3.26GB reserved

Model: stablelm-2-1.6b_float16
  ID: stabilityai/stablelm-2-1_6b
  Type: causal
  Parameters: 1,644,515,328
  Vocab size: 100,289
  Max length: 4096
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: True
23:59:07 - INFO - [model_loading] Duration: 2462.95ms | GPU Memory: 9.1MB -> 3145.8MB (delta +3136.7MB)
23:59:07 - INFO - [after_model_load_stablelm-2-1.6b] GPU State: Allocated: 3145.8MB | Reserved: 3336.0MB | Free: 78009.9MB | Utilization: 100.0%
23:59:07 - INFO - Using batch size: 32
23:59:07 - INFO -   Strategy: base
23:59:07 - INFO - Initialized PromptBuilder for task: rc
23:59:07 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
23:59:07 - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
23:59:07 - INFO - Initialized InferenceEngine for stablelm-2-1.6b_float16
23:59:07 - INFO -   Device: cuda:0
23:59:07 - INFO -   Batch size: 32
23:59:07 - INFO -   Option tokens: {'A': 362, 'B': 426, 'C': 356, 'D': 423, 'E': 469, 'F': 435}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<05:09,  1.98s/it]Running inference:   1%|▏         | 2/157 [00:03<04:40,  1.81s/it]Running inference:   2%|▏         | 3/157 [00:04<03:21,  1.31s/it]Running inference:   3%|▎         | 4/157 [00:05<02:44,  1.08s/it]Running inference:   3%|▎         | 5/157 [00:05<02:23,  1.06it/s]Running inference:   4%|▍         | 6/157 [00:06<02:11,  1.14it/s]Running inference:   4%|▍         | 7/157 [00:07<02:03,  1.22it/s]Running inference:   5%|▌         | 8/157 [00:08<01:58,  1.26it/s]Running inference:   6%|▌         | 9/157 [00:08<01:54,  1.29it/s]Running inference:   6%|▋         | 10/157 [00:09<01:51,  1.32it/s]Running inference:   7%|▋         | 11/157 [00:10<01:50,  1.32it/s]Running inference:   8%|▊         | 12/157 [00:10<01:49,  1.33it/s]Running inference:   8%|▊         | 13/157 [00:11<01:47,  1.34it/s]Running inference:   9%|▉         | 14/157 [00:12<01:45,  1.36it/s]Running inference:  10%|▉         | 15/157 [00:13<01:44,  1.36it/s]Running inference:  10%|█         | 16/157 [00:13<01:43,  1.37it/s]Running inference:  11%|█         | 17/157 [00:14<01:43,  1.36it/s]Running inference:  11%|█▏        | 18/157 [00:15<01:43,  1.34it/s]Running inference:  12%|█▏        | 19/157 [00:16<01:43,  1.33it/s]Running inference:  13%|█▎        | 20/157 [00:16<01:42,  1.33it/s]Running inference:  13%|█▎        | 21/157 [00:17<01:41,  1.34it/s]Running inference:  14%|█▍        | 22/157 [00:18<01:39,  1.35it/s]Running inference:  15%|█▍        | 23/157 [00:19<01:39,  1.35it/s]Running inference:  15%|█▌        | 24/157 [00:19<01:38,  1.35it/s]Running inference:  16%|█▌        | 25/157 [00:20<01:36,  1.37it/s]Running inference:  17%|█▋        | 26/157 [00:21<01:36,  1.35it/s]Running inference:  17%|█▋        | 27/157 [00:22<01:35,  1.36it/s]Running inference:  18%|█▊        | 28/157 [00:22<01:35,  1.35it/s]Running inference:  18%|█▊        | 29/157 [00:23<01:34,  1.36it/s]Running inference:  19%|█▉        | 30/157 [00:24<01:32,  1.37it/s]Running inference:  20%|█▉        | 31/157 [00:24<01:32,  1.37it/s]Running inference:  20%|██        | 32/157 [00:25<01:30,  1.38it/s]Running inference:  21%|██        | 33/157 [00:26<01:30,  1.37it/s]Running inference:  22%|██▏       | 34/157 [00:27<01:29,  1.38it/s]Running inference:  22%|██▏       | 35/157 [00:27<01:28,  1.38it/s]Running inference:  23%|██▎       | 36/157 [00:28<01:28,  1.37it/s]Running inference:  24%|██▎       | 37/157 [00:29<01:27,  1.37it/s]Running inference:  24%|██▍       | 38/157 [00:30<01:27,  1.36it/s]Running inference:  25%|██▍       | 39/157 [00:30<01:26,  1.36it/s]Running inference:  25%|██▌       | 40/157 [00:31<01:25,  1.36it/s]Running inference:  26%|██▌       | 41/157 [00:32<01:25,  1.36it/s]Running inference:  27%|██▋       | 42/157 [00:32<01:24,  1.37it/s]Running inference:  27%|██▋       | 43/157 [00:33<01:23,  1.37it/s]Running inference:  28%|██▊       | 44/157 [00:34<01:22,  1.37it/s]Running inference:  29%|██▊       | 45/157 [00:35<01:21,  1.38it/s]Running inference:  29%|██▉       | 46/157 [00:35<01:20,  1.38it/s]Running inference:  30%|██▉       | 47/157 [00:36<01:19,  1.38it/s]Running inference:  31%|███       | 48/157 [00:37<01:18,  1.39it/s]Running inference:  31%|███       | 49/157 [00:38<01:17,  1.39it/s]Running inference:  32%|███▏      | 50/157 [00:38<01:19,  1.35it/s]Running inference:  32%|███▏      | 51/157 [00:39<01:18,  1.35it/s]Running inference:  33%|███▎      | 52/157 [00:40<01:17,  1.35it/s]Running inference:  34%|███▍      | 53/157 [00:41<01:16,  1.36it/s]Running inference:  34%|███▍      | 54/157 [00:41<01:15,  1.37it/s]Running inference:  35%|███▌      | 55/157 [00:42<01:14,  1.37it/s]Running inference:  36%|███▌      | 56/157 [00:43<01:13,  1.37it/s]Running inference:  36%|███▋      | 57/157 [00:43<01:13,  1.36it/s]Running inference:  37%|███▋      | 58/157 [00:44<01:12,  1.37it/s]Running inference:  38%|███▊      | 59/157 [00:45<01:10,  1.38it/s]Running inference:  38%|███▊      | 60/157 [00:46<01:10,  1.38it/s]Running inference:  39%|███▉      | 61/157 [00:46<01:11,  1.35it/s]Running inference:  39%|███▉      | 62/157 [00:47<01:12,  1.31it/s]Running inference:  40%|████      | 63/157 [00:48<01:20,  1.16it/s]Running inference:  41%|████      | 64/157 [00:50<01:52,  1.21s/it]Running inference:  41%|████▏     | 65/157 [00:52<02:09,  1.40s/it]Running inference:  42%|████▏     | 66/157 [00:54<02:23,  1.57s/it]Running inference:  43%|████▎     | 67/157 [00:56<02:28,  1.65s/it]Running inference:  43%|████▎     | 68/157 [00:58<02:31,  1.70s/it]Running inference:  44%|████▍     | 69/157 [01:00<02:36,  1.78s/it]Running inference:  45%|████▍     | 70/157 [01:02<02:39,  1.83s/it]Running inference:  45%|████▌     | 71/157 [01:04<02:42,  1.88s/it]Running inference:  46%|████▌     | 72/157 [01:06<02:42,  1.91s/it]Running inference:  46%|████▋     | 73/157 [01:08<02:42,  1.93s/it]Running inference:  47%|████▋     | 74/157 [01:10<02:41,  1.95s/it]Running inference:  48%|████▊     | 75/157 [01:12<02:37,  1.92s/it]Running inference:  48%|████▊     | 76/157 [01:14<02:40,  1.98s/it]Running inference:  49%|████▉     | 77/157 [01:16<02:36,  1.95s/it]Running inference:  50%|████▉     | 78/157 [01:17<02:31,  1.92s/it]Running inference:  50%|█████     | 79/157 [01:19<02:29,  1.92s/it]Running inference:  51%|█████     | 80/157 [01:21<02:26,  1.91s/it]Running inference:  52%|█████▏    | 81/157 [01:23<02:26,  1.92s/it]Running inference:  52%|█████▏    | 82/157 [01:25<02:20,  1.88s/it]Running inference:  53%|█████▎    | 83/157 [01:27<02:20,  1.90s/it]Running inference:  54%|█████▎    | 84/157 [01:29<02:20,  1.92s/it]Running inference:  54%|█████▍    | 85/157 [01:31<02:16,  1.89s/it]Running inference:  55%|█████▍    | 86/157 [01:33<02:17,  1.93s/it]Running inference:  55%|█████▌    | 87/157 [01:35<02:13,  1.91s/it]Running inference:  56%|█████▌    | 88/157 [01:36<02:11,  1.91s/it]Running inference:  57%|█████▋    | 89/157 [01:38<02:12,  1.96s/it]Running inference:  57%|█████▋    | 90/157 [01:40<02:09,  1.93s/it]Running inference:  58%|█████▊    | 91/157 [01:42<02:09,  1.96s/it]Running inference:  59%|█████▊    | 92/157 [01:44<02:05,  1.92s/it]Running inference:  59%|█████▉    | 93/157 [01:46<02:05,  1.96s/it]Running inference:  60%|█████▉    | 94/157 [01:48<02:04,  1.97s/it]Running inference:  61%|██████    | 95/157 [01:50<01:59,  1.92s/it]Running inference:  61%|██████    | 96/157 [01:52<01:57,  1.92s/it]Running inference:  62%|██████▏   | 97/157 [01:54<01:54,  1.91s/it]Running inference:  62%|██████▏   | 98/157 [01:56<01:54,  1.94s/it]Running inference:  63%|██████▎   | 99/157 [01:58<01:54,  1.97s/it]Running inference:  64%|██████▎   | 100/157 [02:00<01:51,  1.95s/it]Running inference:  64%|██████▍   | 101/157 [02:02<01:49,  1.96s/it]Running inference:  65%|██████▍   | 102/157 [02:04<01:46,  1.93s/it]Running inference:  66%|██████▌   | 103/157 [02:06<01:45,  1.95s/it]Running inference:  66%|██████▌   | 104/157 [02:08<01:41,  1.92s/it]Running inference:  67%|██████▋   | 105/157 [02:09<01:39,  1.91s/it]Running inference:  68%|██████▊   | 106/157 [02:11<01:39,  1.94s/it]Running inference:  68%|██████▊   | 107/157 [02:13<01:36,  1.92s/it]Running inference:  69%|██████▉   | 108/157 [02:15<01:35,  1.94s/it]Running inference:  69%|██████▉   | 109/157 [02:17<01:31,  1.91s/it]Running inference:  70%|███████   | 110/157 [02:19<01:31,  1.94s/it]Running inference:  71%|███████   | 111/157 [02:21<01:28,  1.93s/it]Running inference:  71%|███████▏  | 112/157 [02:23<01:26,  1.92s/it]Running inference:  72%|███████▏  | 113/157 [02:25<01:25,  1.95s/it]Running inference:  73%|███████▎  | 114/157 [02:27<01:22,  1.92s/it]Running inference:  73%|███████▎  | 115/157 [02:29<01:21,  1.95s/it]Running inference:  74%|███████▍  | 116/157 [02:31<01:19,  1.95s/it]Running inference:  75%|███████▍  | 117/157 [02:33<01:16,  1.92s/it]Running inference:  75%|███████▌  | 118/157 [02:35<01:15,  1.93s/it]Running inference:  76%|███████▌  | 119/157 [02:36<01:12,  1.91s/it]Running inference:  76%|███████▋  | 120/157 [02:38<01:11,  1.94s/it]Running inference:  77%|███████▋  | 121/157 [02:40<01:09,  1.92s/it]Running inference:  78%|███████▊  | 122/157 [02:42<01:07,  1.92s/it]Running inference:  78%|███████▊  | 123/157 [02:44<01:05,  1.93s/it]Running inference:  79%|███████▉  | 124/157 [02:46<01:02,  1.91s/it]Running inference:  80%|███████▉  | 125/157 [02:48<01:01,  1.93s/it]Running inference:  80%|████████  | 126/157 [02:50<00:59,  1.92s/it]Running inference:  81%|████████  | 127/157 [02:52<00:58,  1.94s/it]Running inference:  82%|████████▏ | 128/157 [02:54<00:56,  1.97s/it]Running inference:  82%|████████▏ | 129/157 [02:56<00:54,  1.95s/it]Running inference:  83%|████████▎ | 130/157 [02:58<00:52,  1.96s/it]Running inference:  83%|████████▎ | 131/157 [03:00<00:49,  1.91s/it]Running inference:  84%|████████▍ | 132/157 [03:02<00:48,  1.93s/it]Running inference:  85%|████████▍ | 133/157 [03:04<00:45,  1.92s/it]Running inference:  85%|████████▌ | 134/157 [03:05<00:43,  1.89s/it]Running inference:  86%|████████▌ | 135/157 [03:07<00:42,  1.93s/it]Running inference:  87%|████████▋ | 136/157 [03:09<00:39,  1.90s/it]Running inference:  87%|████████▋ | 137/157 [03:11<00:38,  1.93s/it]Running inference:  88%|████████▊ | 138/157 [03:13<00:36,  1.91s/it]Running inference:  89%|████████▊ | 139/157 [03:15<00:34,  1.92s/it]Running inference:  89%|████████▉ | 140/157 [03:17<00:33,  1.94s/it]Running inference:  90%|████████▉ | 141/157 [03:19<00:31,  1.94s/it]Running inference:  90%|█████████ | 142/157 [03:21<00:29,  1.96s/it]Running inference:  91%|█████████ | 143/157 [03:23<00:27,  1.94s/it]Running inference:  92%|█████████▏| 144/157 [03:25<00:25,  1.97s/it]Running inference:  92%|█████████▏| 145/157 [03:27<00:23,  1.94s/it]Running inference:  93%|█████████▎| 146/157 [03:29<00:21,  1.96s/it]Running inference:  94%|█████████▎| 147/157 [03:31<00:19,  1.96s/it]Running inference:  94%|█████████▍| 148/157 [03:33<00:17,  1.93s/it]Running inference:  95%|█████████▍| 149/157 [03:35<00:15,  1.95s/it]Running inference:  96%|█████████▌| 150/157 [03:37<00:13,  1.95s/it]Running inference:  96%|█████████▌| 151/157 [03:39<00:11,  1.98s/it]Running inference:  97%|█████████▋| 152/157 [03:40<00:09,  1.95s/it]Running inference:  97%|█████████▋| 153/157 [03:42<00:07,  1.96s/it]Running inference:  98%|█████████▊| 154/157 [03:44<00:05,  1.98s/it]Running inference:  99%|█████████▊| 155/157 [03:46<00:03,  1.93s/it]Running inference:  99%|█████████▉| 156/157 [03:48<00:01,  1.94s/it]Running inference: 100%|██████████| 157/157 [03:49<00:00,  1.50s/it]Running inference: 100%|██████████| 157/157 [03:49<00:00,  1.46s/it]
00:02:56 - INFO - [inference_calibration] Duration: 229237.62ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<04:52,  1.87s/it]Running inference:   1%|▏         | 2/157 [00:03<04:45,  1.84s/it]Running inference:   2%|▏         | 3/157 [00:05<04:58,  1.94s/it]Running inference:   3%|▎         | 4/157 [00:07<04:51,  1.91s/it]Running inference:   3%|▎         | 5/157 [00:09<04:53,  1.93s/it]Running inference:   4%|▍         | 6/157 [00:11<04:50,  1.92s/it]Running inference:   4%|▍         | 7/157 [00:13<04:52,  1.95s/it]Running inference:   5%|▌         | 8/157 [00:15<04:57,  2.00s/it]Running inference:   6%|▌         | 9/157 [00:17<04:49,  1.95s/it]Running inference:   6%|▋         | 10/157 [00:19<04:48,  1.96s/it]Running inference:   7%|▋         | 11/157 [00:21<04:40,  1.92s/it]Running inference:   8%|▊         | 12/157 [00:23<04:40,  1.94s/it]Running inference:   8%|▊         | 13/157 [00:25<04:34,  1.91s/it]Running inference:   9%|▉         | 14/157 [00:26<04:31,  1.90s/it]Running inference:  10%|▉         | 15/157 [00:28<04:34,  1.93s/it]Running inference:  10%|█         | 16/157 [00:30<04:27,  1.90s/it]Running inference:  11%|█         | 17/157 [00:32<04:28,  1.92s/it]Running inference:  11%|█▏        | 18/157 [00:34<04:24,  1.90s/it]Running inference:  12%|█▏        | 19/157 [00:36<04:27,  1.94s/it]Running inference:  13%|█▎        | 20/157 [00:38<04:24,  1.93s/it]Running inference:  13%|█▎        | 21/157 [00:40<04:18,  1.90s/it]Running inference:  14%|█▍        | 22/157 [00:42<04:18,  1.92s/it]Running inference:  15%|█▍        | 23/157 [00:44<04:18,  1.93s/it]Running inference:  15%|█▌        | 24/157 [00:46<04:19,  1.95s/it]Running inference:  16%|█▌        | 25/157 [00:48<04:17,  1.95s/it]Running inference:  17%|█▋        | 26/157 [00:50<04:11,  1.92s/it]Running inference:  17%|█▋        | 27/157 [00:52<04:12,  1.94s/it]Running inference:  18%|█▊        | 28/157 [00:53<04:07,  1.92s/it]Running inference:  18%|█▊        | 29/157 [00:56<04:12,  1.97s/it]Running inference:  19%|█▉        | 30/157 [00:57<04:06,  1.94s/it]Running inference:  20%|█▉        | 31/157 [00:59<04:07,  1.97s/it]Running inference:  20%|██        | 32/157 [01:01<04:05,  1.96s/it]Running inference:  21%|██        | 33/157 [01:03<04:03,  1.96s/it]Running inference:  22%|██▏       | 34/157 [01:05<04:06,  2.01s/it]Running inference:  22%|██▏       | 35/157 [01:07<03:59,  1.97s/it]Running inference:  23%|██▎       | 36/157 [01:09<03:54,  1.93s/it]Running inference:  24%|██▎       | 37/157 [01:11<03:54,  1.95s/it]Running inference:  24%|██▍       | 38/157 [01:13<03:50,  1.94s/it]Running inference:  25%|██▍       | 39/157 [01:15<03:50,  1.95s/it]Running inference:  25%|██▌       | 40/157 [01:17<03:45,  1.93s/it]Running inference:  26%|██▌       | 41/157 [01:19<03:49,  1.98s/it]Running inference:  27%|██▋       | 42/157 [01:21<03:45,  1.96s/it]Running inference:  27%|██▋       | 43/157 [01:23<03:43,  1.96s/it]Running inference:  28%|██▊       | 44/157 [01:25<03:43,  1.98s/it]Running inference:  29%|██▊       | 45/157 [01:27<03:37,  1.94s/it]Running inference:  29%|██▉       | 46/157 [01:29<03:35,  1.95s/it]Running inference:  30%|██▉       | 47/157 [01:31<03:35,  1.96s/it]Running inference:  31%|███       | 48/157 [01:33<03:30,  1.93s/it]Running inference:  31%|███       | 49/157 [01:35<03:31,  1.96s/it]Running inference:  32%|███▏      | 50/157 [01:37<03:26,  1.93s/it]Running inference:  32%|███▏      | 51/157 [01:38<03:19,  1.88s/it]Running inference:  33%|███▎      | 52/157 [01:40<03:25,  1.95s/it]Running inference:  34%|███▍      | 53/157 [01:42<03:18,  1.91s/it]Running inference:  34%|███▍      | 54/157 [01:44<03:16,  1.90s/it]Running inference:  35%|███▌      | 55/157 [01:46<03:10,  1.87s/it]Running inference:  36%|███▌      | 56/157 [01:48<03:03,  1.81s/it]Running inference:  36%|███▋      | 57/157 [01:49<03:01,  1.82s/it]Running inference:  37%|███▋      | 58/157 [01:51<02:57,  1.79s/it]Running inference:  38%|███▊      | 59/157 [01:53<02:58,  1.82s/it]Running inference:  38%|███▊      | 60/157 [01:55<02:53,  1.79s/it]Running inference:  39%|███▉      | 61/157 [01:57<02:54,  1.82s/it]Running inference:  39%|███▉      | 62/157 [01:58<02:53,  1.82s/it]Running inference:  40%|████      | 63/157 [02:00<02:47,  1.79s/it]Running inference:  41%|████      | 64/157 [02:02<02:50,  1.84s/it]Running inference:  41%|████▏     | 65/157 [02:04<02:47,  1.82s/it]Running inference:  42%|████▏     | 66/157 [02:06<02:43,  1.79s/it]Running inference:  43%|████▎     | 67/157 [02:07<02:41,  1.79s/it]Running inference:  43%|████▎     | 68/157 [02:09<02:36,  1.76s/it]Running inference:  44%|████▍     | 69/157 [02:11<02:36,  1.78s/it]Running inference:  45%|████▍     | 70/157 [02:13<02:35,  1.79s/it]Running inference:  45%|████▌     | 71/157 [02:15<02:34,  1.80s/it]Running inference:  46%|████▌     | 72/157 [02:17<02:37,  1.85s/it]Running inference:  46%|████▋     | 73/157 [02:18<02:35,  1.85s/it]Running inference:  47%|████▋     | 74/157 [02:20<02:33,  1.85s/it]Running inference:  48%|████▊     | 75/157 [02:22<02:29,  1.82s/it]Running inference:  48%|████▊     | 76/157 [02:24<02:26,  1.81s/it]Running inference:  49%|████▉     | 77/157 [02:26<02:27,  1.84s/it]Running inference:  50%|████▉     | 78/157 [02:27<02:22,  1.81s/it]Running inference:  50%|█████     | 79/157 [02:29<02:25,  1.87s/it]Running inference:  51%|█████     | 80/157 [02:31<02:20,  1.83s/it]Running inference:  52%|█████▏    | 81/157 [02:33<02:19,  1.84s/it]Running inference:  52%|█████▏    | 82/157 [02:35<02:18,  1.85s/it]Running inference:  53%|█████▎    | 83/157 [02:37<02:15,  1.84s/it]Running inference:  54%|█████▎    | 84/157 [02:39<02:18,  1.90s/it]Running inference:  54%|█████▍    | 85/157 [02:41<02:18,  1.93s/it]Running inference:  55%|█████▍    | 86/157 [02:43<02:15,  1.91s/it]Running inference:  55%|█████▌    | 87/157 [02:45<02:17,  1.96s/it]Running inference:  56%|█████▌    | 88/157 [02:47<02:13,  1.93s/it]Running inference:  57%|█████▋    | 89/157 [02:49<02:11,  1.94s/it]Running inference:  57%|█████▋    | 90/157 [02:51<02:12,  1.98s/it]Running inference:  58%|█████▊    | 91/157 [02:52<02:06,  1.92s/it]Running inference:  59%|█████▊    | 92/157 [02:54<02:02,  1.89s/it]Running inference:  59%|█████▉    | 93/157 [02:56<01:58,  1.85s/it]Running inference:  60%|█████▉    | 94/157 [02:58<01:55,  1.84s/it]Running inference:  61%|██████    | 95/157 [03:00<01:56,  1.88s/it]Running inference:  61%|██████    | 96/157 [03:01<01:52,  1.84s/it]Running inference:  62%|██████▏   | 97/157 [03:03<01:49,  1.82s/it]Running inference:  62%|██████▏   | 98/157 [03:05<01:46,  1.81s/it]Running inference:  63%|██████▎   | 99/157 [03:07<01:44,  1.80s/it]Running inference:  64%|██████▎   | 100/157 [03:09<01:45,  1.85s/it]Running inference:  64%|██████▍   | 101/157 [03:11<01:42,  1.83s/it]Running inference:  65%|██████▍   | 102/157 [03:12<01:41,  1.84s/it]Running inference:  66%|██████▌   | 103/157 [03:14<01:41,  1.89s/it]Running inference:  66%|██████▌   | 104/157 [03:16<01:39,  1.87s/it]Running inference:  67%|██████▋   | 105/157 [03:18<01:38,  1.90s/it]Running inference:  68%|██████▊   | 106/157 [03:20<01:37,  1.92s/it]Running inference:  68%|██████▊   | 107/157 [03:22<01:35,  1.90s/it]Running inference:  69%|██████▉   | 108/157 [03:24<01:36,  1.97s/it]Running inference:  69%|██████▉   | 109/157 [03:26<01:33,  1.95s/it]Running inference:  70%|███████   | 110/157 [03:28<01:32,  1.97s/it]Running inference:  71%|███████   | 111/157 [03:30<01:28,  1.92s/it]Running inference:  71%|███████▏  | 112/157 [03:32<01:27,  1.94s/it]Running inference:  72%|███████▏  | 113/157 [03:34<01:26,  1.95s/it]Running inference:  73%|███████▎  | 114/157 [03:36<01:23,  1.94s/it]Running inference:  73%|███████▎  | 115/157 [03:38<01:22,  1.95s/it]Running inference:  74%|███████▍  | 116/157 [03:40<01:19,  1.94s/it]Running inference:  75%|███████▍  | 117/157 [03:42<01:18,  1.96s/it]Running inference:  75%|███████▌  | 118/157 [03:43<01:14,  1.92s/it]Running inference:  76%|███████▌  | 119/157 [03:45<01:12,  1.91s/it]Running inference:  76%|███████▋  | 120/157 [03:47<01:12,  1.97s/it]Running inference:  77%|███████▋  | 121/157 [03:49<01:09,  1.93s/it]Running inference:  78%|███████▊  | 122/157 [03:51<01:09,  1.98s/it]Running inference:  78%|███████▊  | 123/157 [03:53<01:06,  1.94s/it]Running inference:  79%|███████▉  | 124/157 [03:55<01:04,  1.95s/it]Running inference:  80%|███████▉  | 125/157 [03:57<01:02,  1.96s/it]Running inference:  80%|████████  | 126/157 [03:59<01:00,  1.94s/it]Running inference:  81%|████████  | 127/157 [04:01<00:58,  1.96s/it]Running inference:  82%|████████▏ | 128/157 [04:03<00:55,  1.92s/it]Running inference:  82%|████████▏ | 129/157 [04:05<00:53,  1.91s/it]Running inference:  83%|████████▎ | 130/157 [04:07<00:52,  1.94s/it]Running inference:  83%|████████▎ | 131/157 [04:09<00:49,  1.90s/it]Running inference:  84%|████████▍ | 132/157 [04:11<00:48,  1.92s/it]Running inference:  85%|████████▍ | 133/157 [04:13<00:45,  1.91s/it]Running inference:  85%|████████▌ | 134/157 [04:14<00:43,  1.89s/it]Running inference:  86%|████████▌ | 135/157 [04:16<00:41,  1.89s/it]Running inference:  87%|████████▋ | 136/157 [04:18<00:38,  1.85s/it]Running inference:  87%|████████▋ | 137/157 [04:20<00:38,  1.90s/it]Running inference:  88%|████████▊ | 138/157 [04:22<00:35,  1.89s/it]Running inference:  89%|████████▊ | 139/157 [04:24<00:33,  1.88s/it]Running inference:  89%|████████▉ | 140/157 [04:26<00:32,  1.92s/it]Running inference:  90%|████████▉ | 141/157 [04:28<00:30,  1.90s/it]Running inference:  90%|█████████ | 142/157 [04:30<00:29,  1.93s/it]Running inference:  91%|█████████ | 143/157 [04:31<00:26,  1.90s/it]Running inference:  92%|█████████▏| 144/157 [04:33<00:24,  1.92s/it]Running inference:  92%|█████████▏| 145/157 [04:35<00:23,  1.97s/it]Running inference:  93%|█████████▎| 146/157 [04:37<00:21,  1.94s/it]Running inference:  94%|█████████▎| 147/157 [04:39<00:19,  1.97s/it]Running inference:  94%|█████████▍| 148/157 [04:41<00:17,  1.93s/it]Running inference:  95%|█████████▍| 149/157 [04:43<00:15,  1.92s/it]Running inference:  96%|█████████▌| 150/157 [04:45<00:13,  1.96s/it]Running inference:  96%|█████████▌| 151/157 [04:47<00:11,  1.94s/it]Running inference:  97%|█████████▋| 152/157 [04:49<00:09,  1.98s/it]Running inference:  97%|█████████▋| 153/157 [04:51<00:07,  1.95s/it]Running inference:  98%|█████████▊| 154/157 [04:53<00:05,  1.93s/it]Running inference:  99%|█████████▊| 155/157 [04:55<00:03,  1.95s/it]Running inference:  99%|█████████▉| 156/157 [04:57<00:01,  1.91s/it]Running inference: 100%|██████████| 157/157 [04:57<00:00,  1.51s/it]Running inference: 100%|██████████| 157/157 [04:57<00:00,  1.90s/it]
00:07:54 - INFO - [inference_test] Duration: 297795.50ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:07:54 - INFO -     Inference: 527.04s for 10000 samples (18.97 samples/sec)
00:07:54 - INFO - Initialized ProbabilityExtractor
00:07:54 - INFO -   Temperature: 1.0
00:07:54 - INFO -   Calibration method: None
00:07:54 - INFO - [probability_extraction] Duration: 239.50ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:07:54 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_stablelm-2-1.6b_rc_float16_base_20251207_234559.npz
00:07:54 - INFO - Initialized LACScorer
00:07:54 - INFO -   Alpha: 0.1
00:07:54 - INFO -   Target coverage: 90.0%
00:07:54 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
00:07:54 - INFO - Initialized PredictionSetGenerator
00:07:54 - INFO -   Methods: ['lac']
00:07:54 - INFO -   Alpha: 0.1
00:07:54 - INFO -   Aggregation: separate
00:07:54 - INFO - Calibrating 1 conformal predictors...
00:07:54 - INFO -   Calibrating LAC...
00:07:54 - INFO - Calibrating with 4999 samples...
00:07:54 - INFO - Calibration complete
00:07:54 - INFO -   Threshold: 0.9943
00:07:54 - INFO -   Score range: [0.0000, 1.0000]
00:07:54 - INFO - Calibration complete
00:07:54 - INFO - Generating prediction sets using LAC...
00:07:54 - INFO - Generating prediction sets for 5001 test instances...
00:07:54 - INFO - Prediction complete
00:07:54 - INFO -   Average set size: 5.28
00:07:54 - INFO -   Coverage rate: 90.52%
00:07:54 - INFO -   Meets coverage guarantee: True
00:07:54 - INFO - [PASS] Coverage guarantee met: 90.52% >= 90.00%
00:07:54 - INFO -     LAC: Acc=21.86%, CR=90.52%, SS=5.28
00:07:54 - INFO - Initialized APSScorer
00:07:54 - INFO -   Alpha: 0.1
00:07:54 - INFO -   Target coverage: 90.0%
00:07:54 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
00:07:54 - INFO - Initialized PredictionSetGenerator
00:07:54 - INFO -   Methods: ['aps']
00:07:54 - INFO -   Alpha: 0.1
00:07:54 - INFO -   Aggregation: separate
00:07:54 - INFO - Calibrating 1 conformal predictors...
00:07:54 - INFO -   Calibrating APS...
00:07:54 - INFO - Calibrating with 4999 samples...
00:07:54 - INFO - Calibration complete
00:07:54 - INFO -   Threshold: 1.0000
00:07:54 - INFO -   Score range: [0.2046, 1.0000]
00:07:54 - INFO - Calibration complete
00:07:54 - INFO - Generating prediction sets using APS...
00:07:54 - INFO - Generating prediction sets for 5001 test instances...
00:07:54 - INFO - Prediction complete
00:07:54 - INFO -   Average set size: 5.04
00:07:54 - INFO -   Coverage rate: 90.22%
00:07:54 - INFO -   Meets coverage guarantee: True
00:07:54 - INFO - [PASS] Coverage guarantee met: 90.22% >= 90.00%
00:07:54 - INFO -     APS: Acc=21.86%, CR=90.22%, SS=5.04
00:07:57 - INFO - Unloaded model: stablelm-2-1.6b_float16
00:07:58 - INFO - Checkpoint saved after completing: stablelm-2-1.6b | rc | float16
00:07:58 - INFO - 
================================================================================
00:07:58 - INFO - Run 3/5: stablelm-2-1.6b | ci | float16
00:07:58 - INFO - ================================================================================
00:07:58 - INFO - [start_stablelm-2-1.6b_ci] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 100.0%
00:07:58 - INFO - Loading ci dataset (10000 samples)...
00:07:58 - INFO - Loading HellaSwag dataset with 10000 samples...
00:08:02 - INFO - Loaded 10000 HellaSwag instances
00:08:02 - INFO - [dataset_loading] Duration: 3843.69ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:08:02 - INFO - Processing ci dataset to 6-option format...
00:08:02 - INFO - Processed 10000 instances for ci
00:08:02 - INFO - Splitting ci dataset (calibration: 50%, test: 50%)
00:08:02 - INFO - Split complete:
00:08:02 - INFO -   Calibration: 4999 instances
00:08:02 - INFO -   Test: 5001 instances
00:08:02 - INFO - Answer distribution:
00:08:02 - INFO -   Calibration: {'A': 1240, 'B': 1242, 'C': 1256, 'D': 1261}
00:08:02 - INFO -   Test: {'A': 1240, 'B': 1242, 'C': 1257, 'D': 1262}
00:08:02 - INFO - [dataset_processing] Duration: 38.20ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:08:02 - INFO - Initialized DemonstrationSelector
00:08:02 - INFO -   Strategy: random
00:08:02 - INFO -   Num demonstrations: 5
00:08:02 - INFO - Initialized DemonstrationManager
00:08:02 - INFO - Selecting 5 demonstrations using 'random' strategy
00:08:02 - INFO - Selected and cached 5 demonstrations for ci
00:08:02 - INFO - Loading model: stablelm-2-1.6b (float16)
00:08:02 - INFO - Loading model: stablelm-2-1.6b_float16 (stabilityai/stablelm-2-1_6b)
00:08:02 - INFO - Loading tokenizer from stabilityai/stablelm-2-1_6b
00:08:02 - INFO - Tokenizer loaded successfully
00:08:02 - INFO -   Vocab size: 100289
00:08:02 - INFO -   Padding side: left
00:08:02 - INFO -   PAD token: <|endoftext|> (ID: 100257)
00:08:02 - INFO - Loading model from stabilityai/stablelm-2-1_6b
00:08:02 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
00:08:04 - INFO - Model loaded successfully
00:08:04 - INFO -   GPU Memory: 3.07GB allocated, 3.26GB reserved

Model: stablelm-2-1.6b_float16
  ID: stabilityai/stablelm-2-1_6b
  Type: causal
  Parameters: 1,644,515,328
  Vocab size: 100,289
  Max length: 4096
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: True
00:08:04 - INFO - [model_loading] Duration: 2731.66ms | GPU Memory: 9.1MB -> 3145.8MB (delta +3136.7MB)
00:08:04 - INFO - [after_model_load_stablelm-2-1.6b] GPU State: Allocated: 3145.8MB | Reserved: 3336.0MB | Free: 78009.9MB | Utilization: 85.0%
00:08:04 - INFO - Using batch size: 32
00:08:04 - INFO -   Strategy: base
00:08:04 - INFO - Initialized PromptBuilder for task: ci
00:08:04 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
00:08:04 - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
00:08:04 - INFO - Initialized InferenceEngine for stablelm-2-1.6b_float16
00:08:04 - INFO -   Device: cuda:0
00:08:04 - INFO -   Batch size: 32
00:08:04 - INFO -   Option tokens: {'A': 362, 'B': 426, 'C': 356, 'D': 423, 'E': 469, 'F': 435}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<05:11,  1.99s/it]Running inference:   1%|▏         | 2/157 [00:04<05:18,  2.05s/it]Running inference:   2%|▏         | 3/157 [00:06<05:06,  1.99s/it]Running inference:   3%|▎         | 4/157 [00:08<05:07,  2.01s/it]Running inference:   3%|▎         | 5/157 [00:09<04:56,  1.95s/it]Running inference:   4%|▍         | 6/157 [00:11<04:56,  1.97s/it]Running inference:   4%|▍         | 7/157 [00:13<04:49,  1.93s/it]Running inference:   5%|▌         | 8/157 [00:15<04:45,  1.92s/it]Running inference:   6%|▌         | 9/157 [00:17<04:48,  1.95s/it]Running inference:   6%|▋         | 10/157 [00:19<04:42,  1.92s/it]Running inference:   7%|▋         | 11/157 [00:21<04:44,  1.95s/it]Running inference:   8%|▊         | 12/157 [00:23<04:39,  1.93s/it]Running inference:   8%|▊         | 13/157 [00:25<04:34,  1.91s/it]Running inference:   9%|▉         | 14/157 [00:27<04:41,  1.97s/it]Running inference:  10%|▉         | 15/157 [00:29<04:38,  1.96s/it]Running inference:  10%|█         | 16/157 [00:31<04:31,  1.93s/it]Running inference:  11%|█         | 17/157 [00:33<04:32,  1.95s/it]Running inference:  11%|█▏        | 18/157 [00:35<04:26,  1.92s/it]Running inference:  12%|█▏        | 19/157 [00:37<04:29,  1.95s/it]Running inference:  13%|█▎        | 20/157 [00:39<04:27,  1.95s/it]Running inference:  13%|█▎        | 21/157 [00:41<04:28,  1.97s/it]Running inference:  14%|█▍        | 22/157 [00:42<04:26,  1.97s/it]Running inference:  15%|█▍        | 23/157 [00:44<04:21,  1.95s/it]Running inference:  15%|█▌        | 24/157 [00:46<04:22,  1.98s/it]Running inference:  16%|█▌        | 25/157 [00:48<04:16,  1.95s/it]Running inference:  17%|█▋        | 26/157 [00:50<04:13,  1.94s/it]Running inference:  17%|█▋        | 27/157 [00:52<04:08,  1.91s/it]Running inference:  18%|█▊        | 28/157 [00:54<04:04,  1.90s/it]Running inference:  18%|█▊        | 29/157 [00:56<04:06,  1.92s/it]Running inference:  19%|█▉        | 30/157 [00:58<04:02,  1.91s/it]Running inference:  20%|█▉        | 31/157 [01:00<04:05,  1.94s/it]Running inference:  20%|██        | 32/157 [01:02<04:01,  1.93s/it]Running inference:  21%|██        | 33/157 [01:04<03:56,  1.91s/it]Running inference:  22%|██▏       | 34/157 [01:06<03:58,  1.94s/it]Running inference:  22%|██▏       | 35/157 [01:07<03:54,  1.92s/it]Running inference:  23%|██▎       | 36/157 [01:10<03:58,  1.97s/it]Running inference:  24%|██▎       | 37/157 [01:11<03:53,  1.95s/it]Running inference:  24%|██▍       | 38/157 [01:13<03:51,  1.95s/it]Running inference:  25%|██▍       | 39/157 [01:15<03:47,  1.92s/it]Running inference:  25%|██▌       | 40/157 [01:17<03:41,  1.89s/it]Running inference:  26%|██▌       | 41/157 [01:19<03:41,  1.91s/it]Running inference:  27%|██▋       | 42/157 [01:21<03:37,  1.89s/it]Running inference:  27%|██▋       | 43/157 [01:23<03:42,  1.95s/it]Running inference:  28%|██▊       | 44/157 [01:25<03:36,  1.92s/it]Running inference:  29%|██▊       | 45/157 [01:27<03:34,  1.91s/it]Running inference:  29%|██▉       | 46/157 [01:29<03:39,  1.97s/it]Running inference:  30%|██▉       | 47/157 [01:31<03:33,  1.94s/it]Running inference:  31%|███       | 48/157 [01:33<03:36,  1.99s/it]Running inference:  31%|███       | 49/157 [01:35<03:34,  1.98s/it]Running inference:  32%|███▏      | 50/157 [01:37<03:31,  1.97s/it]Running inference:  32%|███▏      | 51/157 [01:39<03:30,  1.99s/it]Running inference:  33%|███▎      | 52/157 [01:41<03:28,  1.99s/it]Running inference:  34%|███▍      | 53/157 [01:43<03:28,  2.00s/it]Running inference:  34%|███▍      | 54/157 [01:45<03:22,  1.96s/it]Running inference:  35%|███▌      | 55/157 [01:47<03:17,  1.94s/it]Running inference:  36%|███▌      | 56/157 [01:49<03:19,  1.97s/it]Running inference:  36%|███▋      | 57/157 [01:50<03:14,  1.95s/it]Running inference:  37%|███▋      | 58/157 [01:52<03:14,  1.96s/it]Running inference:  38%|███▊      | 59/157 [01:54<03:09,  1.93s/it]Running inference:  38%|███▊      | 60/157 [01:56<03:04,  1.91s/it]Running inference:  39%|███▉      | 61/157 [01:58<03:05,  1.93s/it]Running inference:  39%|███▉      | 62/157 [02:00<03:05,  1.95s/it]Running inference:  40%|████      | 63/157 [02:02<03:04,  1.97s/it]Running inference:  41%|████      | 64/157 [02:04<03:01,  1.95s/it]Running inference:  41%|████▏     | 65/157 [02:06<03:01,  1.98s/it]Running inference:  42%|████▏     | 66/157 [02:08<02:59,  1.98s/it]Running inference:  43%|████▎     | 67/157 [02:10<02:57,  1.97s/it]Running inference:  43%|████▎     | 68/157 [02:12<02:56,  1.98s/it]Running inference:  44%|████▍     | 69/157 [02:14<02:50,  1.93s/it]Running inference:  45%|████▍     | 70/157 [02:16<02:52,  1.98s/it]Running inference:  45%|████▌     | 71/157 [02:18<02:46,  1.94s/it]Running inference:  46%|████▌     | 72/157 [02:20<02:43,  1.93s/it]Running inference:  46%|████▋     | 73/157 [02:22<02:42,  1.94s/it]Running inference:  47%|████▋     | 74/157 [02:23<02:38,  1.91s/it]Running inference:  48%|████▊     | 75/157 [02:25<02:38,  1.94s/it]Running inference:  48%|████▊     | 76/157 [02:27<02:35,  1.93s/it]Running inference:  49%|████▉     | 77/157 [02:30<02:38,  1.99s/it]Running inference:  50%|████▉     | 78/157 [02:31<02:34,  1.95s/it]Running inference:  50%|█████     | 79/157 [02:33<02:29,  1.92s/it]Running inference:  51%|█████     | 80/157 [02:35<02:29,  1.95s/it]Running inference:  52%|█████▏    | 81/157 [02:37<02:25,  1.92s/it]Running inference:  52%|█████▏    | 82/157 [02:39<02:26,  1.96s/it]Running inference:  53%|█████▎    | 83/157 [02:41<02:21,  1.92s/it]Running inference:  54%|█████▎    | 84/157 [02:43<02:20,  1.92s/it]Running inference:  54%|█████▍    | 85/157 [02:45<02:22,  1.98s/it]Running inference:  55%|█████▍    | 86/157 [02:47<02:18,  1.95s/it]Running inference:  55%|█████▌    | 87/157 [02:49<02:17,  1.97s/it]Running inference:  56%|█████▌    | 88/157 [02:51<02:13,  1.93s/it]Running inference:  57%|█████▋    | 89/157 [02:53<02:10,  1.92s/it]Running inference:  57%|█████▋    | 90/157 [02:55<02:09,  1.94s/it]Running inference:  58%|█████▊    | 91/157 [02:57<02:06,  1.92s/it]Running inference:  59%|█████▊    | 92/157 [02:58<02:05,  1.94s/it]Running inference:  59%|█████▉    | 93/157 [03:00<02:03,  1.94s/it]Running inference:  60%|█████▉    | 94/157 [03:02<02:01,  1.94s/it]Running inference:  61%|██████    | 95/157 [03:04<02:01,  1.97s/it]Running inference:  61%|██████    | 96/157 [03:06<01:57,  1.93s/it]Running inference:  62%|██████▏   | 97/157 [03:08<01:55,  1.93s/it]Running inference:  62%|██████▏   | 98/157 [03:10<01:52,  1.90s/it]Running inference:  63%|██████▎   | 99/157 [03:12<01:50,  1.90s/it]Running inference:  64%|██████▎   | 100/157 [03:14<01:47,  1.89s/it]Running inference:  64%|██████▍   | 101/157 [03:16<01:44,  1.86s/it]Running inference:  65%|██████▍   | 102/157 [03:17<01:42,  1.87s/it]Running inference:  66%|██████▌   | 103/157 [03:19<01:40,  1.86s/it]Running inference:  66%|██████▌   | 104/157 [03:21<01:39,  1.88s/it]Running inference:  67%|██████▋   | 105/157 [03:23<01:39,  1.91s/it]Running inference:  68%|██████▊   | 106/157 [03:25<01:35,  1.87s/it]Running inference:  68%|██████▊   | 107/157 [03:27<01:32,  1.86s/it]Running inference:  69%|██████▉   | 108/157 [03:29<01:31,  1.86s/it]Running inference:  69%|██████▉   | 109/157 [03:30<01:27,  1.83s/it]Running inference:  70%|███████   | 110/157 [03:32<01:27,  1.85s/it]Running inference:  71%|███████   | 111/157 [03:34<01:24,  1.84s/it]Running inference:  71%|███████▏  | 112/157 [03:36<01:21,  1.82s/it]Running inference:  72%|███████▏  | 113/157 [03:38<01:21,  1.85s/it]Running inference:  73%|███████▎  | 114/157 [03:40<01:19,  1.84s/it]Running inference:  73%|███████▎  | 115/157 [03:42<01:18,  1.87s/it]Running inference:  74%|███████▍  | 116/157 [03:43<01:16,  1.87s/it]Running inference:  75%|███████▍  | 117/157 [03:45<01:15,  1.90s/it]Running inference:  75%|███████▌  | 118/157 [03:47<01:14,  1.91s/it]Running inference:  76%|███████▌  | 119/157 [03:49<01:12,  1.90s/it]Running inference:  76%|███████▋  | 120/157 [03:51<01:12,  1.95s/it]Running inference:  77%|███████▋  | 121/157 [03:53<01:08,  1.91s/it]Running inference:  78%|███████▊  | 122/157 [03:55<01:07,  1.94s/it]Running inference:  78%|███████▊  | 123/157 [03:57<01:05,  1.93s/it]Running inference:  79%|███████▉  | 124/157 [03:59<01:03,  1.92s/it]Running inference:  80%|███████▉  | 125/157 [04:01<01:02,  1.94s/it]Running inference:  80%|████████  | 126/157 [04:03<00:58,  1.89s/it]Running inference:  81%|████████  | 127/157 [04:05<00:57,  1.93s/it]Running inference:  82%|████████▏ | 128/157 [04:06<00:54,  1.89s/it]Running inference:  82%|████████▏ | 129/157 [04:08<00:52,  1.88s/it]Running inference:  83%|████████▎ | 130/157 [04:10<00:51,  1.92s/it]Running inference:  83%|████████▎ | 131/157 [04:12<00:49,  1.90s/it]Running inference:  84%|████████▍ | 132/157 [04:14<00:48,  1.93s/it]Running inference:  85%|████████▍ | 133/157 [04:16<00:45,  1.91s/it]Running inference:  85%|████████▌ | 134/157 [04:18<00:43,  1.88s/it]Running inference:  86%|████████▌ | 135/157 [04:20<00:41,  1.91s/it]Running inference:  87%|████████▋ | 136/157 [04:22<00:39,  1.89s/it]Running inference:  87%|████████▋ | 137/157 [04:24<00:38,  1.92s/it]Running inference:  88%|████████▊ | 138/157 [04:26<00:36,  1.91s/it]Running inference:  89%|████████▊ | 139/157 [04:28<00:36,  2.02s/it]Running inference:  89%|████████▉ | 140/157 [04:30<00:34,  2.02s/it]Running inference:  90%|████████▉ | 141/157 [04:32<00:31,  1.97s/it]Running inference:  90%|█████████ | 142/157 [04:34<00:29,  1.95s/it]Running inference:  91%|█████████ | 143/157 [04:36<00:27,  1.98s/it]Running inference:  92%|█████████▏| 144/157 [04:38<00:25,  1.98s/it]Running inference:  92%|█████████▏| 145/157 [04:40<00:24,  2.02s/it]Running inference:  93%|█████████▎| 146/157 [04:42<00:21,  1.99s/it]Running inference:  94%|█████████▎| 147/157 [04:44<00:19,  1.97s/it]Running inference:  94%|█████████▍| 148/157 [04:46<00:17,  1.98s/it]Running inference:  95%|█████████▍| 149/157 [04:48<00:15,  1.97s/it]Running inference:  96%|█████████▌| 150/157 [04:50<00:14,  2.01s/it]Running inference:  96%|█████████▌| 151/157 [04:52<00:11,  1.97s/it]Running inference:  97%|█████████▋| 152/157 [04:53<00:09,  1.93s/it]Running inference:  97%|█████████▋| 153/157 [04:55<00:07,  1.96s/it]Running inference:  98%|█████████▊| 154/157 [04:57<00:05,  1.94s/it]Running inference:  99%|█████████▊| 155/157 [04:59<00:03,  1.96s/it]Running inference:  99%|█████████▉| 156/157 [05:01<00:01,  1.94s/it]Running inference: 100%|██████████| 157/157 [05:02<00:00,  1.50s/it]Running inference: 100%|██████████| 157/157 [05:02<00:00,  1.92s/it]
00:13:07 - INFO - [inference_calibration] Duration: 302197.83ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:02<05:13,  2.01s/it]Running inference:   1%|▏         | 2/157 [00:04<05:10,  2.00s/it]Running inference:   2%|▏         | 3/157 [00:05<05:00,  1.95s/it]Running inference:   3%|▎         | 4/157 [00:07<05:01,  1.97s/it]Running inference:   3%|▎         | 5/157 [00:09<04:54,  1.94s/it]Running inference:   4%|▍         | 6/157 [00:11<04:56,  1.96s/it]Running inference:   4%|▍         | 7/157 [00:13<04:57,  1.98s/it]Running inference:   5%|▌         | 8/157 [00:15<04:50,  1.95s/it]Running inference:   6%|▌         | 9/157 [00:17<04:53,  1.99s/it]Running inference:   6%|▋         | 10/157 [00:19<04:45,  1.94s/it]Running inference:   7%|▋         | 11/157 [00:21<04:45,  1.96s/it]Running inference:   8%|▊         | 12/157 [00:23<04:45,  1.97s/it]Running inference:   8%|▊         | 13/157 [00:25<04:38,  1.93s/it]Running inference:   9%|▉         | 14/157 [00:27<04:39,  1.96s/it]Running inference:  10%|▉         | 15/157 [00:29<04:34,  1.94s/it]Running inference:  10%|█         | 16/157 [00:31<04:33,  1.94s/it]Running inference:  11%|█         | 17/157 [00:33<04:29,  1.93s/it]Running inference:  11%|█▏        | 18/157 [00:35<04:26,  1.92s/it]Running inference:  12%|█▏        | 19/157 [00:37<04:27,  1.94s/it]Running inference:  13%|█▎        | 20/157 [00:38<04:20,  1.90s/it]Running inference:  13%|█▎        | 21/157 [00:40<04:20,  1.92s/it]Running inference:  14%|█▍        | 22/157 [00:42<04:19,  1.92s/it]Running inference:  15%|█▍        | 23/157 [00:44<04:18,  1.93s/it]Running inference:  15%|█▌        | 24/157 [00:46<04:20,  1.96s/it]Running inference:  16%|█▌        | 25/157 [00:48<04:19,  1.96s/it]Running inference:  17%|█▋        | 26/157 [00:50<04:22,  2.00s/it]Running inference:  17%|█▋        | 27/157 [00:52<04:14,  1.96s/it]Running inference:  18%|█▊        | 28/157 [00:54<04:11,  1.95s/it]Running inference:  18%|█▊        | 29/157 [00:56<04:08,  1.94s/it]Running inference:  19%|█▉        | 30/157 [00:58<04:04,  1.93s/it]Running inference:  20%|█▉        | 31/157 [01:00<04:05,  1.95s/it]Running inference:  20%|██        | 32/157 [01:02<03:58,  1.91s/it]Running inference:  21%|██        | 33/157 [01:04<03:58,  1.92s/it]Running inference:  22%|██▏       | 34/157 [01:05<03:48,  1.85s/it]Running inference:  22%|██▏       | 35/157 [01:07<03:45,  1.85s/it]Running inference:  23%|██▎       | 36/157 [01:09<03:43,  1.85s/it]Running inference:  24%|██▎       | 37/157 [01:11<03:41,  1.84s/it]Running inference:  24%|██▍       | 38/157 [01:13<03:44,  1.88s/it]Running inference:  25%|██▍       | 39/157 [01:15<03:41,  1.87s/it]Running inference:  25%|██▌       | 40/157 [01:17<03:40,  1.89s/it]Running inference:  26%|██▌       | 41/157 [01:19<03:40,  1.90s/it]Running inference:  27%|██▋       | 42/157 [01:20<03:33,  1.86s/it]Running inference:  27%|██▋       | 43/157 [01:22<03:36,  1.90s/it]Running inference:  28%|██▊       | 44/157 [01:24<03:31,  1.87s/it]Running inference:  29%|██▊       | 45/157 [01:26<03:31,  1.88s/it]Running inference:  29%|██▉       | 46/157 [01:28<03:29,  1.89s/it]Running inference:  30%|██▉       | 47/157 [01:30<03:23,  1.85s/it]Running inference:  31%|███       | 48/157 [01:32<03:21,  1.85s/it]Running inference:  31%|███       | 49/157 [01:33<03:17,  1.83s/it]Running inference:  32%|███▏      | 50/157 [01:35<03:20,  1.87s/it]Running inference:  32%|███▏      | 51/157 [01:37<03:23,  1.92s/it]Running inference:  33%|███▎      | 52/157 [01:39<03:19,  1.90s/it]Running inference:  34%|███▍      | 53/157 [01:41<03:23,  1.96s/it]Running inference:  34%|███▍      | 54/157 [01:43<03:21,  1.96s/it]Running inference:  35%|███▌      | 55/157 [01:45<03:14,  1.90s/it]Running inference:  36%|███▌      | 56/157 [01:47<03:14,  1.92s/it]Running inference:  36%|███▋      | 57/157 [01:49<03:10,  1.90s/it]Running inference:  37%|███▋      | 58/157 [01:50<03:00,  1.82s/it]Running inference:  38%|███▊      | 59/157 [01:52<03:01,  1.85s/it]Running inference:  38%|███▊      | 60/157 [01:54<02:59,  1.85s/it]Running inference:  39%|███▉      | 61/157 [01:56<02:59,  1.87s/it]Running inference:  39%|███▉      | 62/157 [01:58<02:54,  1.84s/it]Running inference:  40%|████      | 63/157 [02:00<02:53,  1.84s/it]Running inference:  41%|████      | 64/157 [02:02<02:53,  1.86s/it]Running inference:  41%|████▏     | 65/157 [02:03<02:49,  1.84s/it]Running inference:  42%|████▏     | 66/157 [02:05<02:51,  1.89s/it]Running inference:  43%|████▎     | 67/157 [02:07<02:47,  1.86s/it]Running inference:  43%|████▎     | 68/157 [02:09<02:46,  1.87s/it]Running inference:  44%|████▍     | 69/157 [02:11<02:49,  1.92s/it]Running inference:  45%|████▍     | 70/157 [02:13<02:45,  1.90s/it]Running inference:  45%|████▌     | 71/157 [02:15<02:39,  1.86s/it]Running inference:  46%|████▌     | 72/157 [02:17<02:40,  1.89s/it]Running inference:  46%|████▋     | 73/157 [02:19<02:36,  1.86s/it]Running inference:  47%|████▋     | 74/157 [02:20<02:35,  1.87s/it]Running inference:  48%|████▊     | 75/157 [02:22<02:34,  1.88s/it]Running inference:  48%|████▊     | 76/157 [02:24<02:28,  1.83s/it]Running inference:  49%|████▉     | 77/157 [02:26<02:29,  1.87s/it]Running inference:  50%|████▉     | 78/157 [02:28<02:25,  1.84s/it]Running inference:  50%|█████     | 79/157 [02:30<02:21,  1.82s/it]Running inference:  51%|█████     | 80/157 [02:31<02:20,  1.83s/it]Running inference:  52%|█████▏    | 81/157 [02:33<02:18,  1.82s/it]Running inference:  52%|█████▏    | 82/157 [02:35<02:15,  1.81s/it]Running inference:  53%|█████▎    | 83/157 [02:37<02:14,  1.82s/it]Running inference:  54%|█████▎    | 84/157 [02:39<02:10,  1.79s/it]Running inference:  54%|█████▍    | 85/157 [02:40<02:10,  1.82s/it]Running inference:  55%|█████▍    | 86/157 [02:42<02:07,  1.80s/it]Running inference:  55%|█████▌    | 87/157 [02:44<02:04,  1.78s/it]Running inference:  56%|█████▌    | 88/157 [02:46<02:06,  1.84s/it]Running inference:  57%|█████▋    | 89/157 [02:48<02:03,  1.81s/it]Running inference:  57%|█████▋    | 90/157 [02:49<02:00,  1.79s/it]Running inference:  58%|█████▊    | 91/157 [02:51<01:59,  1.80s/it]Running inference:  59%|█████▊    | 92/157 [02:53<01:55,  1.78s/it]Running inference:  59%|█████▉    | 93/157 [02:55<01:55,  1.81s/it]Running inference:  60%|█████▉    | 94/157 [02:57<01:54,  1.82s/it]Running inference:  61%|██████    | 95/157 [02:59<01:53,  1.83s/it]Running inference:  61%|██████    | 96/157 [03:00<01:52,  1.84s/it]Running inference:  62%|██████▏   | 97/157 [03:02<01:50,  1.84s/it]Running inference:  62%|██████▏   | 98/157 [03:04<01:49,  1.86s/it]Running inference:  63%|██████▎   | 99/157 [03:06<01:45,  1.83s/it]Running inference:  64%|██████▎   | 100/157 [03:08<01:44,  1.84s/it]Running inference:  64%|██████▍   | 101/157 [03:10<01:43,  1.84s/it]Running inference:  65%|██████▍   | 102/157 [03:11<01:36,  1.75s/it]Running inference:  66%|██████▌   | 103/157 [03:12<01:17,  1.44s/it]Running inference:  66%|██████▌   | 104/157 [03:13<01:05,  1.23s/it]Running inference:  67%|██████▋   | 105/157 [03:13<00:56,  1.08s/it]Running inference:  68%|██████▊   | 106/157 [03:14<00:49,  1.03it/s]Running inference:  68%|██████▊   | 107/157 [03:15<00:44,  1.12it/s]Running inference:  69%|██████▉   | 108/157 [03:16<00:41,  1.18it/s]Running inference:  69%|██████▉   | 109/157 [03:16<00:38,  1.24it/s]Running inference:  70%|███████   | 110/157 [03:17<00:37,  1.26it/s]Running inference:  71%|███████   | 111/157 [03:18<00:35,  1.29it/s]Running inference:  71%|███████▏  | 112/157 [03:19<00:34,  1.31it/s]Running inference:  72%|███████▏  | 113/157 [03:19<00:33,  1.31it/s]Running inference:  73%|███████▎  | 114/157 [03:20<00:32,  1.33it/s]Running inference:  73%|███████▎  | 115/157 [03:21<00:31,  1.35it/s]Running inference:  74%|███████▍  | 116/157 [03:21<00:30,  1.36it/s]Running inference:  75%|███████▍  | 117/157 [03:22<00:29,  1.36it/s]Running inference:  75%|███████▌  | 118/157 [03:23<00:28,  1.37it/s]Running inference:  76%|███████▌  | 119/157 [03:24<00:27,  1.37it/s]Running inference:  76%|███████▋  | 120/157 [03:24<00:27,  1.36it/s]Running inference:  77%|███████▋  | 121/157 [03:25<00:26,  1.36it/s]Running inference:  78%|███████▊  | 122/157 [03:26<00:25,  1.37it/s]Running inference:  78%|███████▊  | 123/157 [03:27<00:24,  1.38it/s]Running inference:  79%|███████▉  | 124/157 [03:27<00:23,  1.38it/s]Running inference:  80%|███████▉  | 125/157 [03:28<00:23,  1.37it/s]Running inference:  80%|████████  | 126/157 [03:29<00:22,  1.37it/s]Running inference:  81%|████████  | 127/157 [03:29<00:21,  1.38it/s]Running inference:  82%|████████▏ | 128/157 [03:30<00:21,  1.37it/s]Running inference:  82%|████████▏ | 129/157 [03:31<00:20,  1.36it/s]Running inference:  83%|████████▎ | 130/157 [03:32<00:19,  1.36it/s]Running inference:  83%|████████▎ | 131/157 [03:32<00:18,  1.37it/s]Running inference:  84%|████████▍ | 132/157 [03:33<00:18,  1.37it/s]Running inference:  85%|████████▍ | 133/157 [03:34<00:17,  1.38it/s]Running inference:  85%|████████▌ | 134/157 [03:35<00:17,  1.35it/s]Running inference:  86%|████████▌ | 135/157 [03:35<00:16,  1.35it/s]Running inference:  87%|████████▋ | 136/157 [03:36<00:15,  1.35it/s]Running inference:  87%|████████▋ | 137/157 [03:37<00:14,  1.36it/s]Running inference:  88%|████████▊ | 138/157 [03:38<00:13,  1.36it/s]Running inference:  89%|████████▊ | 139/157 [03:38<00:13,  1.35it/s]Running inference:  89%|████████▉ | 140/157 [03:39<00:12,  1.37it/s]Running inference:  90%|████████▉ | 141/157 [03:40<00:11,  1.35it/s]Running inference:  90%|█████████ | 142/157 [03:40<00:11,  1.36it/s]Running inference:  91%|█████████ | 143/157 [03:41<00:10,  1.36it/s]Running inference:  92%|█████████▏| 144/157 [03:42<00:09,  1.37it/s]Running inference:  92%|█████████▏| 145/157 [03:43<00:08,  1.37it/s]Running inference:  93%|█████████▎| 146/157 [03:43<00:08,  1.35it/s]Running inference:  94%|█████████▎| 147/157 [03:44<00:07,  1.36it/s]Running inference:  94%|█████████▍| 148/157 [03:45<00:06,  1.36it/s]Running inference:  95%|█████████▍| 149/157 [03:46<00:05,  1.36it/s]Running inference:  96%|█████████▌| 150/157 [03:46<00:05,  1.34it/s]Running inference:  96%|█████████▌| 151/157 [03:47<00:04,  1.35it/s]Running inference:  97%|█████████▋| 152/157 [03:48<00:03,  1.35it/s]Running inference:  97%|█████████▋| 153/157 [03:49<00:02,  1.36it/s]Running inference:  98%|█████████▊| 154/157 [03:49<00:02,  1.36it/s]Running inference:  99%|█████████▊| 155/157 [03:50<00:01,  1.37it/s]Running inference:  99%|█████████▉| 156/157 [03:51<00:00,  1.35it/s]Running inference: 100%|██████████| 157/157 [03:51<00:00,  1.71it/s]Running inference: 100%|██████████| 157/157 [03:51<00:00,  1.47s/it]
00:16:58 - INFO - [inference_test] Duration: 231519.85ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:16:58 - INFO -     Inference: 533.72s for 10000 samples (18.74 samples/sec)
00:16:58 - INFO - Initialized ProbabilityExtractor
00:16:58 - INFO -   Temperature: 1.0
00:16:58 - INFO -   Calibration method: None
00:16:58 - INFO - [probability_extraction] Duration: 249.72ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:16:58 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_stablelm-2-1.6b_ci_float16_base_20251207_234559.npz
00:16:58 - INFO - Initialized LACScorer
00:16:58 - INFO -   Alpha: 0.1
00:16:58 - INFO -   Target coverage: 90.0%
00:16:58 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
00:16:58 - INFO - Initialized PredictionSetGenerator
00:16:58 - INFO -   Methods: ['lac']
00:16:58 - INFO -   Alpha: 0.1
00:16:58 - INFO -   Aggregation: separate
00:16:58 - INFO - Calibrating 1 conformal predictors...
00:16:58 - INFO -   Calibrating LAC...
00:16:58 - INFO - Calibrating with 4999 samples...
00:16:58 - INFO - Calibration complete
00:16:58 - INFO -   Threshold: 0.9924
00:16:58 - INFO -   Score range: [0.0000, 1.0000]
00:16:58 - INFO - Calibration complete
00:16:58 - INFO - Generating prediction sets using LAC...
00:16:58 - INFO - Generating prediction sets for 5001 test instances...
00:16:58 - INFO - Prediction complete
00:16:58 - INFO -   Average set size: 5.25
00:16:58 - INFO -   Coverage rate: 90.00%
00:16:58 - INFO -   Meets coverage guarantee: True
00:16:58 - INFO - [PASS] Coverage guarantee met: 90.00% >= 90.00%
00:16:58 - INFO -     LAC: Acc=22.20%, CR=90.00%, SS=5.25
00:16:58 - INFO - Initialized APSScorer
00:16:58 - INFO -   Alpha: 0.1
00:16:58 - INFO -   Target coverage: 90.0%
00:16:58 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
00:16:58 - INFO - Initialized PredictionSetGenerator
00:16:58 - INFO -   Methods: ['aps']
00:16:58 - INFO -   Alpha: 0.1
00:16:58 - INFO -   Aggregation: separate
00:16:58 - INFO - Calibrating 1 conformal predictors...
00:16:58 - INFO -   Calibrating APS...
00:16:58 - INFO - Calibrating with 4999 samples...
00:16:59 - INFO - Calibration complete
00:16:59 - INFO -   Threshold: 1.0000
00:16:59 - INFO -   Score range: [0.2050, 1.0000]
00:16:59 - INFO - Calibration complete
00:16:59 - INFO - Generating prediction sets using APS...
00:16:59 - INFO - Generating prediction sets for 5001 test instances...
00:16:59 - INFO - Prediction complete
00:16:59 - INFO -   Average set size: 5.19
00:16:59 - INFO -   Coverage rate: 92.02%
00:16:59 - INFO -   Meets coverage guarantee: True
00:16:59 - INFO - [PASS] Coverage guarantee met: 92.02% >= 90.00%
00:16:59 - INFO -     APS: Acc=22.20%, CR=92.02%, SS=5.19
00:17:02 - INFO - Unloaded model: stablelm-2-1.6b_float16
00:17:02 - INFO - Checkpoint saved after completing: stablelm-2-1.6b | ci | float16
00:17:02 - INFO - 
================================================================================
00:17:02 - INFO - Run 4/5: stablelm-2-1.6b | drs | float16
00:17:02 - INFO - ================================================================================
00:17:02 - INFO - [start_stablelm-2-1.6b_drs] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 100.0%
00:17:02 - INFO - Loading drs dataset (10000 samples)...
00:17:02 - INFO - Loading HaluDial dataset with 10000 samples...
00:17:04 - INFO - Loaded 10000 HaluDial instances
00:17:04 - INFO - [dataset_loading] Duration: 1698.69ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:17:04 - INFO - Processing drs dataset to 6-option format...
00:17:35 - INFO - Processed 10000 instances for drs
00:17:35 - INFO - Option expansion statistics for drs:
00:17:35 - INFO -   Instances expanded (2→4 options): 10000
00:17:35 - INFO -   Total options sampled: 20000
00:17:35 - INFO -   Duplicate options avoided: 2
00:17:35 - INFO -   Fallback options used: 0
00:17:35 - INFO - Splitting drs dataset (calibration: 50%, test: 50%)
00:17:35 - INFO - Split complete:
00:17:35 - INFO -   Calibration: 4999 instances
00:17:35 - INFO -   Test: 5001 instances
00:17:35 - INFO - Answer distribution:
00:17:35 - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
00:17:35 - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
00:17:35 - INFO - [dataset_processing] Duration: 30687.64ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:17:35 - INFO - Initialized DemonstrationSelector
00:17:35 - INFO -   Strategy: random
00:17:35 - INFO -   Num demonstrations: 5
00:17:35 - INFO - Initialized DemonstrationManager
00:17:35 - INFO - Selecting 3 demonstrations using 'random' strategy
00:17:35 - INFO - Selected and cached 3 demonstrations for drs
00:17:35 - INFO - Loading model: stablelm-2-1.6b (float16)
00:17:35 - INFO - Loading model: stablelm-2-1.6b_float16 (stabilityai/stablelm-2-1_6b)
00:17:35 - INFO - Loading tokenizer from stabilityai/stablelm-2-1_6b
00:17:35 - INFO - Tokenizer loaded successfully
00:17:35 - INFO -   Vocab size: 100289
00:17:35 - INFO -   Padding side: left
00:17:35 - INFO -   PAD token: <|endoftext|> (ID: 100257)
00:17:35 - INFO - Loading model from stabilityai/stablelm-2-1_6b
00:17:35 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
00:17:37 - INFO - Model loaded successfully
00:17:37 - INFO -   GPU Memory: 3.07GB allocated, 3.26GB reserved

Model: stablelm-2-1.6b_float16
  ID: stabilityai/stablelm-2-1_6b
  Type: causal
  Parameters: 1,644,515,328
  Vocab size: 100,289
  Max length: 4096
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: True
00:17:37 - INFO - [model_loading] Duration: 2375.42ms | GPU Memory: 9.1MB -> 3145.8MB (delta +3136.7MB)
00:17:37 - INFO - [after_model_load_stablelm-2-1.6b] GPU State: Allocated: 3145.8MB | Reserved: 3336.0MB | Free: 78009.9MB | Utilization: 100.0%
00:17:37 - INFO - Using batch size: 32
00:17:37 - INFO -   Strategy: base
00:17:37 - INFO - Initialized PromptBuilder for task: drs
00:17:37 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
00:17:37 - INFO - Building 10000 prompts using 'base' strategy with 3 demonstrations
00:17:37 - INFO - Initialized InferenceEngine for stablelm-2-1.6b_float16
00:17:37 - INFO -   Device: cuda:0
00:17:37 - INFO -   Batch size: 32
00:17:37 - INFO -   Option tokens: {'A': 362, 'B': 426, 'C': 356, 'D': 423, 'E': 469, 'F': 435}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<03:10,  1.22s/it]Running inference:   1%|▏         | 2/157 [00:02<03:01,  1.17s/it]Running inference:   2%|▏         | 3/157 [00:03<02:58,  1.16s/it]Running inference:   3%|▎         | 4/157 [00:04<02:59,  1.17s/it]Running inference:   3%|▎         | 5/157 [00:05<03:00,  1.19s/it]Running inference:   4%|▍         | 6/157 [00:07<03:06,  1.23s/it]Running inference:   4%|▍         | 7/157 [00:08<02:57,  1.18s/it]Running inference:   5%|▌         | 8/157 [00:09<02:58,  1.20s/it]Running inference:   6%|▌         | 9/157 [00:10<02:58,  1.21s/it]Running inference:   6%|▋         | 10/157 [00:12<03:00,  1.23s/it]Running inference:   7%|▋         | 11/157 [00:13<02:55,  1.20s/it]Running inference:   8%|▊         | 12/157 [00:14<02:52,  1.19s/it]Running inference:   8%|▊         | 13/157 [00:15<02:54,  1.22s/it]Running inference:   9%|▉         | 14/157 [00:16<02:56,  1.24s/it]Running inference:  10%|▉         | 15/157 [00:18<02:56,  1.24s/it]Running inference:  10%|█         | 16/157 [00:19<02:45,  1.17s/it]Running inference:  11%|█         | 17/157 [00:20<02:41,  1.15s/it]Running inference:  11%|█▏        | 18/157 [00:21<02:41,  1.16s/it]Running inference:  12%|█▏        | 19/157 [00:22<02:41,  1.17s/it]Running inference:  13%|█▎        | 20/157 [00:23<02:37,  1.15s/it]Running inference:  13%|█▎        | 21/157 [00:24<02:35,  1.14s/it]Running inference:  14%|█▍        | 22/157 [00:26<02:33,  1.14s/it]Running inference:  15%|█▍        | 23/157 [00:27<02:36,  1.17s/it]Running inference:  15%|█▌        | 24/157 [00:28<02:37,  1.18s/it]Running inference:  16%|█▌        | 25/157 [00:29<02:33,  1.16s/it]Running inference:  17%|█▋        | 26/157 [00:30<02:37,  1.20s/it]Running inference:  17%|█▋        | 27/157 [00:32<02:37,  1.22s/it]Running inference:  18%|█▊        | 28/157 [00:33<02:37,  1.22s/it]Running inference:  18%|█▊        | 29/157 [00:34<02:36,  1.22s/it]Running inference:  19%|█▉        | 30/157 [00:35<02:35,  1.23s/it]Running inference:  20%|█▉        | 31/157 [00:37<02:34,  1.23s/it]Running inference:  20%|██        | 32/157 [00:38<02:35,  1.24s/it]Running inference:  21%|██        | 33/157 [00:39<02:35,  1.25s/it]Running inference:  22%|██▏       | 34/157 [00:40<02:34,  1.25s/it]Running inference:  22%|██▏       | 35/157 [00:42<02:29,  1.23s/it]Running inference:  23%|██▎       | 36/157 [00:43<02:27,  1.22s/it]Running inference:  24%|██▎       | 37/157 [00:44<02:23,  1.20s/it]Running inference:  24%|██▍       | 38/157 [00:45<02:19,  1.17s/it]Running inference:  25%|██▍       | 39/157 [00:46<02:19,  1.18s/it]Running inference:  25%|██▌       | 40/157 [00:47<02:20,  1.20s/it]Running inference:  26%|██▌       | 41/157 [00:49<02:24,  1.25s/it]Running inference:  27%|██▋       | 42/157 [00:50<02:25,  1.26s/it]Running inference:  27%|██▋       | 43/157 [00:51<02:16,  1.20s/it]Running inference:  28%|██▊       | 44/157 [00:52<02:17,  1.22s/it]Running inference:  29%|██▊       | 45/157 [00:54<02:13,  1.19s/it]Running inference:  29%|██▉       | 46/157 [00:55<02:11,  1.19s/it]Running inference:  30%|██▉       | 47/157 [00:56<02:15,  1.23s/it]Running inference:  31%|███       | 48/157 [00:57<02:11,  1.20s/it]Running inference:  31%|███       | 49/157 [00:59<02:15,  1.25s/it]Running inference:  32%|███▏      | 50/157 [01:00<02:15,  1.26s/it]Running inference:  32%|███▏      | 51/157 [01:01<02:17,  1.30s/it]Running inference:  33%|███▎      | 52/157 [01:02<02:14,  1.28s/it]Running inference:  34%|███▍      | 53/157 [01:04<02:10,  1.25s/it]Running inference:  34%|███▍      | 54/157 [01:05<02:08,  1.25s/it]Running inference:  35%|███▌      | 55/157 [01:06<02:08,  1.26s/it]Running inference:  36%|███▌      | 56/157 [01:07<02:04,  1.23s/it]Running inference:  36%|███▋      | 57/157 [01:08<01:59,  1.20s/it]Running inference:  37%|███▋      | 58/157 [01:10<01:57,  1.19s/it]Running inference:  38%|███▊      | 59/157 [01:11<01:53,  1.15s/it]Running inference:  38%|███▊      | 60/157 [01:12<01:46,  1.10s/it]Running inference:  39%|███▉      | 61/157 [01:13<01:47,  1.12s/it]Running inference:  39%|███▉      | 62/157 [01:14<01:48,  1.14s/it]Running inference:  40%|████      | 63/157 [01:15<01:46,  1.13s/it]Running inference:  41%|████      | 64/157 [01:16<01:46,  1.14s/it]Running inference:  41%|████▏     | 65/157 [01:17<01:43,  1.12s/it]Running inference:  42%|████▏     | 66/157 [01:19<01:43,  1.13s/it]Running inference:  43%|████▎     | 67/157 [01:20<01:42,  1.14s/it]Running inference:  43%|████▎     | 68/157 [01:21<01:40,  1.13s/it]Running inference:  44%|████▍     | 69/157 [01:22<01:35,  1.09s/it]Running inference:  45%|████▍     | 70/157 [01:23<01:36,  1.11s/it]Running inference:  45%|████▌     | 71/157 [01:24<01:34,  1.10s/it]Running inference:  46%|████▌     | 72/157 [01:25<01:35,  1.12s/it]Running inference:  46%|████▋     | 73/157 [01:26<01:35,  1.14s/it]Running inference:  47%|████▋     | 74/157 [01:28<01:37,  1.17s/it]Running inference:  48%|████▊     | 75/157 [01:29<01:35,  1.17s/it]Running inference:  48%|████▊     | 76/157 [01:30<01:34,  1.17s/it]Running inference:  49%|████▉     | 77/157 [01:31<01:34,  1.19s/it]Running inference:  50%|████▉     | 78/157 [01:32<01:31,  1.16s/it]Running inference:  50%|█████     | 79/157 [01:33<01:30,  1.16s/it]Running inference:  51%|█████     | 80/157 [01:35<01:29,  1.16s/it]Running inference:  52%|█████▏    | 81/157 [01:36<01:28,  1.16s/it]Running inference:  52%|█████▏    | 82/157 [01:37<01:26,  1.16s/it]Running inference:  53%|█████▎    | 83/157 [01:38<01:25,  1.16s/it]Running inference:  54%|█████▎    | 84/157 [01:39<01:23,  1.14s/it]Running inference:  54%|█████▍    | 85/157 [01:40<01:21,  1.13s/it]Running inference:  55%|█████▍    | 86/157 [01:42<01:23,  1.18s/it]Running inference:  55%|█████▌    | 87/157 [01:43<01:18,  1.12s/it]Running inference:  56%|█████▌    | 88/157 [01:44<01:16,  1.11s/it]Running inference:  57%|█████▋    | 89/157 [01:45<01:16,  1.13s/it]Running inference:  57%|█████▋    | 90/157 [01:46<01:17,  1.16s/it]Running inference:  58%|█████▊    | 91/157 [01:47<01:16,  1.16s/it]Running inference:  59%|█████▊    | 92/157 [01:48<01:14,  1.15s/it]Running inference:  59%|█████▉    | 93/157 [01:49<01:12,  1.13s/it]Running inference:  60%|█████▉    | 94/157 [01:51<01:10,  1.12s/it]Running inference:  61%|██████    | 95/157 [01:52<01:10,  1.14s/it]Running inference:  61%|██████    | 96/157 [01:53<01:08,  1.13s/it]Running inference:  62%|██████▏   | 97/157 [01:54<01:06,  1.11s/it]Running inference:  62%|██████▏   | 98/157 [01:55<01:07,  1.15s/it]Running inference:  63%|██████▎   | 99/157 [01:57<01:13,  1.27s/it]Running inference:  64%|██████▎   | 100/157 [01:58<01:11,  1.26s/it]Running inference:  64%|██████▍   | 101/157 [01:59<01:09,  1.24s/it]Running inference:  65%|██████▍   | 102/157 [02:00<01:07,  1.22s/it]Running inference:  66%|██████▌   | 103/157 [02:01<01:05,  1.21s/it]Running inference:  66%|██████▌   | 104/157 [02:03<01:01,  1.16s/it]Running inference:  67%|██████▋   | 105/157 [02:04<00:59,  1.14s/it]Running inference:  68%|██████▊   | 106/157 [02:05<00:57,  1.12s/it]Running inference:  68%|██████▊   | 107/157 [02:06<00:57,  1.14s/it]Running inference:  69%|██████▉   | 108/157 [02:07<00:55,  1.13s/it]Running inference:  69%|██████▉   | 109/157 [02:08<00:53,  1.11s/it]Running inference:  70%|███████   | 110/157 [02:09<00:52,  1.12s/it]Running inference:  71%|███████   | 111/157 [02:10<00:50,  1.11s/it]Running inference:  71%|███████▏  | 112/157 [02:11<00:50,  1.11s/it]Running inference:  72%|███████▏  | 113/157 [02:12<00:47,  1.08s/it]Running inference:  73%|███████▎  | 114/157 [02:14<00:46,  1.09s/it]Running inference:  73%|███████▎  | 115/157 [02:15<00:45,  1.09s/it]Running inference:  74%|███████▍  | 116/157 [02:16<00:45,  1.12s/it]Running inference:  75%|███████▍  | 117/157 [02:17<00:44,  1.11s/it]Running inference:  75%|███████▌  | 118/157 [02:18<00:44,  1.14s/it]Running inference:  76%|███████▌  | 119/157 [02:19<00:43,  1.15s/it]Running inference:  76%|███████▋  | 120/157 [02:20<00:42,  1.15s/it]Running inference:  77%|███████▋  | 121/157 [02:22<00:41,  1.16s/it]Running inference:  78%|███████▊  | 122/157 [02:23<00:38,  1.11s/it]Running inference:  78%|███████▊  | 123/157 [02:24<00:38,  1.12s/it]Running inference:  79%|███████▉  | 124/157 [02:25<00:37,  1.14s/it]Running inference:  80%|███████▉  | 125/157 [02:26<00:36,  1.14s/it]Running inference:  80%|████████  | 126/157 [02:27<00:35,  1.14s/it]Running inference:  81%|████████  | 127/157 [02:28<00:34,  1.15s/it]Running inference:  82%|████████▏ | 128/157 [02:30<00:33,  1.14s/it]Running inference:  82%|████████▏ | 129/157 [02:31<00:31,  1.13s/it]Running inference:  83%|████████▎ | 130/157 [02:32<00:30,  1.13s/it]Running inference:  83%|████████▎ | 131/157 [02:33<00:27,  1.07s/it]Running inference:  84%|████████▍ | 132/157 [02:34<00:27,  1.09s/it]Running inference:  85%|████████▍ | 133/157 [02:35<00:25,  1.08s/it]Running inference:  85%|████████▌ | 134/157 [02:36<00:25,  1.09s/it]Running inference:  86%|████████▌ | 135/157 [02:37<00:24,  1.11s/it]Running inference:  87%|████████▋ | 136/157 [02:38<00:23,  1.12s/it]Running inference:  87%|████████▋ | 137/157 [02:39<00:22,  1.11s/it]Running inference:  88%|████████▊ | 138/157 [02:40<00:21,  1.12s/it]Running inference:  89%|████████▊ | 139/157 [02:42<00:20,  1.13s/it]Running inference:  89%|████████▉ | 140/157 [02:43<00:18,  1.08s/it]Running inference:  90%|████████▉ | 141/157 [02:44<00:17,  1.08s/it]Running inference:  90%|█████████ | 142/157 [02:45<00:16,  1.11s/it]Running inference:  91%|█████████ | 143/157 [02:46<00:15,  1.12s/it]Running inference:  92%|█████████▏| 144/157 [02:47<00:14,  1.12s/it]Running inference:  92%|█████████▏| 145/157 [02:48<00:13,  1.13s/it]Running inference:  93%|█████████▎| 146/157 [02:49<00:12,  1.12s/it]Running inference:  94%|█████████▎| 147/157 [02:51<00:11,  1.12s/it]Running inference:  94%|█████████▍| 148/157 [02:52<00:10,  1.16s/it]Running inference:  95%|█████████▍| 149/157 [02:53<00:08,  1.12s/it]Running inference:  96%|█████████▌| 150/157 [02:54<00:07,  1.12s/it]Running inference:  96%|█████████▌| 151/157 [02:55<00:06,  1.13s/it]Running inference:  97%|█████████▋| 152/157 [02:56<00:05,  1.12s/it]Running inference:  97%|█████████▋| 153/157 [02:57<00:04,  1.13s/it]Running inference:  98%|█████████▊| 154/157 [02:58<00:03,  1.13s/it]Running inference:  99%|█████████▊| 155/157 [03:00<00:02,  1.13s/it]Running inference:  99%|█████████▉| 156/157 [03:01<00:01,  1.13s/it]Running inference: 100%|██████████| 157/157 [03:01<00:00,  1.15it/s]Running inference: 100%|██████████| 157/157 [03:01<00:00,  1.16s/it]
00:20:38 - INFO - [inference_calibration] Duration: 181476.12ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<03:00,  1.16s/it]Running inference:   1%|▏         | 2/157 [00:02<02:47,  1.08s/it]Running inference:   2%|▏         | 3/157 [00:03<02:49,  1.10s/it]Running inference:   3%|▎         | 4/157 [00:04<02:51,  1.12s/it]Running inference:   3%|▎         | 5/157 [00:05<02:52,  1.14s/it]Running inference:   4%|▍         | 6/157 [00:06<02:53,  1.15s/it]Running inference:   4%|▍         | 7/157 [00:07<02:49,  1.13s/it]Running inference:   5%|▌         | 8/157 [00:09<02:48,  1.13s/it]Running inference:   6%|▌         | 9/157 [00:10<02:45,  1.12s/it]Running inference:   6%|▋         | 10/157 [00:11<02:41,  1.10s/it]Running inference:   7%|▋         | 11/157 [00:12<02:36,  1.07s/it]Running inference:   8%|▊         | 12/157 [00:13<02:37,  1.09s/it]Running inference:   8%|▊         | 13/157 [00:14<02:43,  1.13s/it]Running inference:   9%|▉         | 14/157 [00:15<02:39,  1.11s/it]Running inference:  10%|▉         | 15/157 [00:16<02:38,  1.12s/it]Running inference:  10%|█         | 16/157 [00:17<02:40,  1.14s/it]Running inference:  11%|█         | 17/157 [00:19<02:40,  1.15s/it]Running inference:  11%|█▏        | 18/157 [00:20<02:36,  1.13s/it]Running inference:  12%|█▏        | 19/157 [00:21<02:30,  1.09s/it]Running inference:  13%|█▎        | 20/157 [00:22<02:26,  1.07s/it]Running inference:  13%|█▎        | 21/157 [00:23<02:26,  1.08s/it]Running inference:  14%|█▍        | 22/157 [00:24<02:28,  1.10s/it]Running inference:  15%|█▍        | 23/157 [00:25<02:31,  1.13s/it]Running inference:  15%|█▌        | 24/157 [00:26<02:33,  1.15s/it]Running inference:  16%|█▌        | 25/157 [00:28<02:32,  1.16s/it]Running inference:  17%|█▋        | 26/157 [00:29<02:32,  1.16s/it]Running inference:  17%|█▋        | 27/157 [00:30<02:33,  1.18s/it]Running inference:  18%|█▊        | 28/157 [00:31<02:29,  1.16s/it]Running inference:  18%|█▊        | 29/157 [00:32<02:25,  1.14s/it]Running inference:  19%|█▉        | 30/157 [00:33<02:27,  1.16s/it]Running inference:  20%|█▉        | 31/157 [00:35<02:29,  1.19s/it]Running inference:  20%|██        | 32/157 [00:36<02:30,  1.20s/it]Running inference:  21%|██        | 33/157 [00:37<02:30,  1.22s/it]Running inference:  22%|██▏       | 34/157 [00:38<02:28,  1.21s/it]Running inference:  22%|██▏       | 35/157 [00:39<02:25,  1.20s/it]Running inference:  23%|██▎       | 36/157 [00:41<02:24,  1.20s/it]Running inference:  24%|██▎       | 37/157 [00:42<02:17,  1.14s/it]Running inference:  24%|██▍       | 38/157 [00:43<02:15,  1.13s/it]Running inference:  25%|██▍       | 39/157 [00:44<02:12,  1.12s/it]Running inference:  25%|██▌       | 40/157 [00:45<02:11,  1.13s/it]Running inference:  26%|██▌       | 41/157 [00:46<02:12,  1.14s/it]Running inference:  27%|██▋       | 42/157 [00:47<02:13,  1.16s/it]Running inference:  27%|██▋       | 43/157 [00:49<02:12,  1.16s/it]Running inference:  28%|██▊       | 44/157 [00:50<02:11,  1.16s/it]Running inference:  29%|██▊       | 45/157 [00:51<02:09,  1.16s/it]Running inference:  29%|██▉       | 46/157 [00:52<02:03,  1.11s/it]Running inference:  30%|██▉       | 47/157 [00:53<02:04,  1.13s/it]Running inference:  31%|███       | 48/157 [00:54<02:02,  1.13s/it]Running inference:  31%|███       | 49/157 [00:55<02:02,  1.13s/it]Running inference:  32%|███▏      | 50/157 [00:57<02:06,  1.18s/it]Running inference:  32%|███▏      | 51/157 [00:58<02:06,  1.19s/it]Running inference:  33%|███▎      | 52/157 [00:59<02:06,  1.20s/it]Running inference:  34%|███▍      | 53/157 [01:00<02:05,  1.21s/it]Running inference:  34%|███▍      | 54/157 [01:01<02:03,  1.20s/it]Running inference:  35%|███▌      | 55/157 [01:02<01:55,  1.14s/it]Running inference:  36%|███▌      | 56/157 [01:03<01:53,  1.12s/it]Running inference:  36%|███▋      | 57/157 [01:05<01:55,  1.15s/it]Running inference:  37%|███▋      | 58/157 [01:06<01:54,  1.16s/it]Running inference:  38%|███▊      | 59/157 [01:07<01:52,  1.14s/it]Running inference:  38%|███▊      | 60/157 [01:08<01:50,  1.14s/it]Running inference:  39%|███▉      | 61/157 [01:09<01:51,  1.16s/it]Running inference:  39%|███▉      | 62/157 [01:10<01:48,  1.14s/it]Running inference:  40%|████      | 63/157 [01:12<01:48,  1.16s/it]Running inference:  41%|████      | 64/157 [01:13<01:42,  1.10s/it]Running inference:  41%|████▏     | 65/157 [01:14<01:43,  1.13s/it]Running inference:  42%|████▏     | 66/157 [01:15<01:43,  1.14s/it]Running inference:  43%|████▎     | 67/157 [01:16<01:43,  1.15s/it]Running inference:  43%|████▎     | 68/157 [01:17<01:41,  1.14s/it]Running inference:  44%|████▍     | 69/157 [01:18<01:41,  1.15s/it]Running inference:  45%|████▍     | 70/157 [01:20<01:41,  1.17s/it]Running inference:  45%|████▌     | 71/157 [01:21<01:43,  1.21s/it]Running inference:  46%|████▌     | 72/157 [01:22<01:41,  1.19s/it]Running inference:  46%|████▋     | 73/157 [01:23<01:38,  1.17s/it]Running inference:  47%|████▋     | 74/157 [01:24<01:38,  1.19s/it]Running inference:  48%|████▊     | 75/157 [01:26<01:36,  1.17s/it]Running inference:  48%|████▊     | 76/157 [01:27<01:38,  1.22s/it]Running inference:  49%|████▉     | 77/157 [01:28<01:34,  1.18s/it]Running inference:  50%|████▉     | 78/157 [01:29<01:31,  1.15s/it]Running inference:  50%|█████     | 79/157 [01:30<01:30,  1.16s/it]Running inference:  51%|█████     | 80/157 [01:31<01:28,  1.15s/it]Running inference:  52%|█████▏    | 81/157 [01:32<01:22,  1.09s/it]Running inference:  52%|█████▏    | 82/157 [01:33<01:20,  1.07s/it]Running inference:  53%|█████▎    | 83/157 [01:35<01:21,  1.10s/it]Running inference:  54%|█████▎    | 84/157 [01:36<01:22,  1.13s/it]Running inference:  54%|█████▍    | 85/157 [01:37<01:23,  1.16s/it]Running inference:  55%|█████▍    | 86/157 [01:38<01:22,  1.17s/it]Running inference:  55%|█████▌    | 87/157 [01:39<01:20,  1.15s/it]Running inference:  56%|█████▌    | 88/157 [01:40<01:20,  1.16s/it]Running inference:  57%|█████▋    | 89/157 [01:42<01:17,  1.14s/it]Running inference:  57%|█████▋    | 90/157 [01:43<01:14,  1.10s/it]Running inference:  58%|█████▊    | 91/157 [01:44<01:11,  1.08s/it]Running inference:  59%|█████▊    | 92/157 [01:45<01:10,  1.09s/it]Running inference:  59%|█████▉    | 93/157 [01:46<01:11,  1.12s/it]Running inference:  60%|█████▉    | 94/157 [01:47<01:12,  1.14s/it]Running inference:  61%|██████    | 95/157 [01:48<01:11,  1.15s/it]Running inference:  61%|██████    | 96/157 [01:49<01:10,  1.15s/it]Running inference:  62%|██████▏   | 97/157 [01:51<01:08,  1.14s/it]Running inference:  62%|██████▏   | 98/157 [01:52<01:06,  1.13s/it]Running inference:  63%|██████▎   | 99/157 [01:53<01:03,  1.09s/it]Running inference:  64%|██████▎   | 100/157 [01:54<01:03,  1.12s/it]Running inference:  64%|██████▍   | 101/157 [01:55<01:03,  1.13s/it]Running inference:  65%|██████▍   | 102/157 [01:56<01:02,  1.13s/it]Running inference:  66%|██████▌   | 103/157 [01:57<01:02,  1.15s/it]Running inference:  66%|██████▌   | 104/157 [01:58<01:01,  1.16s/it]Running inference:  67%|██████▋   | 105/157 [02:00<00:59,  1.15s/it]Running inference:  68%|██████▊   | 106/157 [02:01<00:58,  1.15s/it]Running inference:  68%|██████▊   | 107/157 [02:02<00:56,  1.13s/it]Running inference:  69%|██████▉   | 108/157 [02:03<00:53,  1.09s/it]Running inference:  69%|██████▉   | 109/157 [02:04<00:52,  1.09s/it]Running inference:  70%|███████   | 110/157 [02:05<00:52,  1.11s/it]Running inference:  71%|███████   | 111/157 [02:06<00:52,  1.14s/it]Running inference:  71%|███████▏  | 112/157 [02:07<00:51,  1.15s/it]Running inference:  72%|███████▏  | 113/157 [02:09<00:52,  1.19s/it]Running inference:  73%|███████▎  | 114/157 [02:10<00:51,  1.19s/it]Running inference:  73%|███████▎  | 115/157 [02:11<00:50,  1.19s/it]Running inference:  74%|███████▍  | 116/157 [02:12<00:46,  1.14s/it]Running inference:  75%|███████▍  | 117/157 [02:13<00:45,  1.13s/it]Running inference:  75%|███████▌  | 118/157 [02:14<00:45,  1.16s/it]Running inference:  76%|███████▌  | 119/157 [02:16<00:44,  1.17s/it]Running inference:  76%|███████▋  | 120/157 [02:17<00:43,  1.17s/it]Running inference:  77%|███████▋  | 121/157 [02:18<00:41,  1.17s/it]Running inference:  78%|███████▊  | 122/157 [02:19<00:41,  1.19s/it]Running inference:  78%|███████▊  | 123/157 [02:20<00:40,  1.20s/it]Running inference:  79%|███████▉  | 124/157 [02:22<00:40,  1.22s/it]Running inference:  80%|███████▉  | 125/157 [02:23<00:37,  1.17s/it]Running inference:  80%|████████  | 126/157 [02:24<00:35,  1.13s/it]Running inference:  81%|████████  | 127/157 [02:25<00:34,  1.15s/it]Running inference:  82%|████████▏ | 128/157 [02:26<00:33,  1.16s/it]Running inference:  82%|████████▏ | 129/157 [02:27<00:32,  1.16s/it]Running inference:  83%|████████▎ | 130/157 [02:29<00:31,  1.17s/it]Running inference:  83%|████████▎ | 131/157 [02:30<00:30,  1.16s/it]Running inference:  84%|████████▍ | 132/157 [02:31<00:29,  1.17s/it]Running inference:  85%|████████▍ | 133/157 [02:32<00:27,  1.14s/it]Running inference:  85%|████████▌ | 134/157 [02:33<00:25,  1.11s/it]Running inference:  86%|████████▌ | 135/157 [02:34<00:23,  1.08s/it]Running inference:  87%|████████▋ | 136/157 [02:35<00:22,  1.08s/it]Running inference:  87%|████████▋ | 137/157 [02:36<00:21,  1.09s/it]Running inference:  88%|████████▊ | 138/157 [02:37<00:20,  1.10s/it]Running inference:  89%|████████▊ | 139/157 [02:38<00:19,  1.09s/it]Running inference:  89%|████████▉ | 140/157 [02:40<00:18,  1.10s/it]Running inference:  90%|████████▉ | 141/157 [02:41<00:17,  1.12s/it]Running inference:  90%|█████████ | 142/157 [02:42<00:17,  1.15s/it]Running inference:  91%|█████████ | 143/157 [02:43<00:15,  1.10s/it]Running inference:  92%|█████████▏| 144/157 [02:44<00:14,  1.09s/it]Running inference:  92%|█████████▏| 145/157 [02:45<00:13,  1.10s/it]Running inference:  93%|█████████▎| 146/157 [02:46<00:12,  1.11s/it]Running inference:  94%|█████████▎| 147/157 [02:47<00:11,  1.11s/it]Running inference:  94%|█████████▍| 148/157 [02:48<00:10,  1.12s/it]Running inference:  95%|█████████▍| 149/157 [02:50<00:08,  1.11s/it]Running inference:  96%|█████████▌| 150/157 [02:51<00:07,  1.12s/it]Running inference:  96%|█████████▌| 151/157 [02:52<00:06,  1.13s/it]Running inference:  97%|█████████▋| 152/157 [02:53<00:05,  1.09s/it]Running inference:  97%|█████████▋| 153/157 [02:54<00:04,  1.09s/it]Running inference:  98%|█████████▊| 154/157 [02:55<00:03,  1.12s/it]Running inference:  99%|█████████▊| 155/157 [02:56<00:02,  1.15s/it]Running inference:  99%|█████████▉| 156/157 [02:58<00:01,  1.15s/it]Running inference: 100%|██████████| 157/157 [02:58<00:00,  1.11it/s]Running inference: 100%|██████████| 157/157 [02:58<00:00,  1.14s/it]
00:23:37 - INFO - [inference_test] Duration: 178358.73ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:23:37 - INFO -     Inference: 359.84s for 10000 samples (27.79 samples/sec)
00:23:37 - INFO - Initialized ProbabilityExtractor
00:23:37 - INFO -   Temperature: 1.0
00:23:37 - INFO -   Calibration method: None
00:23:37 - INFO - [probability_extraction] Duration: 484.31ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:23:37 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_stablelm-2-1.6b_drs_float16_base_20251207_234559.npz
00:23:37 - INFO - Initialized LACScorer
00:23:37 - INFO -   Alpha: 0.1
00:23:37 - INFO -   Target coverage: 90.0%
00:23:37 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
00:23:37 - INFO - Initialized PredictionSetGenerator
00:23:37 - INFO -   Methods: ['lac']
00:23:37 - INFO -   Alpha: 0.1
00:23:37 - INFO -   Aggregation: separate
00:23:37 - INFO - Calibrating 1 conformal predictors...
00:23:37 - INFO -   Calibrating LAC...
00:23:37 - INFO - Calibrating with 4999 samples...
00:23:37 - INFO - Calibration complete
00:23:37 - INFO -   Threshold: 0.9895
00:23:37 - INFO -   Score range: [0.0000, 1.0000]
00:23:37 - INFO - Calibration complete
00:23:37 - INFO - Generating prediction sets using LAC...
00:23:37 - INFO - Generating prediction sets for 5001 test instances...
00:23:37 - INFO - Prediction complete
00:23:37 - INFO -   Average set size: 5.24
00:23:37 - INFO -   Coverage rate: 89.52%
00:23:37 - INFO -   Meets coverage guarantee: False
00:23:37 - WARNING - ✗ Coverage guarantee NOT met: 89.52% < 90.00%
00:23:37 - WARNING - LAC does not meet coverage guarantee: 89.52% < 90.00%
00:23:37 - INFO -     LAC: Acc=21.28%, CR=89.52%, SS=5.24
00:23:37 - INFO - Initialized APSScorer
00:23:37 - INFO -   Alpha: 0.1
00:23:37 - INFO -   Target coverage: 90.0%
00:23:37 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
00:23:37 - INFO - Initialized PredictionSetGenerator
00:23:37 - INFO -   Methods: ['aps']
00:23:37 - INFO -   Alpha: 0.1
00:23:37 - INFO -   Aggregation: separate
00:23:37 - INFO - Calibrating 1 conformal predictors...
00:23:37 - INFO -   Calibrating APS...
00:23:37 - INFO - Calibrating with 4999 samples...
00:23:37 - INFO - Calibration complete
00:23:37 - INFO -   Threshold: 1.0000
00:23:37 - INFO -   Score range: [0.1890, 1.0000]
00:23:37 - INFO - Calibration complete
00:23:37 - INFO - Generating prediction sets using APS...
00:23:37 - INFO - Generating prediction sets for 5001 test instances...
00:23:38 - INFO - Prediction complete
00:23:38 - INFO -   Average set size: 4.89
00:23:38 - INFO -   Coverage rate: 89.98%
00:23:38 - INFO -   Meets coverage guarantee: False
00:23:38 - WARNING - ✗ Coverage guarantee NOT met: 89.98% < 90.00%
00:23:38 - WARNING - APS does not meet coverage guarantee: 89.98% < 90.00%
00:23:38 - INFO -     APS: Acc=21.28%, CR=89.98%, SS=4.89
00:23:41 - INFO - Unloaded model: stablelm-2-1.6b_float16
00:23:41 - INFO - Checkpoint saved after completing: stablelm-2-1.6b | drs | float16
00:23:41 - INFO - 
================================================================================
00:23:41 - INFO - Run 5/5: stablelm-2-1.6b | ds | float16
00:23:41 - INFO - ================================================================================
00:23:41 - INFO - [start_stablelm-2-1.6b_ds] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 100.0%
00:23:41 - INFO - Loading ds dataset (10000 samples)...
00:23:41 - INFO - Loading HaluSum dataset with 10000 samples...
00:23:42 - INFO - Loaded 10000 HaluSum instances
00:23:42 - INFO - [dataset_loading] Duration: 781.38ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:23:42 - INFO - Processing ds dataset to 6-option format...
00:24:16 - INFO - Processed 10000 instances for ds
00:24:16 - INFO - Option expansion statistics for ds:
00:24:16 - INFO -   Instances expanded (2→4 options): 10000
00:24:16 - INFO -   Total options sampled: 20000
00:24:16 - INFO -   Duplicate options avoided: 0
00:24:16 - INFO -   Fallback options used: 0
00:24:16 - INFO - Splitting ds dataset (calibration: 50%, test: 50%)
00:24:16 - INFO - Split complete:
00:24:16 - INFO -   Calibration: 4999 instances
00:24:16 - INFO -   Test: 5001 instances
00:24:16 - INFO - Answer distribution:
00:24:16 - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
00:24:16 - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
00:24:16 - INFO - [dataset_processing] Duration: 34517.60ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:24:16 - INFO - Initialized DemonstrationSelector
00:24:16 - INFO -   Strategy: random
00:24:16 - INFO -   Num demonstrations: 5
00:24:16 - INFO - Initialized DemonstrationManager
00:24:16 - INFO - Selecting 1 demonstrations using 'random' strategy
00:24:16 - INFO - Selected and cached 1 demonstrations for ds
00:24:16 - INFO - Loading model: stablelm-2-1.6b (float16)
00:24:16 - INFO - Loading model: stablelm-2-1.6b_float16 (stabilityai/stablelm-2-1_6b)
00:24:16 - INFO - Loading tokenizer from stabilityai/stablelm-2-1_6b
00:24:17 - INFO - Tokenizer loaded successfully
00:24:17 - INFO -   Vocab size: 100289
00:24:17 - INFO -   Padding side: left
00:24:17 - INFO -   PAD token: <|endoftext|> (ID: 100257)
00:24:17 - INFO - Loading model from stabilityai/stablelm-2-1_6b
00:24:17 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
00:24:19 - INFO - Model loaded successfully
00:24:19 - INFO -   GPU Memory: 3.07GB allocated, 3.26GB reserved

Model: stablelm-2-1.6b_float16
  ID: stabilityai/stablelm-2-1_6b
  Type: causal
  Parameters: 1,644,515,328
  Vocab size: 100,289
  Max length: 4096
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: True
00:24:19 - INFO - [model_loading] Duration: 2409.42ms | GPU Memory: 9.1MB -> 3145.8MB (delta +3136.7MB)
00:24:19 - INFO - [after_model_load_stablelm-2-1.6b] GPU State: Allocated: 3145.8MB | Reserved: 3336.0MB | Free: 78009.9MB | Utilization: 100.0%
00:24:19 - INFO - Using batch size: 32
00:24:19 - INFO -   Strategy: base
00:24:19 - INFO - Initialized PromptBuilder for task: ds
00:24:19 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
00:24:19 - INFO - Building 10000 prompts using 'base' strategy with 1 demonstrations
00:24:19 - INFO - Initialized InferenceEngine for stablelm-2-1.6b_float16
00:24:19 - INFO -   Device: cuda:0
00:24:19 - INFO -   Batch size: 32
00:24:19 - INFO -   Option tokens: {'A': 362, 'B': 426, 'C': 356, 'D': 423, 'E': 469, 'F': 435}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:04<11:22,  4.38s/it]Running inference:   1%|▏         | 2/157 [00:08<11:29,  4.45s/it]Running inference:   2%|▏         | 3/157 [00:13<11:26,  4.46s/it]Running inference:   3%|▎         | 4/157 [00:17<11:12,  4.40s/it]Running inference:   3%|▎         | 5/157 [00:22<11:12,  4.42s/it]Running inference:   4%|▍         | 6/157 [00:26<11:02,  4.39s/it]Running inference:   4%|▍         | 7/157 [00:30<11:03,  4.42s/it]Running inference:   5%|▌         | 8/157 [00:35<11:00,  4.44s/it]Running inference:   6%|▌         | 9/157 [00:39<10:57,  4.44s/it]Running inference:   6%|▋         | 10/157 [00:44<11:10,  4.56s/it]Running inference:   7%|▋         | 11/157 [00:49<10:57,  4.51s/it]Running inference:   8%|▊         | 12/157 [00:53<10:52,  4.50s/it]Running inference:   8%|▊         | 13/157 [00:57<10:45,  4.48s/it]Running inference:   9%|▉         | 14/157 [01:02<10:40,  4.48s/it]Running inference:  10%|▉         | 15/157 [01:06<10:35,  4.48s/it]Running inference:  10%|█         | 16/157 [01:11<10:27,  4.45s/it]Running inference:  11%|█         | 17/157 [01:15<10:22,  4.45s/it]Running inference:  11%|█▏        | 18/157 [01:20<10:15,  4.43s/it]Running inference:  12%|█▏        | 19/157 [01:25<10:32,  4.58s/it]Running inference:  13%|█▎        | 20/157 [01:30<10:44,  4.70s/it]Running inference:  13%|█▎        | 21/157 [01:34<10:40,  4.71s/it]Running inference:  14%|█▍        | 22/157 [01:39<10:36,  4.72s/it]Running inference:  15%|█▍        | 23/157 [01:43<10:19,  4.62s/it]Running inference:  15%|█▌        | 24/157 [01:48<10:14,  4.62s/it]Running inference:  16%|█▌        | 25/157 [01:53<10:10,  4.62s/it]Running inference:  17%|█▋        | 26/157 [01:57<10:13,  4.68s/it]Running inference:  17%|█▋        | 27/157 [02:02<10:14,  4.73s/it]Running inference:  18%|█▊        | 28/157 [02:07<10:07,  4.71s/it]Running inference:  18%|█▊        | 29/157 [02:12<10:05,  4.73s/it]Running inference:  19%|█▉        | 30/157 [02:16<09:55,  4.69s/it]Running inference:  20%|█▉        | 31/157 [02:21<09:46,  4.65s/it]Running inference:  20%|██        | 32/157 [02:26<09:44,  4.68s/it]Running inference:  21%|██        | 33/157 [02:30<09:39,  4.67s/it]Running inference:  22%|██▏       | 34/157 [02:35<09:36,  4.69s/it]Running inference:  22%|██▏       | 35/157 [02:39<09:21,  4.60s/it]Running inference:  23%|██▎       | 36/157 [02:44<09:16,  4.60s/it]Running inference:  24%|██▎       | 37/157 [02:49<09:22,  4.68s/it]Running inference:  24%|██▍       | 38/157 [02:54<09:23,  4.74s/it]Running inference:  25%|██▍       | 39/157 [02:58<09:13,  4.69s/it]Running inference:  25%|██▌       | 40/157 [03:03<09:03,  4.65s/it]Running inference:  26%|██▌       | 41/157 [03:08<08:59,  4.65s/it]Running inference:  27%|██▋       | 42/157 [03:12<08:51,  4.62s/it]Running inference:  27%|██▋       | 43/157 [03:17<08:53,  4.68s/it]Running inference:  28%|██▊       | 44/157 [03:22<08:48,  4.67s/it]Running inference:  29%|██▊       | 45/157 [03:26<08:32,  4.57s/it]Running inference:  29%|██▉       | 46/157 [03:30<08:25,  4.55s/it]Running inference:  30%|██▉       | 47/157 [03:35<08:13,  4.48s/it]Running inference:  31%|███       | 48/157 [03:39<08:09,  4.49s/it]Running inference:  31%|███       | 49/157 [03:44<08:04,  4.48s/it]Running inference:  32%|███▏      | 50/157 [03:48<07:57,  4.47s/it]Running inference:  32%|███▏      | 51/157 [03:53<07:53,  4.46s/it]Running inference:  33%|███▎      | 52/157 [03:57<07:43,  4.42s/it]Running inference:  34%|███▍      | 53/157 [04:01<07:40,  4.43s/it]Running inference:  34%|███▍      | 54/157 [04:06<07:32,  4.39s/it]Running inference:  35%|███▌      | 55/157 [04:10<07:30,  4.41s/it]Running inference:  36%|███▌      | 56/157 [04:15<07:42,  4.58s/it]Running inference:  36%|███▋      | 57/157 [04:20<07:35,  4.55s/it]Running inference:  37%|███▋      | 58/157 [04:24<07:37,  4.63s/it]Running inference:  38%|███▊      | 59/157 [04:29<07:23,  4.53s/it]Running inference:  38%|███▊      | 60/157 [04:33<07:17,  4.51s/it]Running inference:  39%|███▉      | 61/157 [04:38<07:08,  4.46s/it]Running inference:  39%|███▉      | 62/157 [04:42<07:04,  4.47s/it]Running inference:  40%|████      | 63/157 [04:47<07:04,  4.52s/it]Running inference:  41%|████      | 64/157 [04:51<07:02,  4.54s/it]Running inference:  41%|████▏     | 65/157 [04:56<06:58,  4.55s/it]Running inference:  42%|████▏     | 66/157 [05:00<06:51,  4.52s/it]Running inference:  43%|████▎     | 67/157 [05:05<06:45,  4.51s/it]Running inference:  43%|████▎     | 68/157 [05:09<06:42,  4.53s/it]Running inference:  44%|████▍     | 69/157 [05:14<06:35,  4.50s/it]Running inference:  45%|████▍     | 70/157 [05:18<06:35,  4.54s/it]Running inference:  45%|████▌     | 71/157 [05:23<06:25,  4.48s/it]Running inference:  46%|████▌     | 72/157 [05:27<06:20,  4.47s/it]Running inference:  46%|████▋     | 73/157 [05:31<06:11,  4.43s/it]Running inference:  47%|████▋     | 74/157 [05:36<06:14,  4.51s/it]Running inference:  48%|████▊     | 75/157 [05:41<06:13,  4.56s/it]Running inference:  48%|████▊     | 76/157 [05:45<06:02,  4.48s/it]Running inference:  49%|████▉     | 77/157 [05:50<05:58,  4.48s/it]Running inference:  50%|████▉     | 78/157 [05:54<05:49,  4.43s/it]Running inference:  50%|█████     | 79/157 [05:58<05:47,  4.46s/it]Running inference:  51%|█████     | 80/157 [06:03<05:40,  4.42s/it]Running inference:  52%|█████▏    | 81/157 [06:07<05:37,  4.43s/it]Running inference:  52%|█████▏    | 82/157 [06:12<05:34,  4.46s/it]Running inference:  53%|█████▎    | 83/157 [06:16<05:31,  4.48s/it]Running inference:  54%|█████▎    | 84/157 [06:21<05:27,  4.48s/it]Running inference:  54%|█████▍    | 85/157 [06:26<05:28,  4.56s/it]Running inference:  55%|█████▍    | 86/157 [06:31<05:32,  4.68s/it]Running inference:  55%|█████▌    | 87/157 [06:35<05:31,  4.74s/it]Running inference:  56%|█████▌    | 88/157 [06:40<05:22,  4.68s/it]Running inference:  57%|█████▋    | 89/157 [06:44<05:15,  4.64s/it]Running inference:  57%|█████▋    | 90/157 [06:49<05:09,  4.62s/it]Running inference:  58%|█████▊    | 91/157 [06:54<05:10,  4.70s/it]Running inference:  59%|█████▊    | 92/157 [06:59<05:07,  4.74s/it]Running inference:  59%|█████▉    | 93/157 [07:03<04:54,  4.61s/it]Running inference:  60%|█████▉    | 94/157 [07:08<04:47,  4.57s/it]Running inference:  61%|██████    | 95/157 [07:12<04:43,  4.58s/it]Running inference:  61%|██████    | 96/157 [07:17<04:40,  4.60s/it]Running inference:  62%|██████▏   | 97/157 [07:21<04:32,  4.55s/it]Running inference:  62%|██████▏   | 98/157 [07:26<04:31,  4.59s/it]Running inference:  63%|██████▎   | 99/157 [07:31<04:30,  4.66s/it]Running inference:  64%|██████▎   | 100/157 [07:35<04:24,  4.65s/it]Running inference:  64%|██████▍   | 101/157 [07:40<04:21,  4.68s/it]Running inference:  65%|██████▍   | 102/157 [07:45<04:13,  4.60s/it]Running inference:  66%|██████▌   | 103/157 [07:49<04:07,  4.59s/it]Running inference:  66%|██████▌   | 104/157 [07:54<04:01,  4.56s/it]Running inference:  67%|██████▋   | 105/157 [07:58<03:53,  4.50s/it]Running inference:  68%|██████▊   | 106/157 [08:02<03:48,  4.48s/it]Running inference:  68%|██████▊   | 107/157 [08:07<03:41,  4.43s/it]Running inference:  69%|██████▉   | 108/157 [08:11<03:37,  4.44s/it]Running inference:  69%|██████▉   | 109/157 [08:15<03:31,  4.40s/it]Running inference:  70%|███████   | 110/157 [08:20<03:27,  4.42s/it]Running inference:  71%|███████   | 111/157 [08:24<03:24,  4.44s/it]Running inference:  71%|███████▏  | 112/157 [08:29<03:17,  4.39s/it]Running inference:  72%|███████▏  | 113/157 [08:33<03:14,  4.42s/it]Running inference:  73%|███████▎  | 114/157 [08:38<03:13,  4.50s/it]Running inference:  73%|███████▎  | 115/157 [08:42<03:09,  4.50s/it]Running inference:  74%|███████▍  | 116/157 [08:47<03:06,  4.54s/it]Running inference:  75%|███████▍  | 117/157 [08:52<03:04,  4.60s/it]Running inference:  75%|███████▌  | 118/157 [08:56<02:57,  4.56s/it]Running inference:  76%|███████▌  | 119/157 [09:01<02:50,  4.49s/it]Running inference:  76%|███████▋  | 120/157 [09:05<02:45,  4.48s/it]Running inference:  77%|███████▋  | 121/157 [09:09<02:39,  4.43s/it]Running inference:  78%|███████▊  | 122/157 [09:14<02:35,  4.44s/it]Running inference:  78%|███████▊  | 123/157 [09:18<02:32,  4.48s/it]Running inference:  79%|███████▉  | 124/157 [09:23<02:26,  4.43s/it]Running inference:  80%|███████▉  | 125/157 [09:27<02:22,  4.44s/it]Running inference:  80%|████████  | 126/157 [09:31<02:16,  4.42s/it]Running inference:  81%|████████  | 127/157 [09:36<02:12,  4.43s/it]Running inference:  82%|████████▏ | 128/157 [09:40<02:07,  4.41s/it]Running inference:  82%|████████▏ | 129/157 [09:45<02:03,  4.42s/it]Running inference:  83%|████████▎ | 130/157 [09:49<01:59,  4.44s/it]Running inference:  83%|████████▎ | 131/157 [09:54<01:54,  4.40s/it]Running inference:  84%|████████▍ | 132/157 [09:58<01:50,  4.43s/it]Running inference:  85%|████████▍ | 133/157 [10:02<01:45,  4.39s/it]Running inference:  85%|████████▌ | 134/157 [10:07<01:41,  4.42s/it]Running inference:  86%|████████▌ | 135/157 [10:11<01:36,  4.39s/it]Running inference:  87%|████████▋ | 136/157 [10:16<01:32,  4.41s/it]Running inference:  87%|████████▋ | 137/157 [10:20<01:30,  4.52s/it]Running inference:  88%|████████▊ | 138/157 [10:25<01:26,  4.58s/it]Running inference:  89%|████████▊ | 139/157 [10:30<01:23,  4.63s/it]Running inference:  89%|████████▉ | 140/157 [10:34<01:17,  4.56s/it]Running inference:  90%|████████▉ | 141/157 [10:39<01:12,  4.56s/it]Running inference:  90%|█████████ | 142/157 [10:44<01:08,  4.60s/it]Running inference:  91%|█████████ | 143/157 [10:48<01:03,  4.51s/it]Running inference:  92%|█████████▏| 144/157 [10:53<01:00,  4.63s/it]Running inference:  92%|█████████▏| 145/157 [10:57<00:55,  4.67s/it]Running inference:  93%|█████████▎| 146/157 [11:02<00:52,  4.74s/it]Running inference:  94%|█████████▎| 147/157 [11:07<00:47,  4.77s/it]Running inference:  94%|█████████▍| 148/157 [11:12<00:42,  4.73s/it]Running inference:  95%|█████████▍| 149/157 [11:16<00:37,  4.69s/it]Running inference:  96%|█████████▌| 150/157 [11:21<00:32,  4.69s/it]Running inference:  96%|█████████▌| 151/157 [11:26<00:28,  4.70s/it]Running inference:  97%|█████████▋| 152/157 [11:30<00:23,  4.64s/it]Running inference:  97%|█████████▋| 153/157 [11:35<00:18,  4.59s/it]Running inference:  98%|█████████▊| 154/157 [11:39<00:13,  4.57s/it]Running inference:  99%|█████████▊| 155/157 [11:44<00:09,  4.59s/it]Running inference:  99%|█████████▉| 156/157 [11:49<00:04,  4.62s/it]Running inference: 100%|██████████| 157/157 [11:50<00:00,  3.54s/it]Running inference: 100%|██████████| 157/157 [11:50<00:00,  4.52s/it]
00:36:09 - INFO - [inference_calibration] Duration: 710213.52ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:04<11:43,  4.51s/it]Running inference:   1%|▏         | 2/157 [00:09<12:04,  4.67s/it]Running inference:   2%|▏         | 3/157 [00:13<11:50,  4.61s/it]Running inference:   3%|▎         | 4/157 [00:18<11:56,  4.68s/it]Running inference:   3%|▎         | 5/157 [00:23<11:55,  4.71s/it]Running inference:   4%|▍         | 6/157 [00:27<11:34,  4.60s/it]Running inference:   4%|▍         | 7/157 [00:32<11:25,  4.57s/it]Running inference:   5%|▌         | 8/157 [00:36<11:10,  4.50s/it]Running inference:   6%|▌         | 9/157 [00:41<11:04,  4.49s/it]Running inference:   6%|▋         | 10/157 [00:45<10:49,  4.42s/it]Running inference:   7%|▋         | 11/157 [00:49<10:50,  4.46s/it]Running inference:   8%|▊         | 12/157 [00:54<10:57,  4.54s/it]Running inference:   8%|▊         | 13/157 [00:58<10:43,  4.47s/it]Running inference:   9%|▉         | 14/157 [01:03<10:40,  4.48s/it]Running inference:  10%|▉         | 15/157 [01:07<10:28,  4.43s/it]Running inference:  10%|█         | 16/157 [01:12<10:25,  4.44s/it]Running inference:  11%|█         | 17/157 [01:17<10:40,  4.57s/it]Running inference:  11%|█▏        | 18/157 [01:21<10:27,  4.51s/it]Running inference:  12%|█▏        | 19/157 [01:26<10:32,  4.59s/it]Running inference:  13%|█▎        | 20/157 [01:30<10:18,  4.51s/it]Running inference:  13%|█▎        | 21/157 [01:35<10:18,  4.54s/it]Running inference:  14%|█▍        | 22/157 [01:39<10:17,  4.57s/it]Running inference:  15%|█▍        | 23/157 [01:44<10:16,  4.60s/it]Running inference:  15%|█▌        | 24/157 [01:48<10:08,  4.57s/it]Running inference:  16%|█▌        | 25/157 [01:53<09:58,  4.54s/it]Running inference:  17%|█▋        | 26/157 [01:58<10:05,  4.62s/it]Running inference:  17%|█▋        | 27/157 [02:02<09:52,  4.56s/it]Running inference:  18%|█▊        | 28/157 [02:07<09:50,  4.58s/it]Running inference:  18%|█▊        | 29/157 [02:11<09:45,  4.57s/it]Running inference:  19%|█▉        | 30/157 [02:16<09:35,  4.53s/it]Running inference:  20%|█▉        | 31/157 [02:20<09:29,  4.52s/it]Running inference:  20%|██        | 32/157 [02:25<09:16,  4.45s/it]Running inference:  21%|██        | 33/157 [02:29<09:11,  4.45s/it]Running inference:  22%|██▏       | 34/157 [02:33<09:07,  4.45s/it]Running inference:  22%|██▏       | 35/157 [02:38<09:04,  4.46s/it]Running inference:  23%|██▎       | 36/157 [02:43<09:07,  4.52s/it]Running inference:  24%|██▎       | 37/157 [02:47<08:57,  4.48s/it]Running inference:  24%|██▍       | 38/157 [02:51<08:52,  4.47s/it]Running inference:  25%|██▍       | 39/157 [02:56<08:46,  4.46s/it]Running inference:  25%|██▌       | 40/157 [03:01<08:54,  4.57s/it]Running inference:  26%|██▌       | 41/157 [03:05<08:47,  4.55s/it]Running inference:  27%|██▋       | 42/157 [03:10<08:39,  4.51s/it]Running inference:  27%|██▋       | 43/157 [03:14<08:40,  4.57s/it]Running inference:  28%|██▊       | 44/157 [03:19<08:27,  4.49s/it]Running inference:  29%|██▊       | 45/157 [03:23<08:29,  4.55s/it]Running inference:  29%|██▉       | 46/157 [03:28<08:22,  4.53s/it]Running inference:  30%|██▉       | 47/157 [03:32<08:20,  4.55s/it]Running inference:  31%|███       | 48/157 [03:37<08:14,  4.54s/it]Running inference:  31%|███       | 49/157 [03:41<08:08,  4.52s/it]Running inference:  32%|███▏      | 50/157 [03:46<08:06,  4.55s/it]Running inference:  32%|███▏      | 51/157 [03:50<07:58,  4.51s/it]Running inference:  33%|███▎      | 52/157 [03:55<08:04,  4.61s/it]Running inference:  34%|███▍      | 53/157 [04:00<08:00,  4.62s/it]Running inference:  34%|███▍      | 54/157 [04:04<07:51,  4.57s/it]Running inference:  35%|███▌      | 55/157 [04:09<07:42,  4.54s/it]Running inference:  36%|███▌      | 56/157 [04:13<07:32,  4.48s/it]Running inference:  36%|███▋      | 57/157 [04:18<07:34,  4.54s/it]Running inference:  37%|███▋      | 58/157 [04:22<07:29,  4.54s/it]Running inference:  38%|███▊      | 59/157 [04:27<07:35,  4.65s/it]Running inference:  38%|███▊      | 60/157 [04:32<07:39,  4.74s/it]Running inference:  39%|███▉      | 61/157 [04:37<07:35,  4.75s/it]Running inference:  39%|███▉      | 62/157 [04:42<07:34,  4.78s/it]Running inference:  40%|████      | 63/157 [04:47<07:26,  4.75s/it]Running inference:  41%|████      | 64/157 [04:51<07:18,  4.72s/it]Running inference:  41%|████▏     | 65/157 [04:56<07:18,  4.77s/it]Running inference:  42%|████▏     | 66/157 [05:01<07:07,  4.70s/it]Running inference:  43%|████▎     | 67/157 [05:05<07:05,  4.73s/it]Running inference:  43%|████▎     | 68/157 [05:10<06:55,  4.66s/it]Running inference:  44%|████▍     | 69/157 [05:15<06:49,  4.66s/it]Running inference:  45%|████▍     | 70/157 [05:19<06:41,  4.61s/it]Running inference:  45%|████▌     | 71/157 [05:24<06:42,  4.68s/it]Running inference:  46%|████▌     | 72/157 [05:29<06:35,  4.66s/it]Running inference:  46%|████▋     | 73/157 [05:33<06:28,  4.63s/it]Running inference:  47%|████▋     | 74/157 [05:38<06:30,  4.71s/it]Running inference:  48%|████▊     | 75/157 [05:43<06:21,  4.65s/it]Running inference:  48%|████▊     | 76/157 [05:47<06:22,  4.73s/it]Running inference:  49%|████▉     | 77/157 [05:52<06:17,  4.72s/it]Running inference:  50%|████▉     | 78/157 [05:57<06:09,  4.67s/it]Running inference:  50%|█████     | 79/157 [06:01<05:59,  4.61s/it]Running inference:  51%|█████     | 80/157 [06:05<05:48,  4.53s/it]Running inference:  52%|█████▏    | 81/157 [06:10<05:45,  4.54s/it]Running inference:  52%|█████▏    | 82/157 [06:15<05:43,  4.59s/it]Running inference:  53%|█████▎    | 83/157 [06:19<05:37,  4.56s/it]Running inference:  54%|█████▎    | 84/157 [06:24<05:39,  4.65s/it]Running inference:  54%|█████▍    | 85/157 [06:29<05:33,  4.63s/it]Running inference:  55%|█████▍    | 86/157 [06:33<05:31,  4.67s/it]Running inference:  55%|█████▌    | 87/157 [06:38<05:28,  4.69s/it]Running inference:  56%|█████▌    | 88/157 [06:43<05:22,  4.67s/it]Running inference:  57%|█████▋    | 89/157 [06:47<05:12,  4.60s/it]Running inference:  57%|█████▋    | 90/157 [06:52<05:02,  4.51s/it]Running inference:  58%|█████▊    | 91/157 [06:56<04:58,  4.52s/it]Running inference:  59%|█████▊    | 92/157 [07:01<04:52,  4.50s/it]Running inference:  59%|█████▉    | 93/157 [07:05<04:44,  4.44s/it]Running inference:  60%|█████▉    | 94/157 [07:09<04:40,  4.45s/it]Running inference:  61%|██████    | 95/157 [07:14<04:32,  4.40s/it]Running inference:  61%|██████    | 96/157 [07:18<04:30,  4.44s/it]Running inference:  62%|██████▏   | 97/157 [07:23<04:31,  4.53s/it]Running inference:  62%|██████▏   | 98/157 [07:28<04:29,  4.57s/it]Running inference:  63%|██████▎   | 99/157 [07:32<04:27,  4.60s/it]Running inference:  64%|██████▎   | 100/157 [07:37<04:22,  4.60s/it]Running inference:  64%|██████▍   | 101/157 [07:41<04:15,  4.56s/it]Running inference:  65%|██████▍   | 102/157 [07:46<04:06,  4.48s/it]Running inference:  66%|██████▌   | 103/157 [07:50<04:03,  4.52s/it]Running inference:  66%|██████▌   | 104/157 [07:55<04:00,  4.55s/it]Running inference:  67%|██████▋   | 105/157 [07:59<03:53,  4.50s/it]Running inference:  68%|██████▊   | 106/157 [08:04<03:48,  4.49s/it]Running inference:  68%|██████▊   | 107/157 [08:08<03:41,  4.43s/it]Running inference:  69%|██████▉   | 108/157 [08:12<03:37,  4.44s/it]Running inference:  69%|██████▉   | 109/157 [08:17<03:31,  4.40s/it]Running inference:  70%|███████   | 110/157 [08:21<03:30,  4.48s/it]Running inference:  71%|███████   | 111/157 [08:26<03:26,  4.48s/it]Running inference:  71%|███████▏  | 112/157 [08:30<03:19,  4.43s/it]Running inference:  72%|███████▏  | 113/157 [08:35<03:15,  4.44s/it]Running inference:  73%|███████▎  | 114/157 [08:39<03:09,  4.40s/it]Running inference:  73%|███████▎  | 115/157 [08:43<03:05,  4.41s/it]Running inference:  74%|███████▍  | 116/157 [08:48<03:01,  4.44s/it]Running inference:  75%|███████▍  | 117/157 [08:52<02:55,  4.40s/it]Running inference:  75%|███████▌  | 118/157 [08:57<02:54,  4.48s/it]Running inference:  76%|███████▌  | 119/157 [09:01<02:49,  4.46s/it]Running inference:  76%|███████▋  | 120/157 [09:06<02:45,  4.46s/it]Running inference:  77%|███████▋  | 121/157 [09:10<02:39,  4.42s/it]Running inference:  78%|███████▊  | 122/157 [09:15<02:35,  4.44s/it]Running inference:  78%|███████▊  | 123/157 [09:19<02:31,  4.45s/it]Running inference:  79%|███████▉  | 124/157 [09:23<02:25,  4.41s/it]Running inference:  80%|███████▉  | 125/157 [09:28<02:22,  4.45s/it]Running inference:  80%|████████  | 126/157 [09:32<02:18,  4.46s/it]Running inference:  81%|████████  | 127/157 [09:37<02:13,  4.46s/it]Running inference:  82%|████████▏ | 128/157 [09:41<02:07,  4.40s/it]Running inference:  82%|████████▏ | 129/157 [09:46<02:03,  4.42s/it]Running inference:  83%|████████▎ | 130/157 [09:50<02:00,  4.45s/it]Running inference:  83%|████████▎ | 131/157 [09:54<01:54,  4.41s/it]Running inference:  84%|████████▍ | 132/157 [09:59<01:52,  4.50s/it]Running inference:  85%|████████▍ | 133/157 [10:03<01:46,  4.45s/it]Running inference:  85%|████████▌ | 134/157 [10:08<01:42,  4.45s/it]Running inference:  86%|████████▌ | 135/157 [10:12<01:38,  4.48s/it]Running inference:  87%|████████▋ | 136/157 [10:17<01:34,  4.52s/it]Running inference:  87%|████████▋ | 137/157 [10:22<01:30,  4.50s/it]Running inference:  88%|████████▊ | 138/157 [10:26<01:24,  4.44s/it]Running inference:  89%|████████▊ | 139/157 [10:30<01:20,  4.45s/it]Running inference:  89%|████████▉ | 140/157 [10:35<01:14,  4.41s/it]Running inference:  90%|████████▉ | 141/157 [10:39<01:10,  4.43s/it]Running inference:  90%|█████████ | 142/157 [10:44<01:07,  4.53s/it]Running inference:  91%|█████████ | 143/157 [10:48<01:03,  4.56s/it]Running inference:  92%|█████████▏| 144/157 [10:53<00:59,  4.61s/it]Running inference:  92%|█████████▏| 145/157 [10:58<00:54,  4.55s/it]Running inference:  93%|█████████▎| 146/157 [11:02<00:49,  4.53s/it]Running inference:  94%|█████████▎| 147/157 [11:07<00:45,  4.51s/it]Running inference:  94%|█████████▍| 148/157 [11:11<00:40,  4.49s/it]Running inference:  95%|█████████▍| 149/157 [11:16<00:35,  4.49s/it]Running inference:  96%|█████████▌| 150/157 [11:20<00:31,  4.44s/it]Running inference:  96%|█████████▌| 151/157 [11:24<00:26,  4.45s/it]Running inference:  97%|█████████▋| 152/157 [11:29<00:22,  4.45s/it]Running inference:  97%|█████████▋| 153/157 [11:33<00:17,  4.48s/it]Running inference:  98%|█████████▊| 154/157 [11:38<00:13,  4.48s/it]Running inference:  99%|█████████▊| 155/157 [11:42<00:08,  4.43s/it]Running inference:  99%|█████████▉| 156/157 [11:47<00:04,  4.44s/it]Running inference: 100%|██████████| 157/157 [11:48<00:00,  3.48s/it]Running inference: 100%|██████████| 157/157 [11:48<00:00,  4.51s/it]
00:47:58 - INFO - [inference_test] Duration: 708291.33ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:47:58 - INFO -     Inference: 1418.51s for 10000 samples (7.05 samples/sec)
00:47:58 - INFO - Initialized ProbabilityExtractor
00:47:58 - INFO -   Temperature: 1.0
00:47:58 - INFO -   Calibration method: None
00:47:58 - INFO - [probability_extraction] Duration: 274.79ms | GPU Memory: 3145.8MB -> 3145.8MB (delta +0.0MB)
00:47:58 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_stablelm-2-1.6b_ds_float16_base_20251207_234559.npz
00:47:58 - INFO - Initialized LACScorer
00:47:58 - INFO -   Alpha: 0.1
00:47:58 - INFO -   Target coverage: 90.0%
00:47:58 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
00:47:58 - INFO - Initialized PredictionSetGenerator
00:47:58 - INFO -   Methods: ['lac']
00:47:58 - INFO -   Alpha: 0.1
00:47:58 - INFO -   Aggregation: separate
00:47:58 - INFO - Calibrating 1 conformal predictors...
00:47:58 - INFO -   Calibrating LAC...
00:47:58 - INFO - Calibrating with 4999 samples...
00:47:58 - INFO - Calibration complete
00:47:58 - INFO -   Threshold: 0.9719
00:47:58 - INFO -   Score range: [0.0001, 1.0000]
00:47:58 - INFO - Calibration complete
00:47:58 - INFO - Generating prediction sets using LAC...
00:47:58 - INFO - Generating prediction sets for 5001 test instances...
00:47:58 - INFO - Prediction complete
00:47:58 - INFO -   Average set size: 5.03
00:47:58 - INFO -   Coverage rate: 90.32%
00:47:58 - INFO -   Meets coverage guarantee: True
00:47:58 - INFO - [PASS] Coverage guarantee met: 90.32% >= 90.00%
00:47:58 - INFO -     LAC: Acc=23.58%, CR=90.32%, SS=5.03
00:47:58 - INFO - Initialized APSScorer
00:47:58 - INFO -   Alpha: 0.1
00:47:58 - INFO -   Target coverage: 90.0%
00:47:58 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
00:47:58 - INFO - Initialized PredictionSetGenerator
00:47:58 - INFO -   Methods: ['aps']
00:47:58 - INFO -   Alpha: 0.1
00:47:58 - INFO -   Aggregation: separate
00:47:58 - INFO - Calibrating 1 conformal predictors...
00:47:58 - INFO -   Calibrating APS...
00:47:58 - INFO - Calibrating with 4999 samples...
00:47:58 - INFO - Calibration complete
00:47:58 - INFO -   Threshold: 0.9950
00:47:58 - INFO -   Score range: [0.2119, 1.0000]
00:47:58 - INFO - Calibration complete
00:47:58 - INFO - Generating prediction sets using APS...
00:47:58 - INFO - Generating prediction sets for 5001 test instances...
00:47:58 - INFO - Prediction complete
00:47:58 - INFO -   Average set size: 4.85
00:47:58 - INFO -   Coverage rate: 90.58%
00:47:58 - INFO -   Meets coverage guarantee: True
00:47:58 - INFO - [PASS] Coverage guarantee met: 90.58% >= 90.00%
00:47:58 - INFO -     APS: Acc=23.58%, CR=90.58%, SS=4.85
00:48:02 - INFO - Unloaded model: stablelm-2-1.6b_float16
00:48:02 - INFO - Checkpoint saved after completing: stablelm-2-1.6b | ds | float16
00:48:02 - INFO - Generating all visualizations...
00:48:03 - INFO - Saved heatmap to outputs/results/figures/heatmap_accuracy.png
00:48:03 - INFO - Saved heatmap to outputs/results/figures/heatmap_coverage_rate.png
00:48:04 - INFO - Saved heatmap to outputs/results/figures/heatmap_avg_set_size.png
00:48:05 - INFO - Saved dashboard to outputs/results/figures/dashboard.png
00:48:06 - INFO - Saved bar chart to outputs/results/figures/bar_comparison_accuracy.png
00:48:06 - INFO - Saved bar chart to outputs/results/figures/bar_comparison_avg_set_size.png
00:48:07 - INFO - Saved radar chart to outputs/results/figures/radar_chart.png
00:48:08 - INFO - Saved uncertainty analysis to outputs/results/figures/uncertainty_analysis.png
00:48:08 - INFO - Saved summary table to outputs/results/figures/results_summary.md
00:48:08 - INFO - Saved summary table to outputs/results/figures/results_summary_lac.md
00:48:08 - INFO - Saved summary table to outputs/results/figures/results_summary_aps.md
00:48:08 - INFO - All visualizations saved to outputs/results/figures
00:48:08 - INFO - Visualizations saved to: outputs/results/figures
00:48:08 - INFO - Stopped GPU monitoring. Collected 1275 snapshots.

================================================================================
GPU PROFILING SUMMARY
================================================================================

Total Operations: 30
Total Time: 3696976.64ms (3696.98s)

--- Operations Breakdown ---

  [inference_calibration]
    Count: 5
    Total: 1801643.90ms (48.7%)
    Avg: 360328.78ms | Min: 181476.12ms | Max: 710213.52ms
    Avg Memory Delta: +1.8MB

  [inference_test]
    Count: 5
    Total: 1797073.94ms (48.6%)
    Avg: 359414.79ms | Min: 178358.73ms | Max: 708291.33ms
    Avg Memory Delta: +0.0MB

  [dataset_processing]
    Count: 5
    Total: 65786.79ms (1.8%)
    Avg: 13157.36ms | Min: 38.20ms | Max: 34517.60ms
    Avg Memory Delta: +0.0MB

  [model_loading]
    Count: 5
    Total: 18092.36ms (0.5%)
    Avg: 3618.47ms | Min: 2375.42ms | Max: 8112.90ms
    Avg Memory Delta: +3136.7MB

  [dataset_loading]
    Count: 5
    Total: 12827.13ms (0.3%)
    Avg: 2565.43ms | Min: 781.38ms | Max: 4576.21ms
    Avg Memory Delta: +0.0MB

  [probability_extraction]
    Count: 5
    Total: 1552.52ms (0.0%)
    Avg: 310.50ms | Min: 239.50ms | Max: 484.31ms
    Avg Memory Delta: +0.0MB

--- Memory Statistics ---
  Peak Allocated: 15690.8MB
  Avg Allocated: 9480.5MB
  Avg GPU Utilization: 99.8%

--- Bottlenecks & Recommendations ---

  [WARN] inference_calibration (48.7% of total time)
     -> Inference is slow. Consider: larger batch size, Flash Attention, or quantization.

  [WARN] inference_test (48.6% of total time)
     -> Inference is slow. Consider: larger batch size, Flash Attention, or quantization.

================================================================================
00:48:08 - INFO - Saved GPU profiling report to outputs/results/gpu_profile_20251207_234559.json
00:48:08 - INFO - GPU profiling report saved to: outputs/results/gpu_profile_20251207_234559.json
00:48:08 - INFO - 
================================================================================
00:48:08 - INFO - BENCHMARK COMPLETE
00:48:08 - INFO - ================================================================================
00:48:08 - INFO - Total time: 62.02 minutes
00:48:08 - INFO - Results saved to: outputs/results

================================================================================
FINAL SUMMARY
================================================================================
Total runs: 10
Overall accuracy: 21.87%
Overall coverage: 91.10%
Overall set size: 5.19
Guarantee met: 70.00%
Total time: 62.02 minutes
Log file: outputs/results/logs/benchmark_20251207_234559.log
================================================================================

00:48:08 - INFO - Benchmark completed successfully
00:48:08 - INFO - Total runs: 10
00:48:08 - INFO - Overall accuracy: 21.87%
00:48:08 - INFO - Overall coverage: 91.10%
00:48:08 - INFO - Log file saved to: outputs/results/logs/benchmark_20251207_234559.log
