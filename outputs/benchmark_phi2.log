
================================================================================
BLUQ: Benchmarking Language models via Uncertainty Quantification
================================================================================
Mode: long (10000 samples per task)
Models: 1 | Tasks: 5 | Dtypes: 1
Total configurations: 5
Log file: outputs/results/logs/benchmark_20251207_231938.log
================================================================================

23:19:38 - INFO - Starting benchmark run
23:19:38 - INFO - Log file: outputs/results/logs/benchmark_20251207_231938.log
23:19:38 - INFO - Mode: long, Samples: 10000
23:19:38 - INFO - Models: ['phi-2']
23:19:38 - INFO - Tasks: ['qa', 'rc', 'ci', 'drs', 'ds']
23:19:38 - INFO - Dtypes: ['float16']
23:19:40 - INFO - Running on: Device: NVIDIA A100 80GB PCIe (cuda)
  Total Memory: 79.25 GB
  Available Memory: 79.25 GB
23:19:40 - INFO - Detected A100 GPU: NVIDIA A100 80GB PCIe - using optimized A100 settings
23:19:40 - INFO - GPU Tier: a100 | Auto max_batch_size: 192 | Safety margin: 0.93
23:19:40 - INFO - Using user-specified max_batch_size: 32
23:19:40 - INFO - NVML initialized for GPU utilization monitoring
23:19:40 - INFO - GPUProfiler initialized (CUDA: True, NVML: True)
23:19:40 - INFO - Started GPU monitoring
23:19:40 - INFO - GPU profiling enabled
23:19:40 - INFO - 
================================================================================
23:19:40 - INFO - FULL BENCHMARK CONFIGURATION
23:19:40 - INFO - ================================================================================
23:19:40 - INFO - Models (1): ['phi-2']
23:19:40 - INFO - Tasks (5): ['qa', 'rc', 'ci', 'drs', 'ds']
23:19:40 - INFO - Data types: ['float16']
23:19:40 - INFO - Samples per task: 10000
23:19:40 - INFO - Alpha (error rate): 0.1
23:19:40 - INFO - Strategies: ['base']
23:19:40 - INFO - Conformal methods: ['lac', 'aps']
23:19:40 - INFO - Dynamic batch sizing: False
23:19:40 - INFO - Max batch size: 32 (GPU tier: a100)
23:19:40 - INFO - Output directory: outputs/results
23:19:40 - INFO - 
================================================================================
23:19:40 - INFO - Run 1/5: phi-2 | qa | float16
23:19:40 - INFO - ================================================================================
23:19:44 - INFO - [start_phi-2_qa] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 0.0%
23:19:44 - INFO - Loading qa dataset (10000 samples)...
23:19:44 - INFO - Loading MMLU dataset with 10000 samples...
23:19:47 - INFO - Loaded 10000 MMLU instances
23:19:47 - INFO - [dataset_loading] Duration: 3573.61ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
23:19:47 - INFO - Processing qa dataset to 6-option format...
23:19:48 - INFO - Processed 10000 instances for qa
23:19:48 - INFO - Splitting qa dataset (calibration: 50%, test: 50%)
23:19:48 - INFO - Split complete:
23:19:48 - INFO -   Calibration: 4998 instances
23:19:48 - INFO -   Test: 5002 instances
23:19:48 - WARNING - Calibration size 4998 differs from expected 5000
23:19:48 - INFO - Answer distribution:
23:19:48 - INFO -   Calibration: {'A': 1174, 'B': 1230, 'C': 1242, 'D': 1352}
23:19:48 - INFO -   Test: {'A': 1175, 'B': 1231, 'C': 1243, 'D': 1353}
23:19:48 - INFO - [dataset_processing] Duration: 353.71ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
23:19:48 - INFO - Initialized DemonstrationSelector
23:19:48 - INFO -   Strategy: random
23:19:48 - INFO -   Num demonstrations: 5
23:19:48 - INFO - Initialized DemonstrationManager
23:19:48 - INFO - Selecting 5 demonstrations using 'random' strategy
23:19:48 - INFO - Selected and cached 5 demonstrations for qa
23:19:48 - INFO - Loading model: phi-2 (float16)
23:19:48 - INFO - Loading model: phi-2_float16 (microsoft/phi-2)
23:19:48 - INFO - Loading tokenizer from microsoft/phi-2
23:19:48 - INFO - Tokenizer loaded successfully
23:19:48 - INFO -   Vocab size: 50295
23:19:48 - INFO -   Padding side: left
23:19:48 - INFO -   PAD token: <|endoftext|> (ID: 50256)
23:19:48 - INFO - Loading model from microsoft/phi-2
`torch_dtype` is deprecated! Use `dtype` instead!
23:19:48 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.38it/s]
23:19:50 - INFO - Model loaded successfully
23:19:50 - INFO -   GPU Memory: 5.18GB allocated, 5.18GB reserved

Model: phi-2_float16
  ID: microsoft/phi-2
  Type: causal
  Parameters: 2,779,683,840
  Vocab size: 50,295
  Max length: 2048
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: False
23:19:50 - INFO - [model_loading] Duration: 1878.88ms | GPU Memory: 0.0MB -> 5301.8MB (delta +5301.8MB)
23:19:50 - INFO - [after_model_load_phi-2] GPU State: Allocated: 5301.8MB | Reserved: 5308.0MB | Free: 75853.9MB | Utilization: 0.0%
23:19:50 - INFO - Using batch size: 32
23:19:50 - INFO -   Strategy: base
23:19:50 - INFO - Initialized PromptBuilder for task: qa
23:19:50 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
23:19:50 - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
23:19:50 - INFO - Initialized InferenceEngine for phi-2_float16
23:19:50 - INFO -   Device: cuda:0
23:19:50 - INFO -   Batch size: 32
23:19:50 - INFO -   Option tokens: {'A': 317, 'B': 347, 'C': 327, 'D': 360, 'E': 412, 'F': 376}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]/root/BLUQ/src/models/inference_engine.py:433: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Running inference:   1%|          | 1/157 [00:02<05:50,  2.25s/it]Running inference:   1%|▏         | 2/157 [00:04<05:26,  2.10s/it]Running inference:   2%|▏         | 3/157 [00:06<05:20,  2.08s/it]Running inference:   3%|▎         | 4/157 [00:08<05:18,  2.08s/it]Running inference:   3%|▎         | 5/157 [00:10<05:25,  2.14s/it]Running inference:   4%|▍         | 6/157 [00:12<05:25,  2.15s/it]Running inference:   4%|▍         | 7/157 [00:15<05:52,  2.35s/it]Running inference:   5%|▌         | 8/157 [00:17<05:53,  2.37s/it]Running inference:   6%|▌         | 9/157 [00:20<06:06,  2.48s/it]Running inference:   6%|▋         | 10/157 [00:22<05:50,  2.39s/it]Running inference:   7%|▋         | 11/157 [00:25<05:39,  2.33s/it]Running inference:   8%|▊         | 12/157 [00:27<05:21,  2.22s/it]Running inference:   8%|▊         | 13/157 [00:29<05:11,  2.17s/it]Running inference:   9%|▉         | 14/157 [00:31<05:08,  2.16s/it]Running inference:  10%|▉         | 15/157 [00:33<05:30,  2.33s/it]Running inference:  10%|█         | 16/157 [00:36<05:32,  2.36s/it]Running inference:  11%|█         | 17/157 [00:38<05:29,  2.36s/it]Running inference:  11%|█▏        | 18/157 [00:41<05:32,  2.39s/it]Running inference:  12%|█▏        | 19/157 [00:43<05:16,  2.29s/it]Running inference:  13%|█▎        | 20/157 [00:45<05:30,  2.42s/it]Running inference:  13%|█▎        | 21/157 [00:48<05:18,  2.34s/it]Running inference:  14%|█▍        | 22/157 [00:50<05:08,  2.29s/it]Running inference:  15%|█▍        | 23/157 [00:52<04:57,  2.22s/it]Running inference:  15%|█▌        | 24/157 [00:54<04:54,  2.22s/it]Running inference:  16%|█▌        | 25/157 [00:56<04:55,  2.24s/it]Running inference:  17%|█▋        | 26/157 [00:58<04:36,  2.11s/it]Running inference:  17%|█▋        | 27/157 [01:01<04:48,  2.22s/it]Running inference:  18%|█▊        | 28/157 [01:03<04:55,  2.29s/it]Running inference:  18%|█▊        | 29/157 [01:05<04:38,  2.18s/it]Running inference:  19%|█▉        | 30/157 [01:07<04:26,  2.10s/it]Running inference:  20%|█▉        | 31/157 [01:09<04:33,  2.17s/it]Running inference:  20%|██        | 32/157 [01:11<04:24,  2.11s/it]Running inference:  21%|██        | 33/157 [01:13<04:21,  2.11s/it]Running inference:  22%|██▏       | 34/157 [01:16<04:23,  2.15s/it]Running inference:  22%|██▏       | 35/157 [01:18<04:33,  2.24s/it]Running inference:  23%|██▎       | 36/157 [01:21<04:40,  2.31s/it]Running inference:  24%|██▎       | 37/157 [01:23<04:31,  2.26s/it]Running inference:  24%|██▍       | 38/157 [01:25<04:28,  2.26s/it]Running inference:  25%|██▍       | 39/157 [01:27<04:18,  2.19s/it]Running inference:  25%|██▌       | 40/157 [01:29<04:20,  2.23s/it]Running inference:  26%|██▌       | 41/157 [01:31<04:12,  2.18s/it]Running inference:  27%|██▋       | 42/157 [01:34<04:30,  2.36s/it]Running inference:  27%|██▋       | 43/157 [01:36<04:13,  2.23s/it]Running inference:  28%|██▊       | 44/157 [01:38<04:00,  2.13s/it]Running inference:  29%|██▊       | 45/157 [01:40<04:12,  2.25s/it]Running inference:  29%|██▉       | 46/157 [01:43<04:04,  2.20s/it]Running inference:  30%|██▉       | 47/157 [01:45<03:58,  2.16s/it]Running inference:  31%|███       | 48/157 [01:47<03:56,  2.17s/it]Running inference:  31%|███       | 49/157 [01:49<03:51,  2.14s/it]Running inference:  32%|███▏      | 50/157 [01:51<03:47,  2.13s/it]Running inference:  32%|███▏      | 51/157 [01:53<03:47,  2.14s/it]Running inference:  33%|███▎      | 52/157 [01:56<04:00,  2.29s/it]Running inference:  34%|███▍      | 53/157 [01:58<03:54,  2.26s/it]Running inference:  34%|███▍      | 54/157 [02:00<03:49,  2.23s/it]Running inference:  35%|███▌      | 55/157 [02:02<03:43,  2.19s/it]Running inference:  36%|███▌      | 56/157 [02:05<03:48,  2.26s/it]Running inference:  36%|███▋      | 57/157 [02:07<03:47,  2.28s/it]Running inference:  37%|███▋      | 58/157 [02:09<03:52,  2.34s/it]Running inference:  38%|███▊      | 59/157 [02:12<03:57,  2.42s/it]Running inference:  38%|███▊      | 60/157 [02:14<03:51,  2.38s/it]Running inference:  39%|███▉      | 61/157 [02:17<03:50,  2.40s/it]Running inference:  39%|███▉      | 62/157 [02:19<03:42,  2.34s/it]Running inference:  40%|████      | 63/157 [02:21<03:32,  2.26s/it]Running inference:  41%|████      | 64/157 [02:23<03:27,  2.23s/it]Running inference:  41%|████▏     | 65/157 [02:26<03:33,  2.32s/it]Running inference:  42%|████▏     | 66/157 [02:28<03:21,  2.22s/it]Running inference:  43%|████▎     | 67/157 [02:30<03:26,  2.30s/it]Running inference:  43%|████▎     | 68/157 [02:32<03:11,  2.15s/it]Running inference:  44%|████▍     | 69/157 [02:34<03:04,  2.10s/it]Running inference:  45%|████▍     | 70/157 [02:37<03:14,  2.24s/it]Running inference:  45%|████▌     | 71/157 [02:39<03:12,  2.24s/it]Running inference:  46%|████▌     | 72/157 [02:41<03:09,  2.23s/it]Running inference:  46%|████▋     | 73/157 [02:43<03:06,  2.22s/it]Running inference:  47%|████▋     | 74/157 [02:45<03:01,  2.18s/it]Running inference:  48%|████▊     | 75/157 [02:47<02:56,  2.16s/it]Running inference:  48%|████▊     | 76/157 [02:49<02:48,  2.08s/it]Running inference:  49%|████▉     | 77/157 [02:52<03:08,  2.36s/it]Running inference:  50%|████▉     | 78/157 [02:54<02:58,  2.26s/it]Running inference:  50%|█████     | 79/157 [02:57<02:55,  2.25s/it]Running inference:  51%|█████     | 80/157 [02:59<02:45,  2.15s/it]Running inference:  52%|█████▏    | 81/157 [03:01<02:53,  2.28s/it]Running inference:  52%|█████▏    | 82/157 [03:03<02:43,  2.18s/it]Running inference:  53%|█████▎    | 83/157 [03:05<02:43,  2.21s/it]Running inference:  54%|█████▎    | 84/157 [03:08<02:52,  2.37s/it]Running inference:  54%|█████▍    | 85/157 [03:10<02:46,  2.31s/it]Running inference:  55%|█████▍    | 86/157 [03:13<02:44,  2.31s/it]Running inference:  55%|█████▌    | 87/157 [03:15<02:44,  2.34s/it]Running inference:  56%|█████▌    | 88/157 [03:17<02:36,  2.27s/it]Running inference:  57%|█████▋    | 89/157 [03:19<02:29,  2.20s/it]Running inference:  57%|█████▋    | 90/157 [03:21<02:22,  2.13s/it]Running inference:  58%|█████▊    | 91/157 [03:24<02:29,  2.26s/it]Running inference:  59%|█████▊    | 92/157 [03:26<02:32,  2.35s/it]Running inference:  59%|█████▉    | 93/157 [03:28<02:24,  2.26s/it]Running inference:  60%|█████▉    | 94/157 [03:30<02:17,  2.18s/it]Running inference:  61%|██████    | 95/157 [03:33<02:19,  2.25s/it]Running inference:  61%|██████    | 96/157 [03:35<02:13,  2.19s/it]Running inference:  62%|██████▏   | 97/157 [03:37<02:13,  2.23s/it]Running inference:  62%|██████▏   | 98/157 [03:40<02:16,  2.31s/it]Running inference:  63%|██████▎   | 99/157 [03:42<02:12,  2.29s/it]Running inference:  64%|██████▎   | 100/157 [03:44<02:06,  2.21s/it]Running inference:  64%|██████▍   | 101/157 [03:46<02:00,  2.16s/it]Running inference:  65%|██████▍   | 102/157 [03:48<01:55,  2.10s/it]Running inference:  66%|██████▌   | 103/157 [03:50<01:53,  2.10s/it]Running inference:  66%|██████▌   | 104/157 [03:52<01:58,  2.24s/it]Running inference:  67%|██████▋   | 105/157 [03:55<01:53,  2.19s/it]Running inference:  68%|██████▊   | 106/157 [03:57<01:53,  2.22s/it]Running inference:  68%|██████▊   | 107/157 [03:59<01:52,  2.26s/it]Running inference:  69%|██████▉   | 108/157 [04:01<01:47,  2.20s/it]Running inference:  69%|██████▉   | 109/157 [04:04<01:50,  2.30s/it]Running inference:  70%|███████   | 110/157 [04:06<01:46,  2.26s/it]Running inference:  71%|███████   | 111/157 [04:08<01:44,  2.27s/it]Running inference:  71%|███████▏  | 112/157 [04:10<01:40,  2.24s/it]Running inference:  72%|███████▏  | 113/157 [04:13<01:42,  2.33s/it]Running inference:  73%|███████▎  | 114/157 [04:15<01:34,  2.21s/it]Running inference:  73%|███████▎  | 115/157 [04:17<01:35,  2.27s/it]Running inference:  74%|███████▍  | 116/157 [04:20<01:32,  2.25s/it]Running inference:  75%|███████▍  | 117/157 [04:22<01:29,  2.24s/it]Running inference:  75%|███████▌  | 118/157 [04:24<01:25,  2.18s/it]Running inference:  76%|███████▌  | 119/157 [04:26<01:24,  2.22s/it]Running inference:  76%|███████▋  | 120/157 [04:28<01:20,  2.17s/it]Running inference:  77%|███████▋  | 121/157 [04:30<01:16,  2.13s/it]Running inference:  78%|███████▊  | 122/157 [04:32<01:14,  2.14s/it]Running inference:  78%|███████▊  | 123/157 [04:35<01:14,  2.20s/it]Running inference:  79%|███████▉  | 124/157 [04:37<01:12,  2.18s/it]Running inference:  80%|███████▉  | 125/157 [04:39<01:07,  2.12s/it]Running inference:  80%|████████  | 126/157 [04:41<01:08,  2.19s/it]Running inference:  81%|████████  | 127/157 [04:44<01:13,  2.44s/it]Running inference:  82%|████████▏ | 128/157 [04:46<01:07,  2.33s/it]Running inference:  82%|████████▏ | 129/157 [04:48<01:04,  2.30s/it]Running inference:  83%|████████▎ | 130/157 [04:50<00:59,  2.21s/it]Running inference:  83%|████████▎ | 131/157 [04:53<00:57,  2.20s/it]Running inference:  84%|████████▍ | 132/157 [04:55<00:55,  2.23s/it]Running inference:  85%|████████▍ | 133/157 [04:57<00:52,  2.18s/it]Running inference:  85%|████████▌ | 134/157 [05:00<00:52,  2.30s/it]Running inference:  86%|████████▌ | 135/157 [05:02<00:52,  2.37s/it]Running inference:  87%|████████▋ | 136/157 [05:04<00:49,  2.36s/it]Running inference:  87%|████████▋ | 137/157 [05:06<00:45,  2.27s/it]Running inference:  88%|████████▊ | 138/157 [05:09<00:41,  2.21s/it]Running inference:  89%|████████▊ | 139/157 [05:11<00:40,  2.27s/it]Running inference:  89%|████████▉ | 140/157 [05:13<00:37,  2.22s/it]Running inference:  90%|████████▉ | 141/157 [05:15<00:34,  2.15s/it]Running inference:  90%|█████████ | 142/157 [05:17<00:32,  2.17s/it]Running inference:  91%|█████████ | 143/157 [05:20<00:32,  2.35s/it]Running inference:  92%|█████████▏| 144/157 [05:23<00:31,  2.41s/it]Running inference:  92%|█████████▏| 145/157 [05:25<00:27,  2.30s/it]Running inference:  93%|█████████▎| 146/157 [05:27<00:24,  2.19s/it]Running inference:  94%|█████████▎| 147/157 [05:29<00:21,  2.13s/it]Running inference:  94%|█████████▍| 148/157 [05:31<00:19,  2.11s/it]Running inference:  95%|█████████▍| 149/157 [05:33<00:16,  2.06s/it]Running inference:  96%|█████████▌| 150/157 [05:35<00:14,  2.10s/it]Running inference:  96%|█████████▌| 151/157 [05:37<00:12,  2.14s/it]Running inference:  97%|█████████▋| 152/157 [05:39<00:11,  2.24s/it]Running inference:  97%|█████████▋| 153/157 [05:42<00:08,  2.21s/it]Running inference:  98%|█████████▊| 154/157 [05:44<00:06,  2.18s/it]Running inference:  99%|█████████▊| 155/157 [05:46<00:04,  2.33s/it]Running inference:  99%|█████████▉| 156/157 [05:48<00:02,  2.21s/it]Running inference: 100%|██████████| 157/157 [05:49<00:00,  1.64s/it]Running inference: 100%|██████████| 157/157 [05:49<00:00,  2.22s/it]
23:25:39 - INFO - [inference_calibration] Duration: 349138.57ms | GPU Memory: 5301.8MB -> 5311.0MB (delta +9.1MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<05:05,  1.96s/it]Running inference:   1%|▏         | 2/157 [00:04<05:20,  2.07s/it]Running inference:   2%|▏         | 3/157 [00:06<05:24,  2.11s/it]Running inference:   3%|▎         | 4/157 [00:08<05:19,  2.09s/it]Running inference:   3%|▎         | 5/157 [00:10<05:17,  2.09s/it]Running inference:   4%|▍         | 6/157 [00:12<05:14,  2.09s/it]Running inference:   4%|▍         | 7/157 [00:15<05:49,  2.33s/it]Running inference:   5%|▌         | 8/157 [00:17<05:26,  2.19s/it]Running inference:   6%|▌         | 9/157 [00:19<05:25,  2.20s/it]Running inference:   6%|▋         | 10/157 [00:21<05:25,  2.21s/it]Running inference:   7%|▋         | 11/157 [00:23<05:20,  2.19s/it]Running inference:   8%|▊         | 12/157 [00:25<05:07,  2.12s/it]Running inference:   8%|▊         | 13/157 [00:27<05:06,  2.13s/it]Running inference:   9%|▉         | 14/157 [00:30<05:06,  2.15s/it]Running inference:  10%|▉         | 15/157 [00:32<05:07,  2.16s/it]Running inference:  10%|█         | 16/157 [00:34<05:04,  2.16s/it]Running inference:  11%|█         | 17/157 [00:36<04:53,  2.09s/it]Running inference:  11%|█▏        | 18/157 [00:38<05:05,  2.20s/it]Running inference:  12%|█▏        | 19/157 [00:40<05:01,  2.19s/it]Running inference:  13%|█▎        | 20/157 [00:43<04:55,  2.16s/it]Running inference:  13%|█▎        | 21/157 [00:45<04:53,  2.16s/it]Running inference:  14%|█▍        | 22/157 [00:47<04:55,  2.19s/it]Running inference:  15%|█▍        | 23/157 [00:50<05:09,  2.31s/it]Running inference:  15%|█▌        | 24/157 [00:51<04:50,  2.19s/it]Running inference:  16%|█▌        | 25/157 [00:54<05:02,  2.30s/it]Running inference:  17%|█▋        | 26/157 [00:57<05:10,  2.37s/it]Running inference:  17%|█▋        | 27/157 [00:59<05:20,  2.47s/it]Running inference:  18%|█▊        | 28/157 [01:01<05:08,  2.39s/it]Running inference:  18%|█▊        | 29/157 [01:04<04:58,  2.33s/it]Running inference:  19%|█▉        | 30/157 [01:06<04:51,  2.29s/it]Running inference:  20%|█▉        | 31/157 [01:08<04:43,  2.25s/it]Running inference:  20%|██        | 32/157 [01:10<04:40,  2.24s/it]Running inference:  21%|██        | 33/157 [01:12<04:31,  2.19s/it]Running inference:  22%|██▏       | 34/157 [01:14<04:23,  2.14s/it]Running inference:  22%|██▏       | 35/157 [01:17<04:22,  2.15s/it]Running inference:  23%|██▎       | 36/157 [01:19<04:16,  2.12s/it]Running inference:  24%|██▎       | 37/157 [01:20<04:04,  2.04s/it]Running inference:  24%|██▍       | 38/157 [01:23<04:08,  2.09s/it]Running inference:  25%|██▍       | 39/157 [01:25<04:16,  2.17s/it]Running inference:  25%|██▌       | 40/157 [01:27<03:58,  2.04s/it]Running inference:  26%|██▌       | 41/157 [01:29<03:57,  2.05s/it]Running inference:  27%|██▋       | 42/157 [01:31<03:55,  2.05s/it]Running inference:  27%|██▋       | 43/157 [01:33<03:57,  2.09s/it]Running inference:  28%|██▊       | 44/157 [01:35<03:54,  2.08s/it]Running inference:  29%|██▊       | 45/157 [01:37<04:01,  2.16s/it]Running inference:  29%|██▉       | 46/157 [01:40<03:57,  2.14s/it]Running inference:  30%|██▉       | 47/157 [01:42<04:05,  2.23s/it]Running inference:  31%|███       | 48/157 [01:44<03:58,  2.19s/it]Running inference:  31%|███       | 49/157 [01:46<03:53,  2.16s/it]Running inference:  32%|███▏      | 50/157 [01:48<03:51,  2.17s/it]Running inference:  32%|███▏      | 51/157 [01:50<03:47,  2.14s/it]Running inference:  33%|███▎      | 52/157 [01:53<03:47,  2.17s/it]Running inference:  34%|███▍      | 53/157 [01:55<03:35,  2.08s/it]Running inference:  34%|███▍      | 54/157 [01:57<03:37,  2.11s/it]Running inference:  35%|███▌      | 55/157 [01:59<03:43,  2.19s/it]Running inference:  36%|███▌      | 56/157 [02:02<03:57,  2.35s/it]Running inference:  36%|███▋      | 57/157 [02:04<03:58,  2.39s/it]Running inference:  37%|███▋      | 58/157 [02:07<04:05,  2.48s/it]Running inference:  38%|███▊      | 59/157 [02:09<03:58,  2.43s/it]Running inference:  38%|███▊      | 60/157 [02:11<03:47,  2.35s/it]Running inference:  39%|███▉      | 61/157 [02:14<03:36,  2.26s/it]Running inference:  39%|███▉      | 62/157 [02:16<03:33,  2.24s/it]Running inference:  40%|████      | 63/157 [02:19<04:07,  2.64s/it]Running inference:  41%|████      | 64/157 [02:22<04:00,  2.58s/it]Running inference:  41%|████▏     | 65/157 [02:24<03:40,  2.40s/it]Running inference:  42%|████▏     | 66/157 [02:26<03:29,  2.30s/it]Running inference:  43%|████▎     | 67/157 [02:28<03:30,  2.34s/it]Running inference:  43%|████▎     | 68/157 [02:30<03:22,  2.27s/it]Running inference:  44%|████▍     | 69/157 [02:32<03:13,  2.20s/it]Running inference:  45%|████▍     | 70/157 [02:35<03:17,  2.28s/it]Running inference:  45%|████▌     | 71/157 [02:37<03:12,  2.24s/it]Running inference:  46%|████▌     | 72/157 [02:39<03:05,  2.18s/it]Running inference:  46%|████▋     | 73/157 [02:43<03:37,  2.59s/it]Running inference:  47%|████▋     | 74/157 [02:45<03:25,  2.48s/it]Running inference:  48%|████▊     | 75/157 [02:47<03:15,  2.38s/it]Running inference:  48%|████▊     | 76/157 [02:49<03:09,  2.34s/it]Running inference:  49%|████▉     | 77/157 [02:52<03:07,  2.34s/it]Running inference:  50%|████▉     | 78/157 [02:54<03:03,  2.32s/it]Running inference:  50%|█████     | 79/157 [02:56<02:57,  2.28s/it]Running inference:  51%|█████     | 80/157 [02:58<02:56,  2.29s/it]Running inference:  52%|█████▏    | 81/157 [03:01<02:57,  2.33s/it]Running inference:  52%|█████▏    | 82/157 [03:03<02:54,  2.32s/it]Running inference:  53%|█████▎    | 83/157 [03:05<02:51,  2.31s/it]Running inference:  54%|█████▎    | 84/157 [03:08<02:52,  2.36s/it]Running inference:  54%|█████▍    | 85/157 [03:11<02:59,  2.50s/it]Running inference:  55%|█████▍    | 86/157 [03:13<02:48,  2.37s/it]Running inference:  55%|█████▌    | 87/157 [03:15<02:39,  2.28s/it]Running inference:  56%|█████▌    | 88/157 [03:17<02:37,  2.29s/it]Running inference:  57%|█████▋    | 89/157 [03:19<02:25,  2.14s/it]Running inference:  57%|█████▋    | 90/157 [03:21<02:20,  2.10s/it]Running inference:  58%|█████▊    | 91/157 [03:23<02:22,  2.16s/it]Running inference:  59%|█████▊    | 92/157 [03:25<02:23,  2.21s/it]Running inference:  59%|█████▉    | 93/157 [03:28<02:27,  2.31s/it]Running inference:  60%|█████▉    | 94/157 [03:30<02:21,  2.24s/it]Running inference:  61%|██████    | 95/157 [03:32<02:16,  2.20s/it]Running inference:  61%|██████    | 96/157 [03:34<02:12,  2.17s/it]Running inference:  62%|██████▏   | 97/157 [03:37<02:13,  2.23s/it]Running inference:  62%|██████▏   | 98/157 [03:39<02:07,  2.16s/it]Running inference:  63%|██████▎   | 99/157 [03:41<02:03,  2.12s/it]Running inference:  64%|██████▎   | 100/157 [03:43<02:00,  2.12s/it]Running inference:  64%|██████▍   | 101/157 [03:45<01:55,  2.05s/it]Running inference:  65%|██████▍   | 102/157 [03:47<01:54,  2.08s/it]Running inference:  66%|██████▌   | 103/157 [03:49<01:58,  2.19s/it]Running inference:  66%|██████▌   | 104/157 [03:52<01:56,  2.20s/it]Running inference:  67%|██████▋   | 105/157 [03:54<01:52,  2.17s/it]Running inference:  68%|██████▊   | 106/157 [03:56<01:49,  2.14s/it]Running inference:  68%|██████▊   | 107/157 [03:59<01:59,  2.39s/it]Running inference:  69%|██████▉   | 108/157 [04:01<01:51,  2.28s/it]Running inference:  69%|██████▉   | 109/157 [04:03<01:46,  2.22s/it]Running inference:  70%|███████   | 110/157 [04:05<01:40,  2.14s/it]Running inference:  71%|███████   | 111/157 [04:07<01:41,  2.20s/it]Running inference:  71%|███████▏  | 112/157 [04:09<01:40,  2.24s/it]Running inference:  72%|███████▏  | 113/157 [04:12<01:39,  2.26s/it]Running inference:  73%|███████▎  | 114/157 [04:14<01:32,  2.15s/it]Running inference:  73%|███████▎  | 115/157 [04:16<01:30,  2.16s/it]Running inference:  74%|███████▍  | 116/157 [04:18<01:31,  2.24s/it]Running inference:  75%|███████▍  | 117/157 [04:20<01:26,  2.15s/it]Running inference:  75%|███████▌  | 118/157 [04:22<01:24,  2.16s/it]Running inference:  76%|███████▌  | 119/157 [04:25<01:26,  2.28s/it]Running inference:  76%|███████▋  | 120/157 [04:27<01:21,  2.21s/it]Running inference:  77%|███████▋  | 121/157 [04:29<01:20,  2.23s/it]Running inference:  78%|███████▊  | 122/157 [04:31<01:14,  2.14s/it]Running inference:  78%|███████▊  | 123/157 [04:33<01:11,  2.11s/it]Running inference:  79%|███████▉  | 124/157 [04:36<01:11,  2.18s/it]Running inference:  80%|███████▉  | 125/157 [04:38<01:07,  2.12s/it]Running inference:  80%|████████  | 126/157 [04:39<01:02,  2.02s/it]Running inference:  81%|████████  | 127/157 [04:42<01:09,  2.31s/it]Running inference:  82%|████████▏ | 128/157 [04:45<01:07,  2.34s/it]Running inference:  82%|████████▏ | 129/157 [04:47<01:02,  2.25s/it]Running inference:  83%|████████▎ | 130/157 [04:49<01:00,  2.23s/it]Running inference:  83%|████████▎ | 131/157 [04:51<00:56,  2.19s/it]Running inference:  84%|████████▍ | 132/157 [04:53<00:54,  2.19s/it]Running inference:  85%|████████▍ | 133/157 [04:55<00:51,  2.15s/it]Running inference:  85%|████████▌ | 134/157 [04:58<00:50,  2.22s/it]Running inference:  86%|████████▌ | 135/157 [05:00<00:50,  2.28s/it]Running inference:  87%|████████▋ | 136/157 [05:02<00:45,  2.18s/it]Running inference:  87%|████████▋ | 137/157 [05:04<00:43,  2.19s/it]Running inference:  88%|████████▊ | 138/157 [05:07<00:42,  2.26s/it]Running inference:  89%|████████▊ | 139/157 [05:09<00:40,  2.27s/it]Running inference:  89%|████████▉ | 140/157 [05:11<00:38,  2.26s/it]Running inference:  90%|████████▉ | 141/157 [05:14<00:38,  2.41s/it]Running inference:  90%|█████████ | 142/157 [05:16<00:35,  2.37s/it]Running inference:  91%|█████████ | 143/157 [05:20<00:38,  2.73s/it]Running inference:  92%|█████████▏| 144/157 [05:22<00:33,  2.57s/it]Running inference:  92%|█████████▏| 145/157 [05:24<00:30,  2.52s/it]Running inference:  93%|█████████▎| 146/157 [05:26<00:26,  2.37s/it]Running inference:  94%|█████████▎| 147/157 [05:29<00:22,  2.29s/it]Running inference:  94%|█████████▍| 148/157 [05:31<00:20,  2.25s/it]Running inference:  95%|█████████▍| 149/157 [05:33<00:17,  2.18s/it]Running inference:  96%|█████████▌| 150/157 [05:35<00:15,  2.28s/it]Running inference:  96%|█████████▌| 151/157 [05:38<00:14,  2.37s/it]Running inference:  97%|█████████▋| 152/157 [05:40<00:11,  2.24s/it]Running inference:  97%|█████████▋| 153/157 [05:42<00:08,  2.23s/it]Running inference:  98%|█████████▊| 154/157 [05:44<00:06,  2.18s/it]Running inference:  99%|█████████▊| 155/157 [05:46<00:04,  2.10s/it]Running inference:  99%|█████████▉| 156/157 [05:48<00:02,  2.19s/it]Running inference: 100%|██████████| 157/157 [05:49<00:00,  1.70s/it]Running inference: 100%|██████████| 157/157 [05:49<00:00,  2.23s/it]
23:31:28 - INFO - [inference_test] Duration: 349401.96ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
23:31:28 - INFO -     Inference: 698.54s for 10000 samples (14.32 samples/sec)
23:31:28 - INFO - Initialized ProbabilityExtractor
23:31:28 - INFO -   Temperature: 1.0
23:31:28 - INFO -   Calibration method: None
23:31:29 - INFO - [probability_extraction] Duration: 257.17ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
23:31:29 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_phi-2_qa_float16_base_20251207_231938.npz
23:31:29 - INFO - Initialized LACScorer
23:31:29 - INFO -   Alpha: 0.1
23:31:29 - INFO -   Target coverage: 90.0%
23:31:29 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
23:31:29 - INFO - Initialized PredictionSetGenerator
23:31:29 - INFO -   Methods: ['lac']
23:31:29 - INFO -   Alpha: 0.1
23:31:29 - INFO -   Aggregation: separate
23:31:29 - INFO - Calibrating 1 conformal predictors...
23:31:29 - INFO -   Calibrating LAC...
23:31:29 - INFO - Calibrating with 4998 samples...
23:31:29 - INFO - Calibration complete
23:31:29 - INFO -   Threshold: 0.9863
23:31:29 - INFO -   Score range: [0.0005, 1.0000]
23:31:29 - INFO - Calibration complete
23:31:29 - INFO - Generating prediction sets using LAC...
23:31:29 - INFO - Generating prediction sets for 5002 test instances...
23:31:29 - INFO - Prediction complete
23:31:29 - INFO -   Average set size: 5.39
23:31:29 - INFO -   Coverage rate: 90.34%
23:31:29 - INFO -   Meets coverage guarantee: True
23:31:29 - INFO - [PASS] Coverage guarantee met: 90.34% >= 90.00%
23:31:29 - INFO -     LAC: Acc=21.65%, CR=90.34%, SS=5.39
23:31:29 - INFO - Initialized APSScorer
23:31:29 - INFO -   Alpha: 0.1
23:31:29 - INFO -   Target coverage: 90.0%
23:31:29 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
23:31:29 - INFO - Initialized PredictionSetGenerator
23:31:29 - INFO -   Methods: ['aps']
23:31:29 - INFO -   Alpha: 0.1
23:31:29 - INFO -   Aggregation: separate
23:31:29 - INFO - Calibrating 1 conformal predictors...
23:31:29 - INFO -   Calibrating APS...
23:31:29 - INFO - Calibrating with 4998 samples...
23:31:29 - INFO - Calibration complete
23:31:29 - INFO -   Threshold: 1.0000
23:31:29 - INFO -   Score range: [0.2081, 1.0000]
23:31:29 - INFO - Calibration complete
23:31:29 - INFO - Generating prediction sets using APS...
23:31:29 - INFO - Generating prediction sets for 5002 test instances...
23:31:29 - INFO - Prediction complete
23:31:29 - INFO -   Average set size: 5.84
23:31:29 - INFO -   Coverage rate: 97.72%
23:31:29 - INFO -   Meets coverage guarantee: True
23:31:29 - INFO - [PASS] Coverage guarantee met: 97.72% >= 90.00%
23:31:29 - INFO -     APS: Acc=21.65%, CR=97.72%, SS=5.84
23:31:35 - INFO - Unloaded model: phi-2_float16
23:31:36 - INFO - Checkpoint saved after completing: phi-2 | qa | float16
23:31:36 - INFO - 
================================================================================
23:31:36 - INFO - Run 2/5: phi-2 | rc | float16
23:31:36 - INFO - ================================================================================
23:31:36 - INFO - [start_phi-2_rc] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 0.0%
23:31:36 - INFO - Loading rc dataset (10000 samples)...
23:31:36 - INFO - Loading CosmosQA dataset with 10000 samples...
23:31:36 - INFO - CosmosQA loaded successfully with standard method
23:31:38 - INFO - Loaded 10000 CosmosQA instances
23:31:38 - INFO - [dataset_loading] Duration: 1863.02ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:31:38 - INFO - Processing rc dataset to 6-option format...
23:31:38 - INFO - Processed 10000 instances for rc
23:31:38 - INFO - Splitting rc dataset (calibration: 50%, test: 50%)
23:31:38 - INFO - Split complete:
23:31:38 - INFO -   Calibration: 4999 instances
23:31:38 - INFO -   Test: 5001 instances
23:31:38 - INFO - Answer distribution:
23:31:38 - INFO -   Calibration: {'A': 1240, 'B': 1245, 'C': 1263, 'D': 1251}
23:31:38 - INFO -   Test: {'A': 1241, 'B': 1245, 'C': 1264, 'D': 1251}
23:31:38 - INFO - [dataset_processing] Duration: 288.09ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:31:38 - INFO - Initialized DemonstrationSelector
23:31:38 - INFO -   Strategy: random
23:31:38 - INFO -   Num demonstrations: 5
23:31:38 - INFO - Initialized DemonstrationManager
23:31:38 - INFO - Selecting 5 demonstrations using 'random' strategy
23:31:38 - INFO - Selected and cached 5 demonstrations for rc
23:31:38 - INFO - Loading model: phi-2 (float16)
23:31:38 - INFO - Loading model: phi-2_float16 (microsoft/phi-2)
23:31:38 - INFO - Loading tokenizer from microsoft/phi-2
23:31:38 - INFO - Tokenizer loaded successfully
23:31:38 - INFO -   Vocab size: 50295
23:31:38 - INFO -   Padding side: left
23:31:38 - INFO -   PAD token: <|endoftext|> (ID: 50256)
23:31:38 - INFO - Loading model from microsoft/phi-2
23:31:38 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.28it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]
23:31:40 - INFO - Model loaded successfully
23:31:40 - INFO -   GPU Memory: 5.19GB allocated, 5.21GB reserved

Model: phi-2_float16
  ID: microsoft/phi-2
  Type: causal
  Parameters: 2,779,683,840
  Vocab size: 50,295
  Max length: 2048
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: False
23:31:40 - INFO - [model_loading] Duration: 2194.20ms | GPU Memory: 9.1MB -> 5311.0MB (delta +5301.8MB)
23:31:40 - INFO - [after_model_load_phi-2] GPU State: Allocated: 5311.0MB | Reserved: 5334.0MB | Free: 75844.8MB | Utilization: 20.0%
23:31:40 - INFO - Using batch size: 32
23:31:40 - INFO -   Strategy: base
23:31:40 - INFO - Initialized PromptBuilder for task: rc
23:31:40 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
23:31:40 - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
23:31:40 - INFO - Initialized InferenceEngine for phi-2_float16
23:31:40 - INFO -   Device: cuda:0
23:31:40 - INFO -   Batch size: 32
23:31:40 - INFO -   Option tokens: {'A': 317, 'B': 347, 'C': 327, 'D': 360, 'E': 412, 'F': 376}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<04:27,  1.72s/it]Running inference:   1%|▏         | 2/157 [00:03<04:31,  1.75s/it]Running inference:   2%|▏         | 3/157 [00:05<04:27,  1.74s/it]Running inference:   3%|▎         | 4/157 [00:07<04:29,  1.76s/it]Running inference:   3%|▎         | 5/157 [00:08<04:26,  1.76s/it]Running inference:   4%|▍         | 6/157 [00:10<04:28,  1.78s/it]Running inference:   4%|▍         | 7/157 [00:12<04:25,  1.77s/it]Running inference:   5%|▌         | 8/157 [00:14<04:24,  1.78s/it]Running inference:   6%|▌         | 9/157 [00:15<04:22,  1.78s/it]Running inference:   6%|▋         | 10/157 [00:17<04:22,  1.79s/it]Running inference:   7%|▋         | 11/157 [00:19<04:23,  1.80s/it]Running inference:   8%|▊         | 12/157 [00:21<04:22,  1.81s/it]Running inference:   8%|▊         | 13/157 [00:23<04:20,  1.81s/it]Running inference:   9%|▉         | 14/157 [00:24<04:17,  1.80s/it]Running inference:  10%|▉         | 15/157 [00:26<04:14,  1.79s/it]Running inference:  10%|█         | 16/157 [00:28<04:13,  1.80s/it]Running inference:  11%|█         | 17/157 [00:30<04:13,  1.81s/it]Running inference:  11%|█▏        | 18/157 [00:32<04:15,  1.84s/it]Running inference:  12%|█▏        | 19/157 [00:34<04:14,  1.84s/it]Running inference:  13%|█▎        | 20/157 [00:35<04:11,  1.84s/it]Running inference:  13%|█▎        | 21/157 [00:37<04:08,  1.83s/it]Running inference:  14%|█▍        | 22/157 [00:39<04:05,  1.82s/it]Running inference:  15%|█▍        | 23/157 [00:41<04:04,  1.82s/it]Running inference:  15%|█▌        | 24/157 [00:43<04:02,  1.82s/it]Running inference:  16%|█▌        | 25/157 [00:44<03:56,  1.79s/it]Running inference:  17%|█▋        | 26/157 [00:46<03:58,  1.82s/it]Running inference:  17%|█▋        | 27/157 [00:48<03:55,  1.82s/it]Running inference:  18%|█▊        | 28/157 [00:50<03:55,  1.82s/it]Running inference:  18%|█▊        | 29/157 [00:52<03:52,  1.81s/it]Running inference:  19%|█▉        | 30/157 [00:54<03:49,  1.81s/it]Running inference:  20%|█▉        | 31/157 [00:55<03:48,  1.81s/it]Running inference:  20%|██        | 32/157 [00:57<03:44,  1.80s/it]Running inference:  21%|██        | 33/157 [00:59<03:44,  1.81s/it]Running inference:  22%|██▏       | 34/157 [01:01<03:40,  1.80s/it]Running inference:  22%|██▏       | 35/157 [01:03<03:39,  1.80s/it]Running inference:  23%|██▎       | 36/157 [01:04<03:38,  1.80s/it]Running inference:  24%|██▎       | 37/157 [01:06<03:37,  1.81s/it]Running inference:  24%|██▍       | 38/157 [01:08<03:36,  1.82s/it]Running inference:  25%|██▍       | 39/157 [01:10<03:34,  1.82s/it]Running inference:  25%|██▌       | 40/157 [01:12<03:32,  1.81s/it]Running inference:  26%|██▌       | 41/157 [01:13<03:30,  1.82s/it]Running inference:  27%|██▋       | 42/157 [01:15<03:28,  1.81s/it]Running inference:  27%|██▋       | 43/157 [01:17<03:26,  1.81s/it]Running inference:  28%|██▊       | 44/157 [01:19<03:24,  1.81s/it]Running inference:  29%|██▊       | 45/157 [01:21<03:21,  1.80s/it]Running inference:  29%|██▉       | 46/157 [01:22<03:18,  1.79s/it]Running inference:  30%|██▉       | 47/157 [01:24<03:17,  1.79s/it]Running inference:  31%|███       | 48/157 [01:26<03:14,  1.79s/it]Running inference:  31%|███       | 49/157 [01:28<03:12,  1.78s/it]Running inference:  32%|███▏      | 50/157 [01:30<03:15,  1.82s/it]Running inference:  32%|███▏      | 51/157 [01:32<03:13,  1.82s/it]Running inference:  33%|███▎      | 52/157 [01:33<03:10,  1.81s/it]Running inference:  34%|███▍      | 53/157 [01:35<03:08,  1.81s/it]Running inference:  34%|███▍      | 54/157 [01:37<03:06,  1.81s/it]Running inference:  35%|███▌      | 55/157 [01:39<03:04,  1.81s/it]Running inference:  36%|███▌      | 56/157 [01:40<03:01,  1.80s/it]Running inference:  36%|███▋      | 57/157 [01:42<03:00,  1.81s/it]Running inference:  37%|███▋      | 58/157 [01:44<02:57,  1.79s/it]Running inference:  38%|███▊      | 59/157 [01:46<02:55,  1.79s/it]Running inference:  38%|███▊      | 60/157 [01:48<02:53,  1.79s/it]Running inference:  39%|███▉      | 61/157 [01:49<02:51,  1.78s/it]Running inference:  39%|███▉      | 62/157 [01:51<02:51,  1.80s/it]Running inference:  40%|████      | 63/157 [01:53<02:48,  1.79s/it]Running inference:  41%|████      | 64/157 [01:55<02:48,  1.81s/it]Running inference:  41%|████▏     | 65/157 [01:57<02:45,  1.80s/it]Running inference:  42%|████▏     | 66/157 [01:58<02:42,  1.79s/it]Running inference:  43%|████▎     | 67/157 [02:00<02:41,  1.79s/it]Running inference:  43%|████▎     | 68/157 [02:02<02:39,  1.79s/it]Running inference:  44%|████▍     | 69/157 [02:04<02:38,  1.80s/it]Running inference:  45%|████▍     | 70/157 [02:06<02:37,  1.81s/it]Running inference:  45%|████▌     | 71/157 [02:07<02:35,  1.81s/it]Running inference:  46%|████▌     | 72/157 [02:09<02:32,  1.80s/it]Running inference:  46%|████▋     | 73/157 [02:11<02:32,  1.81s/it]Running inference:  47%|████▋     | 74/157 [02:13<02:28,  1.79s/it]Running inference:  48%|████▊     | 75/157 [02:15<02:26,  1.78s/it]Running inference:  48%|████▊     | 76/157 [02:17<02:27,  1.82s/it]Running inference:  49%|████▉     | 77/157 [02:18<02:25,  1.82s/it]Running inference:  50%|████▉     | 78/157 [02:20<02:21,  1.79s/it]Running inference:  50%|█████     | 79/157 [02:22<02:19,  1.79s/it]Running inference:  51%|█████     | 80/157 [02:24<02:17,  1.78s/it]Running inference:  52%|█████▏    | 81/157 [02:25<02:14,  1.77s/it]Running inference:  52%|█████▏    | 82/157 [02:27<02:12,  1.77s/it]Running inference:  53%|█████▎    | 83/157 [02:29<02:12,  1.79s/it]Running inference:  54%|█████▎    | 84/157 [02:31<02:10,  1.79s/it]Running inference:  54%|█████▍    | 85/157 [02:32<02:08,  1.78s/it]Running inference:  55%|█████▍    | 86/157 [02:34<02:07,  1.79s/it]Running inference:  55%|█████▌    | 87/157 [02:36<02:05,  1.79s/it]Running inference:  56%|█████▌    | 88/157 [02:38<02:03,  1.79s/it]Running inference:  57%|█████▋    | 89/157 [02:40<02:02,  1.80s/it]Running inference:  57%|█████▋    | 90/157 [02:42<02:00,  1.80s/it]Running inference:  58%|█████▊    | 91/157 [02:43<01:59,  1.81s/it]Running inference:  59%|█████▊    | 92/157 [02:45<01:56,  1.80s/it]Running inference:  59%|█████▉    | 93/157 [02:47<01:55,  1.80s/it]Running inference:  60%|█████▉    | 94/157 [02:49<01:53,  1.80s/it]Running inference:  61%|██████    | 95/157 [02:50<01:50,  1.79s/it]Running inference:  61%|██████    | 96/157 [02:52<01:48,  1.78s/it]Running inference:  62%|██████▏   | 97/157 [02:54<01:47,  1.79s/it]Running inference:  62%|██████▏   | 98/157 [02:56<01:46,  1.81s/it]Running inference:  63%|██████▎   | 99/157 [02:58<01:45,  1.81s/it]Running inference:  64%|██████▎   | 100/157 [03:00<01:43,  1.82s/it]Running inference:  64%|██████▍   | 101/157 [03:01<01:41,  1.81s/it]Running inference:  65%|██████▍   | 102/157 [03:03<01:39,  1.80s/it]Running inference:  66%|██████▌   | 103/157 [03:05<01:36,  1.79s/it]Running inference:  66%|██████▌   | 104/157 [03:07<01:34,  1.79s/it]Running inference:  67%|██████▋   | 105/157 [03:09<01:33,  1.80s/it]Running inference:  68%|██████▊   | 106/157 [03:10<01:32,  1.81s/it]Running inference:  68%|██████▊   | 107/157 [03:12<01:30,  1.81s/it]Running inference:  69%|██████▉   | 108/157 [03:14<01:28,  1.80s/it]Running inference:  69%|██████▉   | 109/157 [03:16<01:25,  1.78s/it]Running inference:  70%|███████   | 110/157 [03:17<01:24,  1.79s/it]Running inference:  71%|███████   | 111/157 [03:19<01:22,  1.79s/it]Running inference:  71%|███████▏  | 112/157 [03:21<01:20,  1.79s/it]Running inference:  72%|███████▏  | 113/157 [03:23<01:19,  1.80s/it]Running inference:  73%|███████▎  | 114/157 [03:25<01:16,  1.79s/it]Running inference:  73%|███████▎  | 115/157 [03:26<01:15,  1.80s/it]Running inference:  74%|███████▍  | 116/157 [03:28<01:13,  1.79s/it]Running inference:  75%|███████▍  | 117/157 [03:30<01:11,  1.78s/it]Running inference:  75%|███████▌  | 118/157 [03:32<01:09,  1.78s/it]Running inference:  76%|███████▌  | 119/157 [03:34<01:07,  1.77s/it]Running inference:  76%|███████▋  | 120/157 [03:35<01:06,  1.79s/it]Running inference:  77%|███████▋  | 121/157 [03:37<01:04,  1.79s/it]Running inference:  78%|███████▊  | 122/157 [03:39<01:02,  1.79s/it]Running inference:  78%|███████▊  | 123/157 [03:41<01:00,  1.79s/it]Running inference:  79%|███████▉  | 124/157 [03:42<00:58,  1.78s/it]Running inference:  80%|███████▉  | 125/157 [03:44<00:56,  1.78s/it]Running inference:  80%|████████  | 126/157 [03:46<00:55,  1.79s/it]Running inference:  81%|████████  | 127/157 [03:48<00:54,  1.80s/it]Running inference:  82%|████████▏ | 128/157 [03:50<00:52,  1.80s/it]Running inference:  82%|████████▏ | 129/157 [03:52<00:50,  1.81s/it]Running inference:  83%|████████▎ | 130/157 [03:53<00:48,  1.81s/it]Running inference:  83%|████████▎ | 131/157 [03:55<00:46,  1.79s/it]Running inference:  84%|████████▍ | 132/157 [03:57<00:44,  1.79s/it]Running inference:  85%|████████▍ | 133/157 [03:59<00:43,  1.80s/it]Running inference:  85%|████████▌ | 134/157 [04:00<00:41,  1.80s/it]Running inference:  86%|████████▌ | 135/157 [04:02<00:39,  1.81s/it]Running inference:  87%|████████▋ | 136/157 [04:04<00:37,  1.80s/it]Running inference:  87%|████████▋ | 137/157 [04:06<00:35,  1.79s/it]Running inference:  88%|████████▊ | 138/157 [04:08<00:34,  1.80s/it]Running inference:  89%|████████▊ | 139/157 [04:09<00:32,  1.80s/it]Running inference:  89%|████████▉ | 140/157 [04:11<00:30,  1.80s/it]Running inference:  90%|████████▉ | 141/157 [04:13<00:28,  1.81s/it]Running inference:  90%|█████████ | 142/157 [04:15<00:27,  1.81s/it]Running inference:  91%|█████████ | 143/157 [04:17<00:25,  1.81s/it]Running inference:  92%|█████████▏| 144/157 [04:19<00:23,  1.81s/it]Running inference:  92%|█████████▏| 145/157 [04:20<00:21,  1.82s/it]Running inference:  93%|█████████▎| 146/157 [04:22<00:20,  1.84s/it]Running inference:  94%|█████████▎| 147/157 [04:24<00:18,  1.82s/it]Running inference:  94%|█████████▍| 148/157 [04:26<00:16,  1.82s/it]Running inference:  95%|█████████▍| 149/157 [04:28<00:14,  1.81s/it]Running inference:  96%|█████████▌| 150/157 [04:30<00:12,  1.82s/it]Running inference:  96%|█████████▌| 151/157 [04:31<00:10,  1.83s/it]Running inference:  97%|█████████▋| 152/157 [04:33<00:09,  1.81s/it]Running inference:  97%|█████████▋| 153/157 [04:35<00:07,  1.81s/it]Running inference:  98%|█████████▊| 154/157 [04:37<00:05,  1.81s/it]Running inference:  99%|█████████▊| 155/157 [04:39<00:03,  1.80s/it]Running inference:  99%|█████████▉| 156/157 [04:40<00:01,  1.79s/it]Running inference: 100%|██████████| 157/157 [04:41<00:00,  1.38s/it]Running inference: 100%|██████████| 157/157 [04:41<00:00,  1.79s/it]
23:36:21 - INFO - [inference_calibration] Duration: 281212.78ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<04:42,  1.81s/it]Running inference:   1%|▏         | 2/157 [00:03<04:36,  1.79s/it]Running inference:   2%|▏         | 3/157 [00:05<04:37,  1.80s/it]Running inference:   3%|▎         | 4/157 [00:07<04:34,  1.80s/it]Running inference:   3%|▎         | 5/157 [00:08<04:33,  1.80s/it]Running inference:   4%|▍         | 6/157 [00:10<04:31,  1.80s/it]Running inference:   4%|▍         | 7/157 [00:12<04:30,  1.80s/it]Running inference:   5%|▌         | 8/157 [00:14<04:30,  1.81s/it]Running inference:   6%|▌         | 9/157 [00:16<04:27,  1.81s/it]Running inference:   6%|▋         | 10/157 [00:17<04:23,  1.79s/it]Running inference:   7%|▋         | 11/157 [00:19<04:21,  1.79s/it]Running inference:   8%|▊         | 12/157 [00:21<04:18,  1.78s/it]Running inference:   8%|▊         | 13/157 [00:23<04:16,  1.78s/it]Running inference:   9%|▉         | 14/157 [00:25<04:14,  1.78s/it]Running inference:  10%|▉         | 15/157 [00:26<04:12,  1.78s/it]Running inference:  10%|█         | 16/157 [00:28<04:10,  1.78s/it]Running inference:  11%|█         | 17/157 [00:30<04:08,  1.78s/it]Running inference:  11%|█▏        | 18/157 [00:32<04:05,  1.77s/it]Running inference:  12%|█▏        | 19/157 [00:33<04:04,  1.77s/it]Running inference:  13%|█▎        | 20/157 [00:35<04:04,  1.78s/it]Running inference:  13%|█▎        | 21/157 [00:37<04:04,  1.79s/it]Running inference:  14%|█▍        | 22/157 [00:39<04:00,  1.78s/it]Running inference:  15%|█▍        | 23/157 [00:41<04:01,  1.80s/it]Running inference:  15%|█▌        | 24/157 [00:42<03:59,  1.80s/it]Running inference:  16%|█▌        | 25/157 [00:44<04:01,  1.83s/it]Running inference:  17%|█▋        | 26/157 [00:46<03:57,  1.81s/it]Running inference:  17%|█▋        | 27/157 [00:48<03:54,  1.80s/it]Running inference:  18%|█▊        | 28/157 [00:50<03:51,  1.79s/it]Running inference:  18%|█▊        | 29/157 [00:52<03:54,  1.83s/it]Running inference:  19%|█▉        | 30/157 [00:53<03:50,  1.81s/it]Running inference:  20%|█▉        | 31/157 [00:55<03:48,  1.81s/it]Running inference:  20%|██        | 32/157 [00:57<03:47,  1.82s/it]Running inference:  21%|██        | 33/157 [00:59<03:45,  1.82s/it]Running inference:  22%|██▏       | 34/157 [01:01<03:47,  1.85s/it]Running inference:  22%|██▏       | 35/157 [01:03<03:44,  1.84s/it]Running inference:  23%|██▎       | 36/157 [01:04<03:41,  1.83s/it]Running inference:  24%|██▎       | 37/157 [01:06<03:38,  1.82s/it]Running inference:  24%|██▍       | 38/157 [01:08<03:35,  1.82s/it]Running inference:  25%|██▍       | 39/157 [01:10<03:31,  1.79s/it]Running inference:  25%|██▌       | 40/157 [01:12<03:30,  1.80s/it]Running inference:  26%|██▌       | 41/157 [01:13<03:30,  1.81s/it]Running inference:  27%|██▋       | 42/157 [01:15<03:28,  1.82s/it]Running inference:  27%|██▋       | 43/157 [01:17<03:27,  1.82s/it]Running inference:  28%|██▊       | 44/157 [01:19<03:24,  1.81s/it]Running inference:  29%|██▊       | 45/157 [01:21<03:22,  1.81s/it]Running inference:  29%|██▉       | 46/157 [01:22<03:21,  1.82s/it]Running inference:  30%|██▉       | 47/157 [01:24<03:19,  1.81s/it]Running inference:  31%|███       | 48/157 [01:26<03:16,  1.80s/it]Running inference:  31%|███       | 49/157 [01:28<03:15,  1.81s/it]Running inference:  32%|███▏      | 50/157 [01:30<03:13,  1.81s/it]Running inference:  32%|███▏      | 51/157 [01:31<03:09,  1.79s/it]Running inference:  33%|███▎      | 52/157 [01:33<03:11,  1.82s/it]Running inference:  34%|███▍      | 53/157 [01:35<03:09,  1.82s/it]Running inference:  34%|███▍      | 54/157 [01:37<03:06,  1.81s/it]Running inference:  35%|███▌      | 55/157 [01:39<03:05,  1.81s/it]Running inference:  36%|███▌      | 56/157 [01:41<03:01,  1.80s/it]Running inference:  36%|███▋      | 57/157 [01:42<02:57,  1.78s/it]Running inference:  37%|███▋      | 58/157 [01:44<02:55,  1.78s/it]Running inference:  38%|███▊      | 59/157 [01:46<02:54,  1.78s/it]Running inference:  38%|███▊      | 60/157 [01:48<02:53,  1.79s/it]Running inference:  39%|███▉      | 61/157 [01:49<02:53,  1.80s/it]Running inference:  39%|███▉      | 62/157 [01:51<02:50,  1.80s/it]Running inference:  40%|████      | 63/157 [01:53<02:48,  1.79s/it]Running inference:  41%|████      | 64/157 [01:55<02:47,  1.80s/it]Running inference:  41%|████▏     | 65/157 [01:57<02:46,  1.81s/it]Running inference:  42%|████▏     | 66/157 [01:58<02:43,  1.80s/it]Running inference:  43%|████▎     | 67/157 [02:00<02:40,  1.78s/it]Running inference:  43%|████▎     | 68/157 [02:02<02:37,  1.77s/it]Running inference:  44%|████▍     | 69/157 [02:04<02:35,  1.76s/it]Running inference:  45%|████▍     | 70/157 [02:05<02:34,  1.78s/it]Running inference:  45%|████▌     | 71/157 [02:07<02:33,  1.79s/it]Running inference:  46%|████▌     | 72/157 [02:09<02:33,  1.80s/it]Running inference:  46%|████▋     | 73/157 [02:11<02:32,  1.82s/it]Running inference:  47%|████▋     | 74/157 [02:13<02:30,  1.81s/it]Running inference:  48%|████▊     | 75/157 [02:15<02:27,  1.80s/it]Running inference:  48%|████▊     | 76/157 [02:16<02:25,  1.79s/it]Running inference:  49%|████▉     | 77/157 [02:18<02:24,  1.80s/it]Running inference:  50%|████▉     | 78/157 [02:20<02:21,  1.80s/it]Running inference:  50%|█████     | 79/157 [02:22<02:21,  1.81s/it]Running inference:  51%|█████     | 80/157 [02:24<02:19,  1.81s/it]Running inference:  52%|█████▏    | 81/157 [02:25<02:18,  1.82s/it]Running inference:  52%|█████▏    | 82/157 [02:27<02:15,  1.81s/it]Running inference:  53%|█████▎    | 83/157 [02:29<02:13,  1.80s/it]Running inference:  54%|█████▎    | 84/157 [02:31<02:12,  1.81s/it]Running inference:  54%|█████▍    | 85/157 [02:33<02:09,  1.80s/it]Running inference:  55%|█████▍    | 86/157 [02:34<02:08,  1.81s/it]Running inference:  55%|█████▌    | 87/157 [02:36<02:08,  1.83s/it]Running inference:  56%|█████▌    | 88/157 [02:38<02:05,  1.83s/it]Running inference:  57%|█████▋    | 89/157 [02:40<02:04,  1.83s/it]Running inference:  57%|█████▋    | 90/157 [02:42<02:02,  1.83s/it]Running inference:  58%|█████▊    | 91/157 [02:44<02:00,  1.82s/it]Running inference:  59%|█████▊    | 92/157 [02:45<01:57,  1.81s/it]Running inference:  59%|█████▉    | 93/157 [02:47<01:55,  1.80s/it]Running inference:  60%|█████▉    | 94/157 [02:49<01:53,  1.80s/it]Running inference:  61%|██████    | 95/157 [02:51<01:51,  1.80s/it]Running inference:  61%|██████    | 96/157 [02:53<01:49,  1.80s/it]Running inference:  62%|██████▏   | 97/157 [02:54<01:47,  1.79s/it]Running inference:  62%|██████▏   | 98/157 [02:56<01:44,  1.76s/it]Running inference:  63%|██████▎   | 99/157 [02:58<01:43,  1.78s/it]Running inference:  64%|██████▎   | 100/157 [03:00<01:42,  1.79s/it]Running inference:  64%|██████▍   | 101/157 [03:01<01:40,  1.80s/it]Running inference:  65%|██████▍   | 102/157 [03:03<01:38,  1.79s/it]Running inference:  66%|██████▌   | 103/157 [03:05<01:37,  1.81s/it]Running inference:  66%|██████▌   | 104/157 [03:07<01:35,  1.80s/it]Running inference:  67%|██████▋   | 105/157 [03:09<01:33,  1.79s/it]Running inference:  68%|██████▊   | 106/157 [03:11<01:33,  1.83s/it]Running inference:  68%|██████▊   | 107/157 [03:12<01:31,  1.83s/it]Running inference:  69%|██████▉   | 108/157 [03:14<01:29,  1.83s/it]Running inference:  69%|██████▉   | 109/157 [03:16<01:27,  1.83s/it]Running inference:  70%|███████   | 110/157 [03:18<01:25,  1.83s/it]Running inference:  71%|███████   | 111/157 [03:20<01:23,  1.81s/it]Running inference:  71%|███████▏  | 112/157 [03:21<01:20,  1.80s/it]Running inference:  72%|███████▏  | 113/157 [03:23<01:19,  1.81s/it]Running inference:  73%|███████▎  | 114/157 [03:25<01:17,  1.81s/it]Running inference:  73%|███████▎  | 115/157 [03:27<01:15,  1.81s/it]Running inference:  74%|███████▍  | 116/157 [03:29<01:14,  1.80s/it]Running inference:  75%|███████▍  | 117/157 [03:30<01:12,  1.81s/it]Running inference:  75%|███████▌  | 118/157 [03:32<01:10,  1.81s/it]Running inference:  76%|███████▌  | 119/157 [03:34<01:08,  1.81s/it]Running inference:  76%|███████▋  | 120/157 [03:36<01:08,  1.84s/it]Running inference:  77%|███████▋  | 121/157 [03:38<01:05,  1.82s/it]Running inference:  78%|███████▊  | 122/157 [03:40<01:04,  1.85s/it]Running inference:  78%|███████▊  | 123/157 [03:42<01:02,  1.84s/it]Running inference:  79%|███████▉  | 124/157 [03:43<01:00,  1.82s/it]Running inference:  80%|███████▉  | 125/157 [03:45<00:58,  1.81s/it]Running inference:  80%|████████  | 126/157 [03:47<00:56,  1.82s/it]Running inference:  81%|████████  | 127/157 [03:49<00:54,  1.82s/it]Running inference:  82%|████████▏ | 128/157 [03:51<00:52,  1.80s/it]Running inference:  82%|████████▏ | 129/157 [03:52<00:50,  1.80s/it]Running inference:  83%|████████▎ | 130/157 [03:54<00:48,  1.81s/it]Running inference:  83%|████████▎ | 131/157 [03:56<00:47,  1.81s/it]Running inference:  84%|████████▍ | 132/157 [03:58<00:44,  1.79s/it]Running inference:  85%|████████▍ | 133/157 [04:00<00:43,  1.80s/it]Running inference:  85%|████████▌ | 134/157 [04:01<00:41,  1.80s/it]Running inference:  86%|████████▌ | 135/157 [04:03<00:39,  1.80s/it]Running inference:  87%|████████▋ | 136/157 [04:05<00:37,  1.81s/it]Running inference:  87%|████████▋ | 137/157 [04:07<00:36,  1.81s/it]Running inference:  88%|████████▊ | 138/157 [04:09<00:34,  1.81s/it]Running inference:  89%|████████▊ | 139/157 [04:10<00:32,  1.82s/it]Running inference:  89%|████████▉ | 140/157 [04:12<00:30,  1.82s/it]Running inference:  90%|████████▉ | 141/157 [04:14<00:29,  1.81s/it]Running inference:  90%|█████████ | 142/157 [04:16<00:27,  1.80s/it]Running inference:  91%|█████████ | 143/157 [04:18<00:25,  1.80s/it]Running inference:  92%|█████████▏| 144/157 [04:19<00:23,  1.80s/it]Running inference:  92%|█████████▏| 145/157 [04:21<00:21,  1.83s/it]Running inference:  93%|█████████▎| 146/157 [04:23<00:20,  1.83s/it]Running inference:  94%|█████████▎| 147/157 [04:25<00:18,  1.82s/it]Running inference:  94%|█████████▍| 148/157 [04:27<00:16,  1.81s/it]Running inference:  95%|█████████▍| 149/157 [04:29<00:14,  1.81s/it]Running inference:  96%|█████████▌| 150/157 [04:30<00:12,  1.81s/it]Running inference:  96%|█████████▌| 151/157 [04:32<00:10,  1.81s/it]Running inference:  97%|█████████▋| 152/157 [04:34<00:09,  1.83s/it]Running inference:  97%|█████████▋| 153/157 [04:36<00:07,  1.82s/it]Running inference:  98%|█████████▊| 154/157 [04:38<00:05,  1.80s/it]Running inference:  99%|█████████▊| 155/157 [04:39<00:03,  1.81s/it]Running inference:  99%|█████████▉| 156/157 [04:41<00:01,  1.79s/it]Running inference: 100%|██████████| 157/157 [04:42<00:00,  1.40s/it]Running inference: 100%|██████████| 157/157 [04:42<00:00,  1.80s/it]
23:41:04 - INFO - [inference_test] Duration: 282117.88ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
23:41:04 - INFO -     Inference: 563.33s for 10000 samples (17.75 samples/sec)
23:41:04 - INFO - Initialized ProbabilityExtractor
23:41:04 - INFO -   Temperature: 1.0
23:41:04 - INFO -   Calibration method: None
23:41:04 - INFO - [probability_extraction] Duration: 322.40ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
23:41:04 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_phi-2_rc_float16_base_20251207_231938.npz
23:41:04 - INFO - Initialized LACScorer
23:41:04 - INFO -   Alpha: 0.1
23:41:04 - INFO -   Target coverage: 90.0%
23:41:04 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
23:41:04 - INFO - Initialized PredictionSetGenerator
23:41:04 - INFO -   Methods: ['lac']
23:41:04 - INFO -   Alpha: 0.1
23:41:04 - INFO -   Aggregation: separate
23:41:04 - INFO - Calibrating 1 conformal predictors...
23:41:04 - INFO -   Calibrating LAC...
23:41:04 - INFO - Calibrating with 4999 samples...
23:41:04 - INFO - Calibration complete
23:41:04 - INFO -   Threshold: 0.9800
23:41:04 - INFO -   Score range: [0.0003, 1.0000]
23:41:04 - INFO - Calibration complete
23:41:04 - INFO - Generating prediction sets using LAC...
23:41:04 - INFO - Generating prediction sets for 5001 test instances...
23:41:04 - INFO - Prediction complete
23:41:04 - INFO -   Average set size: 5.24
23:41:04 - INFO -   Coverage rate: 90.90%
23:41:04 - INFO -   Meets coverage guarantee: True
23:41:04 - INFO - [PASS] Coverage guarantee met: 90.90% >= 90.00%
23:41:04 - INFO -     LAC: Acc=23.82%, CR=90.90%, SS=5.24
23:41:04 - INFO - Initialized APSScorer
23:41:04 - INFO -   Alpha: 0.1
23:41:04 - INFO -   Target coverage: 90.0%
23:41:04 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
23:41:04 - INFO - Initialized PredictionSetGenerator
23:41:04 - INFO -   Methods: ['aps']
23:41:04 - INFO -   Alpha: 0.1
23:41:04 - INFO -   Aggregation: separate
23:41:04 - INFO - Calibrating 1 conformal predictors...
23:41:04 - INFO -   Calibrating APS...
23:41:04 - INFO - Calibrating with 4999 samples...
23:41:04 - INFO - Calibration complete
23:41:04 - INFO -   Threshold: 1.0000
23:41:04 - INFO -   Score range: [0.2005, 1.0000]
23:41:04 - INFO - Calibration complete
23:41:04 - INFO - Generating prediction sets using APS...
23:41:04 - INFO - Generating prediction sets for 5001 test instances...
23:41:04 - INFO - Prediction complete
23:41:04 - INFO -   Average set size: 5.17
23:41:04 - INFO -   Coverage rate: 90.92%
23:41:04 - INFO -   Meets coverage guarantee: True
23:41:04 - INFO - [PASS] Coverage guarantee met: 90.92% >= 90.00%
23:41:04 - INFO -     APS: Acc=23.82%, CR=90.92%, SS=5.17
23:41:10 - INFO - Unloaded model: phi-2_float16
23:41:11 - INFO - Checkpoint saved after completing: phi-2 | rc | float16
23:41:11 - INFO - 
================================================================================
23:41:11 - INFO - Run 3/5: phi-2 | ci | float16
23:41:11 - INFO - ================================================================================
23:41:11 - INFO - [start_phi-2_ci] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 0.0%
23:41:11 - INFO - Loading ci dataset (10000 samples)...
23:41:11 - INFO - Loading HellaSwag dataset with 10000 samples...
23:41:15 - INFO - Loaded 10000 HellaSwag instances
23:41:15 - INFO - [dataset_loading] Duration: 4226.69ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:41:15 - INFO - Processing ci dataset to 6-option format...
23:41:15 - INFO - Processed 10000 instances for ci
23:41:15 - INFO - Splitting ci dataset (calibration: 50%, test: 50%)
23:41:15 - INFO - Split complete:
23:41:15 - INFO -   Calibration: 4999 instances
23:41:15 - INFO -   Test: 5001 instances
23:41:15 - INFO - Answer distribution:
23:41:15 - INFO -   Calibration: {'A': 1240, 'B': 1242, 'C': 1256, 'D': 1261}
23:41:15 - INFO -   Test: {'A': 1240, 'B': 1242, 'C': 1257, 'D': 1262}
23:41:15 - INFO - [dataset_processing] Duration: 224.73ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:41:15 - INFO - Initialized DemonstrationSelector
23:41:15 - INFO -   Strategy: random
23:41:15 - INFO -   Num demonstrations: 5
23:41:15 - INFO - Initialized DemonstrationManager
23:41:15 - INFO - Selecting 5 demonstrations using 'random' strategy
23:41:15 - INFO - Selected and cached 5 demonstrations for ci
23:41:15 - INFO - Loading model: phi-2 (float16)
23:41:15 - INFO - Loading model: phi-2_float16 (microsoft/phi-2)
23:41:15 - INFO - Loading tokenizer from microsoft/phi-2
23:41:16 - INFO - Tokenizer loaded successfully
23:41:16 - INFO -   Vocab size: 50295
23:41:16 - INFO -   Padding side: left
23:41:16 - INFO -   PAD token: <|endoftext|> (ID: 50256)
23:41:16 - INFO - Loading model from microsoft/phi-2
23:41:16 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]
23:41:18 - INFO - Model loaded successfully
23:41:18 - INFO -   GPU Memory: 5.19GB allocated, 5.21GB reserved

Model: phi-2_float16
  ID: microsoft/phi-2
  Type: causal
  Parameters: 2,779,683,840
  Vocab size: 50,295
  Max length: 2048
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: False
23:41:18 - INFO - [model_loading] Duration: 2202.44ms | GPU Memory: 9.1MB -> 5311.0MB (delta +5301.8MB)
23:41:18 - INFO - [after_model_load_phi-2] GPU State: Allocated: 5311.0MB | Reserved: 5334.0MB | Free: 75844.8MB | Utilization: 0.0%
23:41:18 - INFO - Using batch size: 32
23:41:18 - INFO -   Strategy: base
23:41:18 - INFO - Initialized PromptBuilder for task: ci
23:41:18 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
23:41:18 - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
23:41:18 - INFO - Initialized InferenceEngine for phi-2_float16
23:41:18 - INFO -   Device: cuda:0
23:41:18 - INFO -   Batch size: 32
23:41:18 - INFO -   Option tokens: {'A': 317, 'B': 347, 'C': 327, 'D': 360, 'E': 412, 'F': 376}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<04:44,  1.82s/it]Running inference:   1%|▏         | 2/157 [00:03<04:51,  1.88s/it]Running inference:   2%|▏         | 3/157 [00:05<04:44,  1.85s/it]Running inference:   3%|▎         | 4/157 [00:07<04:43,  1.85s/it]Running inference:   3%|▎         | 5/157 [00:09<04:38,  1.83s/it]Running inference:   4%|▍         | 6/157 [00:11<04:36,  1.83s/it]Running inference:   4%|▍         | 7/157 [00:12<04:33,  1.82s/it]Running inference:   5%|▌         | 8/157 [00:14<04:35,  1.85s/it]Running inference:   6%|▌         | 9/157 [00:16<04:33,  1.85s/it]Running inference:   6%|▋         | 10/157 [00:18<04:30,  1.84s/it]Running inference:   7%|▋         | 11/157 [00:20<04:27,  1.84s/it]Running inference:   8%|▊         | 12/157 [00:22<04:25,  1.83s/it]Running inference:   8%|▊         | 13/157 [00:23<04:25,  1.85s/it]Running inference:   9%|▉         | 14/157 [00:25<04:23,  1.84s/it]Running inference:  10%|▉         | 15/157 [00:27<04:21,  1.84s/it]Running inference:  10%|█         | 16/157 [00:29<04:19,  1.84s/it]Running inference:  11%|█         | 17/157 [00:31<04:16,  1.83s/it]Running inference:  11%|█▏        | 18/157 [00:33<04:13,  1.82s/it]Running inference:  12%|█▏        | 19/157 [00:34<04:11,  1.82s/it]Running inference:  13%|█▎        | 20/157 [00:36<04:12,  1.84s/it]Running inference:  13%|█▎        | 21/157 [00:38<04:09,  1.83s/it]Running inference:  14%|█▍        | 22/157 [00:40<04:05,  1.82s/it]Running inference:  15%|█▍        | 23/157 [00:42<04:04,  1.82s/it]Running inference:  15%|█▌        | 24/157 [00:44<04:01,  1.82s/it]Running inference:  16%|█▌        | 25/157 [00:45<03:59,  1.82s/it]Running inference:  17%|█▋        | 26/157 [00:47<03:58,  1.82s/it]Running inference:  17%|█▋        | 27/157 [00:49<03:57,  1.83s/it]Running inference:  18%|█▊        | 28/157 [00:51<03:55,  1.82s/it]Running inference:  18%|█▊        | 29/157 [00:53<03:54,  1.83s/it]Running inference:  19%|█▉        | 30/157 [00:54<03:52,  1.83s/it]Running inference:  20%|█▉        | 31/157 [00:56<03:49,  1.82s/it]Running inference:  20%|██        | 32/157 [00:58<03:48,  1.83s/it]Running inference:  21%|██        | 33/157 [01:00<03:46,  1.83s/it]Running inference:  22%|██▏       | 34/157 [01:02<03:44,  1.83s/it]Running inference:  22%|██▏       | 35/157 [01:04<03:42,  1.83s/it]Running inference:  23%|██▎       | 36/157 [01:05<03:41,  1.83s/it]Running inference:  24%|██▎       | 37/157 [01:07<03:42,  1.85s/it]Running inference:  24%|██▍       | 38/157 [01:09<03:39,  1.85s/it]Running inference:  25%|██▍       | 39/157 [01:11<03:37,  1.84s/it]Running inference:  25%|██▌       | 40/157 [01:13<03:34,  1.83s/it]Running inference:  26%|██▌       | 41/157 [01:15<03:31,  1.82s/it]Running inference:  27%|██▋       | 42/157 [01:16<03:30,  1.83s/it]Running inference:  27%|██▋       | 43/157 [01:18<03:29,  1.84s/it]Running inference:  28%|██▊       | 44/157 [01:20<03:26,  1.82s/it]Running inference:  29%|██▊       | 45/157 [01:22<03:24,  1.83s/it]Running inference:  29%|██▉       | 46/157 [01:24<03:23,  1.83s/it]Running inference:  30%|██▉       | 47/157 [01:26<03:20,  1.83s/it]Running inference:  31%|███       | 48/157 [01:27<03:19,  1.83s/it]Running inference:  31%|███       | 49/157 [01:29<03:19,  1.85s/it]Running inference:  32%|███▏      | 50/157 [01:31<03:17,  1.85s/it]Running inference:  32%|███▏      | 51/157 [01:33<03:15,  1.84s/it]Running inference:  33%|███▎      | 52/157 [01:35<03:16,  1.88s/it]Running inference:  34%|███▍      | 53/157 [01:37<03:13,  1.86s/it]Running inference:  34%|███▍      | 54/157 [01:39<03:11,  1.86s/it]Running inference:  35%|███▌      | 55/157 [01:40<03:07,  1.84s/it]Running inference:  36%|███▌      | 56/157 [01:42<03:05,  1.83s/it]Running inference:  36%|███▋      | 57/157 [01:44<03:03,  1.83s/it]Running inference:  37%|███▋      | 58/157 [01:46<03:00,  1.82s/it]Running inference:  38%|███▊      | 59/157 [01:48<02:58,  1.82s/it]Running inference:  38%|███▊      | 60/157 [01:50<02:56,  1.81s/it]Running inference:  39%|███▉      | 61/157 [01:51<02:54,  1.82s/it]Running inference:  39%|███▉      | 62/157 [01:53<02:53,  1.83s/it]Running inference:  40%|████      | 63/157 [01:55<02:52,  1.83s/it]Running inference:  41%|████      | 64/157 [01:57<02:50,  1.84s/it]Running inference:  41%|████▏     | 65/157 [01:59<02:49,  1.84s/it]Running inference:  42%|████▏     | 66/157 [02:01<02:46,  1.83s/it]Running inference:  43%|████▎     | 67/157 [02:02<02:44,  1.83s/it]Running inference:  43%|████▎     | 68/157 [02:04<02:42,  1.83s/it]Running inference:  44%|████▍     | 69/157 [02:06<02:41,  1.83s/it]Running inference:  45%|████▍     | 70/157 [02:08<02:41,  1.86s/it]Running inference:  45%|████▌     | 71/157 [02:10<02:38,  1.84s/it]Running inference:  46%|████▌     | 72/157 [02:12<02:36,  1.84s/it]Running inference:  46%|████▋     | 73/157 [02:13<02:33,  1.83s/it]Running inference:  47%|████▋     | 74/157 [02:15<02:31,  1.82s/it]Running inference:  48%|████▊     | 75/157 [02:17<02:29,  1.83s/it]Running inference:  48%|████▊     | 76/157 [02:19<02:27,  1.83s/it]Running inference:  49%|████▉     | 77/157 [02:21<02:26,  1.83s/it]Running inference:  50%|████▉     | 78/157 [02:23<02:24,  1.84s/it]Running inference:  50%|█████     | 79/157 [02:24<02:22,  1.82s/it]Running inference:  51%|█████     | 80/157 [02:26<02:20,  1.83s/it]Running inference:  52%|█████▏    | 81/157 [02:28<02:18,  1.82s/it]Running inference:  52%|█████▏    | 82/157 [02:30<02:17,  1.83s/it]Running inference:  53%|█████▎    | 83/157 [02:32<02:14,  1.82s/it]Running inference:  54%|█████▎    | 84/157 [02:33<02:12,  1.82s/it]Running inference:  54%|█████▍    | 85/157 [02:35<02:11,  1.83s/it]Running inference:  55%|█████▍    | 86/157 [02:37<02:10,  1.83s/it]Running inference:  55%|█████▌    | 87/157 [02:39<02:08,  1.83s/it]Running inference:  56%|█████▌    | 88/157 [02:41<02:06,  1.83s/it]Running inference:  57%|█████▋    | 89/157 [02:43<02:05,  1.84s/it]Running inference:  57%|█████▋    | 90/157 [02:45<02:03,  1.84s/it]Running inference:  58%|█████▊    | 91/157 [02:46<02:01,  1.84s/it]Running inference:  59%|█████▊    | 92/157 [02:48<01:59,  1.84s/it]Running inference:  59%|█████▉    | 93/157 [02:50<01:58,  1.85s/it]Running inference:  60%|█████▉    | 94/157 [02:52<01:56,  1.85s/it]Running inference:  61%|██████    | 95/157 [02:54<01:54,  1.85s/it]Running inference:  61%|██████    | 96/157 [02:56<01:52,  1.85s/it]Running inference:  62%|██████▏   | 97/157 [02:57<01:50,  1.84s/it]Running inference:  62%|██████▏   | 98/157 [02:59<01:48,  1.84s/it]Running inference:  63%|██████▎   | 99/157 [03:01<01:47,  1.85s/it]Running inference:  64%|██████▎   | 100/157 [03:03<01:45,  1.85s/it]Running inference:  64%|██████▍   | 101/157 [03:05<01:43,  1.84s/it]Running inference:  65%|██████▍   | 102/157 [03:07<01:40,  1.83s/it]Running inference:  66%|██████▌   | 103/157 [03:08<01:38,  1.82s/it]Running inference:  66%|██████▌   | 104/157 [03:10<01:38,  1.86s/it]Running inference:  67%|██████▋   | 105/157 [03:12<01:36,  1.85s/it]Running inference:  68%|██████▊   | 106/157 [03:14<01:33,  1.83s/it]Running inference:  68%|██████▊   | 107/157 [03:16<01:31,  1.83s/it]Running inference:  69%|██████▉   | 108/157 [03:18<01:29,  1.83s/it]Running inference:  69%|██████▉   | 109/157 [03:19<01:28,  1.84s/it]Running inference:  70%|███████   | 110/157 [03:21<01:26,  1.84s/it]Running inference:  71%|███████   | 111/157 [03:23<01:24,  1.84s/it]Running inference:  71%|███████▏  | 112/157 [03:25<01:22,  1.84s/it]Running inference:  72%|███████▏  | 113/157 [03:27<01:20,  1.84s/it]Running inference:  73%|███████▎  | 114/157 [03:29<01:19,  1.84s/it]Running inference:  73%|███████▎  | 115/157 [03:31<01:17,  1.85s/it]Running inference:  74%|███████▍  | 116/157 [03:32<01:15,  1.85s/it]Running inference:  75%|███████▍  | 117/157 [03:34<01:13,  1.85s/it]Running inference:  75%|███████▌  | 118/157 [03:36<01:12,  1.86s/it]Running inference:  76%|███████▌  | 119/157 [03:38<01:10,  1.85s/it]Running inference:  76%|███████▋  | 120/157 [03:40<01:09,  1.87s/it]Running inference:  77%|███████▋  | 121/157 [03:42<01:06,  1.86s/it]Running inference:  78%|███████▊  | 122/157 [03:44<01:04,  1.84s/it]Running inference:  78%|███████▊  | 123/157 [03:45<01:02,  1.85s/it]Running inference:  79%|███████▉  | 124/157 [03:47<01:00,  1.84s/it]Running inference:  80%|███████▉  | 125/157 [03:49<00:58,  1.84s/it]Running inference:  80%|████████  | 126/157 [03:51<00:56,  1.83s/it]Running inference:  81%|████████  | 127/157 [03:53<00:55,  1.84s/it]Running inference:  82%|████████▏ | 128/157 [03:55<00:53,  1.85s/it]Running inference:  82%|████████▏ | 129/157 [03:56<00:51,  1.84s/it]Running inference:  83%|████████▎ | 130/157 [03:58<00:49,  1.84s/it]Running inference:  83%|████████▎ | 131/157 [04:00<00:47,  1.84s/it]Running inference:  84%|████████▍ | 132/157 [04:02<00:45,  1.83s/it]Running inference:  85%|████████▍ | 133/157 [04:04<00:43,  1.83s/it]Running inference:  85%|████████▌ | 134/157 [04:06<00:41,  1.82s/it]Running inference:  86%|████████▌ | 135/157 [04:07<00:40,  1.82s/it]Running inference:  87%|████████▋ | 136/157 [04:09<00:38,  1.83s/it]Running inference:  87%|████████▋ | 137/157 [04:11<00:36,  1.83s/it]Running inference:  88%|████████▊ | 138/157 [04:13<00:34,  1.82s/it]Running inference:  89%|████████▊ | 139/157 [04:15<00:32,  1.83s/it]Running inference:  89%|████████▉ | 140/157 [04:17<00:31,  1.83s/it]Running inference:  90%|████████▉ | 141/157 [04:18<00:29,  1.82s/it]Running inference:  90%|█████████ | 142/157 [04:20<00:27,  1.82s/it]Running inference:  91%|█████████ | 143/157 [04:22<00:25,  1.84s/it]Running inference:  92%|█████████▏| 144/157 [04:24<00:23,  1.84s/it]Running inference:  92%|█████████▏| 145/157 [04:26<00:22,  1.86s/it]Running inference:  93%|█████████▎| 146/157 [04:28<00:20,  1.86s/it]Running inference:  94%|█████████▎| 147/157 [04:29<00:18,  1.84s/it]Running inference:  94%|█████████▍| 148/157 [04:31<00:16,  1.84s/it]Running inference:  95%|█████████▍| 149/157 [04:33<00:14,  1.84s/it]Running inference:  96%|█████████▌| 150/157 [04:35<00:13,  1.86s/it]Running inference:  96%|█████████▌| 151/157 [04:37<00:11,  1.86s/it]Running inference:  97%|█████████▋| 152/157 [04:39<00:09,  1.84s/it]Running inference:  97%|█████████▋| 153/157 [04:40<00:07,  1.84s/it]Running inference:  98%|█████████▊| 154/157 [04:42<00:05,  1.83s/it]Running inference:  99%|█████████▊| 155/157 [04:44<00:03,  1.82s/it]Running inference:  99%|█████████▉| 156/157 [04:46<00:01,  1.81s/it]Running inference: 100%|██████████| 157/157 [04:46<00:00,  1.39s/it]Running inference: 100%|██████████| 157/157 [04:46<00:00,  1.83s/it]
23:46:04 - INFO - [inference_calibration] Duration: 286812.13ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<04:55,  1.89s/it]Running inference:   1%|▏         | 2/157 [00:03<04:47,  1.85s/it]Running inference:   2%|▏         | 3/157 [00:05<04:42,  1.83s/it]Running inference:   3%|▎         | 4/157 [00:07<04:39,  1.83s/it]Running inference:   3%|▎         | 5/157 [00:09<04:37,  1.83s/it]Running inference:   4%|▍         | 6/157 [00:11<04:39,  1.85s/it]Running inference:   4%|▍         | 7/157 [00:13<04:51,  1.94s/it]Running inference:   5%|▌         | 8/157 [00:16<06:11,  2.49s/it]Running inference:   6%|▌         | 9/157 [00:21<07:54,  3.21s/it]Running inference:   6%|▋         | 10/157 [00:26<09:21,  3.82s/it]Running inference:   7%|▋         | 11/157 [00:32<10:23,  4.27s/it]Running inference:   8%|▊         | 12/157 [00:37<11:06,  4.59s/it]Running inference:   8%|▊         | 13/157 [00:42<11:29,  4.79s/it]Running inference:   9%|▉         | 14/157 [00:47<11:41,  4.91s/it]Running inference:  10%|▉         | 15/157 [00:53<11:55,  5.04s/it]Running inference:  10%|█         | 16/157 [00:58<11:57,  5.09s/it]Running inference:  11%|█         | 17/157 [01:03<12:00,  5.14s/it]Running inference:  11%|█▏        | 18/157 [01:08<11:55,  5.15s/it]Running inference:  12%|█▏        | 19/157 [01:14<12:01,  5.23s/it]Running inference:  13%|█▎        | 20/157 [01:19<12:03,  5.28s/it]Running inference:  13%|█▎        | 21/157 [01:24<11:56,  5.26s/it]Running inference:  14%|█▍        | 22/157 [01:30<11:50,  5.27s/it]Running inference:  15%|█▍        | 23/157 [01:35<11:42,  5.24s/it]Running inference:  15%|█▌        | 24/157 [01:40<11:35,  5.23s/it]Running inference:  16%|█▌        | 25/157 [01:46<11:42,  5.32s/it]Running inference:  17%|█▋        | 26/157 [01:51<11:29,  5.27s/it]Running inference:  17%|█▋        | 27/157 [01:56<11:20,  5.23s/it]Running inference:  18%|█▊        | 28/157 [02:01<11:00,  5.12s/it]Running inference:  18%|█▊        | 29/157 [02:06<11:11,  5.25s/it]Running inference:  19%|█▉        | 30/157 [02:12<11:11,  5.29s/it]Running inference:  20%|█▉        | 31/157 [02:17<11:01,  5.25s/it]Running inference:  20%|██        | 32/157 [02:22<11:00,  5.28s/it]Running inference:  21%|██        | 33/157 [02:28<11:02,  5.34s/it]Running inference:  22%|██▏       | 34/157 [02:33<10:50,  5.29s/it]Running inference:  22%|██▏       | 35/157 [02:38<10:45,  5.29s/it]Running inference:  23%|██▎       | 36/157 [02:44<10:44,  5.33s/it]Running inference:  24%|██▎       | 37/157 [02:49<10:37,  5.31s/it]Running inference:  24%|██▍       | 38/157 [02:54<10:32,  5.32s/it]Running inference:  25%|██▍       | 39/157 [03:00<10:30,  5.35s/it]Running inference:  25%|██▌       | 40/157 [03:05<10:19,  5.30s/it]Running inference:  26%|██▌       | 41/157 [03:10<10:11,  5.27s/it]Running inference:  27%|██▋       | 42/157 [03:15<10:04,  5.26s/it]Running inference:  27%|██▋       | 43/157 [03:20<09:55,  5.22s/it]Running inference:  28%|██▊       | 44/157 [03:25<09:44,  5.17s/it]Running inference:  29%|██▊       | 45/157 [03:31<09:44,  5.22s/it]Running inference:  29%|██▉       | 46/157 [03:36<09:34,  5.17s/it]Running inference:  30%|██▉       | 47/157 [03:41<09:36,  5.24s/it]Running inference:  31%|███       | 48/157 [03:46<09:29,  5.22s/it]Running inference:  31%|███       | 49/157 [03:52<09:26,  5.25s/it]Running inference:  32%|███▏      | 50/157 [03:57<09:31,  5.34s/it]Running inference:  32%|███▏      | 51/157 [04:03<09:25,  5.33s/it]Running inference:  33%|███▎      | 52/157 [04:08<09:12,  5.26s/it]Running inference:  34%|███▍      | 53/157 [04:12<08:53,  5.13s/it]Running inference:  34%|███▍      | 54/157 [04:17<08:37,  5.02s/it]Running inference:  35%|███▌      | 55/157 [04:22<08:26,  4.97s/it]Running inference:  36%|███▌      | 56/157 [04:27<08:30,  5.05s/it]Running inference:  36%|███▋      | 57/157 [04:33<08:32,  5.13s/it]Running inference:  37%|███▋      | 58/157 [04:38<08:32,  5.18s/it]Running inference:  38%|███▊      | 59/157 [04:43<08:32,  5.23s/it]Running inference:  38%|███▊      | 60/157 [04:49<08:31,  5.27s/it]Running inference:  39%|███▉      | 61/157 [04:54<08:27,  5.29s/it]Running inference:  39%|███▉      | 62/157 [04:59<08:24,  5.32s/it]Running inference:  40%|████      | 63/157 [05:04<08:15,  5.27s/it]Running inference:  41%|████      | 64/157 [05:10<08:07,  5.24s/it]Running inference:  41%|████▏     | 65/157 [05:15<08:05,  5.28s/it]Running inference:  42%|████▏     | 66/157 [05:20<07:59,  5.27s/it]Running inference:  43%|████▎     | 67/157 [05:25<07:49,  5.22s/it]Running inference:  43%|████▎     | 68/157 [05:31<07:49,  5.27s/it]Running inference:  44%|████▍     | 69/157 [05:36<07:47,  5.31s/it]Running inference:  45%|████▍     | 70/157 [05:41<07:41,  5.31s/it]Running inference:  45%|████▌     | 71/157 [05:47<07:36,  5.31s/it]Running inference:  46%|████▌     | 72/157 [05:52<07:37,  5.38s/it]Running inference:  46%|████▋     | 73/157 [05:58<07:34,  5.41s/it]Running inference:  47%|████▋     | 74/157 [06:03<07:30,  5.43s/it]Running inference:  48%|████▊     | 75/157 [06:09<07:34,  5.54s/it]Running inference:  48%|████▊     | 76/157 [06:14<07:19,  5.42s/it]Running inference:  49%|████▉     | 77/157 [06:20<07:13,  5.42s/it]Running inference:  50%|████▉     | 78/157 [06:25<07:04,  5.38s/it]Running inference:  50%|█████     | 79/157 [06:30<07:02,  5.41s/it]Running inference:  51%|█████     | 80/157 [06:36<06:53,  5.37s/it]Running inference:  52%|█████▏    | 81/157 [06:41<06:47,  5.36s/it]Running inference:  52%|█████▏    | 82/157 [06:46<06:37,  5.30s/it]Running inference:  53%|█████▎    | 83/157 [06:52<06:34,  5.33s/it]Running inference:  54%|█████▎    | 84/157 [06:57<06:30,  5.34s/it]Running inference:  54%|█████▍    | 85/157 [07:02<06:21,  5.30s/it]Running inference:  55%|█████▍    | 86/157 [07:07<06:16,  5.30s/it]Running inference:  55%|█████▌    | 87/157 [07:13<06:14,  5.35s/it]Running inference:  56%|█████▌    | 88/157 [07:18<06:07,  5.33s/it]Running inference:  57%|█████▋    | 89/157 [07:23<06:01,  5.31s/it]Running inference:  57%|█████▋    | 90/157 [07:29<05:56,  5.32s/it]Running inference:  58%|█████▊    | 91/157 [07:34<05:52,  5.33s/it]Running inference:  59%|█████▊    | 92/157 [07:40<05:49,  5.38s/it]Running inference:  59%|█████▉    | 93/157 [07:45<05:45,  5.41s/it]Running inference:  60%|█████▉    | 94/157 [07:51<05:40,  5.41s/it]Running inference:  61%|██████    | 95/157 [07:56<05:33,  5.38s/it]Running inference:  61%|██████    | 96/157 [08:01<05:29,  5.39s/it]Running inference:  62%|██████▏   | 97/157 [08:06<05:18,  5.31s/it]Running inference:  62%|██████▏   | 98/157 [08:12<05:15,  5.35s/it]Running inference:  63%|██████▎   | 99/157 [08:17<05:09,  5.34s/it]Running inference:  64%|██████▎   | 100/157 [08:22<05:02,  5.31s/it]Running inference:  64%|██████▍   | 101/157 [08:28<04:55,  5.28s/it]Running inference:  65%|██████▍   | 102/157 [08:33<04:50,  5.27s/it]Running inference:  66%|██████▌   | 103/157 [08:38<04:48,  5.34s/it]Running inference:  66%|██████▌   | 104/157 [08:44<04:42,  5.33s/it]Running inference:  67%|██████▋   | 105/157 [08:49<04:35,  5.30s/it]Running inference:  68%|██████▊   | 106/157 [08:54<04:27,  5.24s/it]Running inference:  68%|██████▊   | 107/157 [08:59<04:19,  5.20s/it]Running inference:  69%|██████▉   | 108/157 [09:04<04:14,  5.20s/it]Running inference:  69%|██████▉   | 109/157 [09:10<04:10,  5.22s/it]Running inference:  70%|███████   | 110/157 [09:15<04:10,  5.32s/it]Running inference:  71%|███████   | 111/157 [09:20<04:04,  5.31s/it]Running inference:  71%|███████▏  | 112/157 [09:26<03:58,  5.31s/it]Running inference:  72%|███████▏  | 113/157 [09:31<03:56,  5.38s/it]Running inference:  73%|███████▎  | 114/157 [09:37<03:50,  5.35s/it]Running inference:  73%|███████▎  | 115/157 [09:42<03:42,  5.29s/it]Running inference:  74%|███████▍  | 116/157 [09:47<03:36,  5.27s/it]Running inference:  75%|███████▍  | 117/157 [09:52<03:32,  5.31s/it]Running inference:  75%|███████▌  | 118/157 [09:58<03:26,  5.29s/it]Running inference:  76%|███████▌  | 119/157 [10:03<03:20,  5.29s/it]Running inference:  76%|███████▋  | 120/157 [10:08<03:19,  5.39s/it]Running inference:  77%|███████▋  | 121/157 [10:14<03:13,  5.37s/it]Running inference:  78%|███████▊  | 122/157 [10:19<03:07,  5.37s/it]Running inference:  78%|███████▊  | 123/157 [10:24<03:01,  5.34s/it]Running inference:  79%|███████▉  | 124/157 [10:30<02:55,  5.33s/it]Running inference:  80%|███████▉  | 125/157 [10:35<02:50,  5.33s/it]Running inference:  80%|████████  | 126/157 [10:40<02:44,  5.30s/it]Running inference:  81%|████████  | 127/157 [10:45<02:32,  5.10s/it]Running inference:  82%|████████▏ | 128/157 [10:50<02:31,  5.21s/it]Running inference:  82%|████████▏ | 129/157 [10:56<02:28,  5.30s/it]Running inference:  83%|████████▎ | 130/157 [11:01<02:23,  5.30s/it]Running inference:  83%|████████▎ | 131/157 [11:07<02:18,  5.32s/it]Running inference:  84%|████████▍ | 132/157 [11:12<02:13,  5.32s/it]Running inference:  85%|████████▍ | 133/157 [11:17<02:07,  5.31s/it]Running inference:  85%|████████▌ | 134/157 [11:23<02:03,  5.38s/it]Running inference:  86%|████████▌ | 135/157 [11:28<01:57,  5.34s/it]Running inference:  87%|████████▋ | 136/157 [11:33<01:52,  5.33s/it]Running inference:  87%|████████▋ | 137/157 [11:39<01:46,  5.35s/it]Running inference:  88%|████████▊ | 138/157 [11:44<01:41,  5.35s/it]Running inference:  89%|████████▊ | 139/157 [11:49<01:35,  5.32s/it]Running inference:  89%|████████▉ | 140/157 [11:54<01:29,  5.28s/it]Running inference:  90%|████████▉ | 141/157 [12:00<01:24,  5.31s/it]Running inference:  90%|█████████ | 142/157 [12:05<01:19,  5.29s/it]Running inference:  91%|█████████ | 143/157 [12:10<01:14,  5.32s/it]Running inference:  92%|█████████▏| 144/157 [12:16<01:08,  5.29s/it]Running inference:  92%|█████████▏| 145/157 [12:21<01:03,  5.33s/it]Running inference:  93%|█████████▎| 146/157 [12:27<00:59,  5.42s/it]Running inference:  94%|█████████▎| 147/157 [12:32<00:53,  5.37s/it]Running inference:  94%|█████████▍| 148/157 [12:37<00:47,  5.33s/it]Running inference:  95%|█████████▍| 149/157 [12:43<00:42,  5.34s/it]Running inference:  96%|█████████▌| 150/157 [12:48<00:37,  5.39s/it]Running inference:  96%|█████████▌| 151/157 [12:53<00:31,  5.20s/it]Running inference:  97%|█████████▋| 152/157 [12:55<00:20,  4.19s/it]Running inference:  97%|█████████▋| 153/157 [12:57<00:13,  3.49s/it]Running inference:  98%|█████████▊| 154/157 [12:58<00:08,  2.99s/it]Running inference:  99%|█████████▊| 155/157 [13:00<00:05,  2.66s/it]Running inference:  99%|█████████▉| 156/157 [13:04<00:02,  2.89s/it]Running inference: 100%|██████████| 157/157 [13:05<00:00,  2.49s/it]Running inference: 100%|██████████| 157/157 [13:05<00:00,  5.00s/it]
23:59:10 - INFO - [inference_test] Duration: 785753.95ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
23:59:10 - INFO -     Inference: 1072.57s for 10000 samples (9.32 samples/sec)
23:59:10 - INFO - Initialized ProbabilityExtractor
23:59:10 - INFO -   Temperature: 1.0
23:59:10 - INFO -   Calibration method: None
23:59:10 - INFO - [probability_extraction] Duration: 254.17ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
23:59:11 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_phi-2_ci_float16_base_20251207_231938.npz
23:59:11 - INFO - Initialized LACScorer
23:59:11 - INFO -   Alpha: 0.1
23:59:11 - INFO -   Target coverage: 90.0%
23:59:11 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
23:59:11 - INFO - Initialized PredictionSetGenerator
23:59:11 - INFO -   Methods: ['lac']
23:59:11 - INFO -   Alpha: 0.1
23:59:11 - INFO -   Aggregation: separate
23:59:11 - INFO - Calibrating 1 conformal predictors...
23:59:11 - INFO -   Calibrating LAC...
23:59:11 - INFO - Calibrating with 4999 samples...
23:59:11 - INFO - Calibration complete
23:59:11 - INFO -   Threshold: 0.9834
23:59:11 - INFO -   Score range: [0.0008, 1.0000]
23:59:11 - INFO - Calibration complete
23:59:11 - INFO - Generating prediction sets using LAC...
23:59:11 - INFO - Generating prediction sets for 5001 test instances...
23:59:11 - INFO - Prediction complete
23:59:11 - INFO -   Average set size: 5.24
23:59:11 - INFO -   Coverage rate: 89.96%
23:59:11 - INFO -   Meets coverage guarantee: False
23:59:11 - WARNING - ✗ Coverage guarantee NOT met: 89.96% < 90.00%
23:59:11 - WARNING - LAC does not meet coverage guarantee: 89.96% < 90.00%
23:59:11 - INFO -     LAC: Acc=22.40%, CR=89.96%, SS=5.24
23:59:11 - INFO - Initialized APSScorer
23:59:11 - INFO -   Alpha: 0.1
23:59:11 - INFO -   Target coverage: 90.0%
23:59:11 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
23:59:11 - INFO - Initialized PredictionSetGenerator
23:59:11 - INFO -   Methods: ['aps']
23:59:11 - INFO -   Alpha: 0.1
23:59:11 - INFO -   Aggregation: separate
23:59:11 - INFO - Calibrating 1 conformal predictors...
23:59:11 - INFO -   Calibrating APS...
23:59:11 - INFO - Calibrating with 4999 samples...
23:59:11 - INFO - Calibration complete
23:59:11 - INFO -   Threshold: 1.0000
23:59:11 - INFO -   Score range: [0.2022, 1.0000]
23:59:11 - INFO - Calibration complete
23:59:11 - INFO - Generating prediction sets using APS...
23:59:11 - INFO - Generating prediction sets for 5001 test instances...
23:59:11 - INFO - Prediction complete
23:59:11 - INFO -   Average set size: 5.85
23:59:11 - INFO -   Coverage rate: 98.28%
23:59:11 - INFO -   Meets coverage guarantee: True
23:59:11 - INFO - [PASS] Coverage guarantee met: 98.28% >= 90.00%
23:59:11 - INFO -     APS: Acc=22.40%, CR=98.28%, SS=5.85
23:59:16 - INFO - Unloaded model: phi-2_float16
23:59:17 - INFO - Checkpoint saved after completing: phi-2 | ci | float16
23:59:17 - INFO - 
================================================================================
23:59:17 - INFO - Run 4/5: phi-2 | drs | float16
23:59:17 - INFO - ================================================================================
23:59:17 - INFO - [start_phi-2_drs] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 100.0%
23:59:17 - INFO - Loading drs dataset (10000 samples)...
23:59:17 - INFO - Loading HaluDial dataset with 10000 samples...
23:59:20 - INFO - Loaded 10000 HaluDial instances
23:59:20 - INFO - [dataset_loading] Duration: 2787.29ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:59:20 - INFO - Processing drs dataset to 6-option format...
23:59:52 - INFO - Processed 10000 instances for drs
23:59:52 - INFO - Option expansion statistics for drs:
23:59:52 - INFO -   Instances expanded (2→4 options): 10000
23:59:52 - INFO -   Total options sampled: 20000
23:59:52 - INFO -   Duplicate options avoided: 2
23:59:52 - INFO -   Fallback options used: 0
23:59:52 - INFO - Splitting drs dataset (calibration: 50%, test: 50%)
23:59:52 - INFO - Split complete:
23:59:52 - INFO -   Calibration: 4999 instances
23:59:52 - INFO -   Test: 5001 instances
23:59:52 - INFO - Answer distribution:
23:59:52 - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
23:59:52 - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
23:59:52 - INFO - [dataset_processing] Duration: 32442.29ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
23:59:52 - INFO - Initialized DemonstrationSelector
23:59:52 - INFO -   Strategy: random
23:59:52 - INFO -   Num demonstrations: 5
23:59:52 - INFO - Initialized DemonstrationManager
23:59:52 - INFO - Selecting 3 demonstrations using 'random' strategy
23:59:52 - INFO - Selected and cached 3 demonstrations for drs
23:59:52 - INFO - Loading model: phi-2 (float16)
23:59:52 - INFO - Loading model: phi-2_float16 (microsoft/phi-2)
23:59:52 - INFO - Loading tokenizer from microsoft/phi-2
23:59:53 - INFO - Tokenizer loaded successfully
23:59:53 - INFO -   Vocab size: 50295
23:59:53 - INFO -   Padding side: left
23:59:53 - INFO -   PAD token: <|endoftext|> (ID: 50256)
23:59:53 - INFO - Loading model from microsoft/phi-2
23:59:53 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]
23:59:55 - INFO - Model loaded successfully
23:59:55 - INFO -   GPU Memory: 5.19GB allocated, 5.21GB reserved

Model: phi-2_float16
  ID: microsoft/phi-2
  Type: causal
  Parameters: 2,779,683,840
  Vocab size: 50,295
  Max length: 2048
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: False
23:59:55 - INFO - [model_loading] Duration: 2406.98ms | GPU Memory: 9.1MB -> 5311.0MB (delta +5301.8MB)
23:59:55 - INFO - [after_model_load_phi-2] GPU State: Allocated: 5311.0MB | Reserved: 5334.0MB | Free: 75844.8MB | Utilization: 100.0%
23:59:55 - INFO - Using batch size: 32
23:59:55 - INFO -   Strategy: base
23:59:55 - INFO - Initialized PromptBuilder for task: drs
23:59:55 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
23:59:55 - INFO - Building 10000 prompts using 'base' strategy with 3 demonstrations
23:59:55 - INFO - Initialized InferenceEngine for phi-2_float16
23:59:55 - INFO -   Device: cuda:0
23:59:55 - INFO -   Batch size: 32
23:59:55 - INFO -   Option tokens: {'A': 317, 'B': 347, 'C': 327, 'D': 360, 'E': 412, 'F': 376}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:03<08:31,  3.28s/it]Running inference:   1%|▏         | 2/157 [00:06<08:31,  3.30s/it]Running inference:   2%|▏         | 3/157 [00:09<08:18,  3.24s/it]Running inference:   3%|▎         | 4/157 [00:12<08:04,  3.17s/it]Running inference:   3%|▎         | 5/157 [00:16<08:03,  3.18s/it]Running inference:   4%|▍         | 6/157 [00:19<08:12,  3.26s/it]Running inference:   4%|▍         | 7/157 [00:22<08:13,  3.29s/it]Running inference:   5%|▌         | 8/157 [00:26<08:08,  3.28s/it]Running inference:   6%|▌         | 9/157 [00:29<08:09,  3.31s/it]Running inference:   6%|▋         | 10/157 [00:32<07:52,  3.21s/it]Running inference:   7%|▋         | 11/157 [00:35<07:47,  3.20s/it]Running inference:   8%|▊         | 12/157 [00:38<07:47,  3.22s/it]Running inference:   8%|▊         | 13/157 [00:42<07:45,  3.23s/it]Running inference:   9%|▉         | 14/157 [00:45<07:52,  3.30s/it]Running inference:  10%|▉         | 15/157 [00:48<07:43,  3.26s/it]Running inference:  10%|█         | 16/157 [00:52<07:46,  3.31s/it]Running inference:  11%|█         | 17/157 [00:55<07:34,  3.24s/it]Running inference:  11%|█▏        | 18/157 [00:58<07:34,  3.27s/it]Running inference:  12%|█▏        | 19/157 [01:01<07:35,  3.30s/it]Running inference:  13%|█▎        | 20/157 [01:04<07:18,  3.20s/it]Running inference:  13%|█▎        | 21/157 [01:08<07:18,  3.23s/it]Running inference:  14%|█▍        | 22/157 [01:11<07:23,  3.29s/it]Running inference:  15%|█▍        | 23/157 [01:15<07:25,  3.33s/it]Running inference:  15%|█▌        | 24/157 [01:18<07:16,  3.28s/it]Running inference:  16%|█▌        | 25/157 [01:21<07:22,  3.35s/it]Running inference:  17%|█▋        | 26/157 [01:25<07:19,  3.36s/it]Running inference:  17%|█▋        | 27/157 [01:28<07:15,  3.35s/it]Running inference:  18%|█▊        | 28/157 [01:31<07:01,  3.27s/it]Running inference:  18%|█▊        | 29/157 [01:34<07:04,  3.31s/it]Running inference:  19%|█▉        | 30/157 [01:38<06:52,  3.25s/it]Running inference:  20%|█▉        | 31/157 [01:41<06:44,  3.21s/it]Running inference:  20%|██        | 32/157 [01:44<06:39,  3.19s/it]Running inference:  21%|██        | 33/157 [01:47<06:36,  3.20s/it]Running inference:  22%|██▏       | 34/157 [01:51<06:55,  3.38s/it]Running inference:  22%|██▏       | 35/157 [01:54<06:47,  3.34s/it]Running inference:  23%|██▎       | 36/157 [01:57<06:44,  3.35s/it]Running inference:  24%|██▎       | 37/157 [02:01<06:37,  3.31s/it]Running inference:  24%|██▍       | 38/157 [02:04<06:27,  3.25s/it]Running inference:  25%|██▍       | 39/157 [02:07<06:30,  3.31s/it]Running inference:  25%|██▌       | 40/157 [02:10<06:20,  3.25s/it]Running inference:  26%|██▌       | 41/157 [02:14<06:20,  3.28s/it]Running inference:  27%|██▋       | 42/157 [02:17<06:23,  3.33s/it]Running inference:  27%|██▋       | 43/157 [02:20<06:18,  3.32s/it]Running inference:  28%|██▊       | 44/157 [02:24<06:09,  3.27s/it]Running inference:  29%|██▊       | 45/157 [02:27<06:04,  3.26s/it]Running inference:  29%|██▉       | 46/157 [02:30<06:05,  3.29s/it]Running inference:  30%|██▉       | 47/157 [02:34<06:06,  3.33s/it]Running inference:  31%|███       | 48/157 [02:37<05:59,  3.30s/it]Running inference:  31%|███       | 49/157 [02:40<06:03,  3.37s/it]Running inference:  32%|███▏      | 50/157 [02:44<05:55,  3.32s/it]Running inference:  32%|███▏      | 51/157 [02:47<06:08,  3.47s/it]Running inference:  33%|███▎      | 52/157 [02:51<06:03,  3.46s/it]Running inference:  34%|███▍      | 53/157 [02:54<05:59,  3.46s/it]Running inference:  34%|███▍      | 54/157 [02:58<05:50,  3.40s/it]Running inference:  35%|███▌      | 55/157 [03:01<05:45,  3.39s/it]Running inference:  36%|███▌      | 56/157 [03:04<05:40,  3.37s/it]Running inference:  36%|███▋      | 57/157 [03:08<05:34,  3.35s/it]Running inference:  37%|███▋      | 58/157 [03:11<05:32,  3.36s/it]Running inference:  38%|███▊      | 59/157 [03:14<05:21,  3.29s/it]Running inference:  38%|███▊      | 60/157 [03:17<05:20,  3.30s/it]Running inference:  39%|███▉      | 61/157 [03:21<05:19,  3.33s/it]Running inference:  39%|███▉      | 62/157 [03:24<05:18,  3.35s/it]Running inference:  40%|████      | 63/157 [03:27<05:14,  3.35s/it]Running inference:  41%|████      | 64/157 [03:31<05:14,  3.38s/it]Running inference:  41%|████▏     | 65/157 [03:34<05:03,  3.30s/it]Running inference:  42%|████▏     | 66/157 [03:37<05:02,  3.32s/it]Running inference:  43%|████▎     | 67/157 [03:41<05:02,  3.37s/it]Running inference:  43%|████▎     | 68/157 [03:44<04:54,  3.31s/it]Running inference:  44%|████▍     | 69/157 [03:47<04:45,  3.25s/it]Running inference:  45%|████▍     | 70/157 [03:51<04:47,  3.30s/it]Running inference:  45%|████▌     | 71/157 [03:54<04:43,  3.29s/it]Running inference:  46%|████▌     | 72/157 [03:57<04:42,  3.33s/it]Running inference:  46%|████▋     | 73/157 [04:00<04:36,  3.29s/it]Running inference:  47%|████▋     | 74/157 [04:04<04:36,  3.33s/it]Running inference:  48%|████▊     | 75/157 [04:07<04:27,  3.26s/it]Running inference:  48%|████▊     | 76/157 [04:10<04:22,  3.25s/it]Running inference:  49%|████▉     | 77/157 [04:14<04:26,  3.33s/it]Running inference:  50%|████▉     | 78/157 [04:17<04:23,  3.34s/it]Running inference:  50%|█████     | 79/157 [04:20<04:14,  3.26s/it]Running inference:  51%|█████     | 80/157 [04:24<04:14,  3.31s/it]Running inference:  52%|█████▏    | 81/157 [04:27<04:09,  3.28s/it]Running inference:  52%|█████▏    | 82/157 [04:30<03:58,  3.19s/it]Running inference:  53%|█████▎    | 83/157 [04:33<04:00,  3.25s/it]Running inference:  54%|█████▎    | 84/157 [04:36<03:54,  3.22s/it]Running inference:  54%|█████▍    | 85/157 [04:39<03:46,  3.14s/it]Running inference:  55%|█████▍    | 86/157 [04:43<03:50,  3.25s/it]Running inference:  55%|█████▌    | 87/157 [04:46<03:40,  3.15s/it]Running inference:  56%|█████▌    | 88/157 [04:49<03:31,  3.07s/it]Running inference:  57%|█████▋    | 89/157 [04:52<03:28,  3.07s/it]Running inference:  57%|█████▋    | 90/157 [04:55<03:25,  3.07s/it]Running inference:  58%|█████▊    | 91/157 [04:58<03:19,  3.02s/it]Running inference:  59%|█████▊    | 92/157 [05:01<03:14,  2.99s/it]Running inference:  59%|█████▉    | 93/157 [05:03<03:06,  2.92s/it]Running inference:  60%|█████▉    | 94/157 [05:06<03:03,  2.92s/it]Running inference:  61%|██████    | 95/157 [05:09<03:01,  2.93s/it]Running inference:  61%|██████    | 96/157 [05:12<03:01,  2.98s/it]Running inference:  62%|██████▏   | 97/157 [05:15<02:57,  2.95s/it]Running inference:  62%|██████▏   | 98/157 [05:19<03:02,  3.09s/it]Running inference:  63%|██████▎   | 99/157 [05:22<03:03,  3.17s/it]Running inference:  64%|██████▎   | 100/157 [05:25<02:55,  3.08s/it]Running inference:  64%|██████▍   | 101/157 [05:28<02:47,  3.00s/it]Running inference:  65%|██████▍   | 102/157 [05:31<02:43,  2.98s/it]Running inference:  66%|██████▌   | 103/157 [05:34<02:40,  2.97s/it]Running inference:  66%|██████▌   | 104/157 [05:37<02:40,  3.02s/it]Running inference:  67%|██████▋   | 105/157 [05:40<02:38,  3.06s/it]Running inference:  68%|██████▊   | 106/157 [05:43<02:38,  3.10s/it]Running inference:  68%|██████▊   | 107/157 [05:46<02:38,  3.18s/it]Running inference:  69%|██████▉   | 108/157 [05:50<02:35,  3.18s/it]Running inference:  69%|██████▉   | 109/157 [05:53<02:31,  3.15s/it]Running inference:  70%|███████   | 110/157 [05:56<02:25,  3.09s/it]Running inference:  71%|███████   | 111/157 [05:59<02:20,  3.05s/it]Running inference:  71%|███████▏  | 112/157 [06:02<02:16,  3.03s/it]Running inference:  72%|███████▏  | 113/157 [06:04<02:09,  2.95s/it]Running inference:  73%|███████▎  | 114/157 [06:07<02:06,  2.94s/it]Running inference:  73%|███████▎  | 115/157 [06:10<02:01,  2.90s/it]Running inference:  74%|███████▍  | 116/157 [06:13<02:03,  3.01s/it]Running inference:  75%|███████▍  | 117/157 [06:16<02:01,  3.03s/it]Running inference:  75%|███████▌  | 118/157 [06:20<02:02,  3.13s/it]Running inference:  76%|███████▌  | 119/157 [06:23<02:01,  3.20s/it]Running inference:  76%|███████▋  | 120/157 [06:26<02:00,  3.25s/it]Running inference:  77%|███████▋  | 121/157 [06:30<01:57,  3.27s/it]Running inference:  78%|███████▊  | 122/157 [06:33<01:55,  3.29s/it]Running inference:  78%|███████▊  | 123/157 [06:37<01:54,  3.38s/it]Running inference:  79%|███████▉  | 124/157 [06:40<01:52,  3.40s/it]Running inference:  80%|███████▉  | 125/157 [06:43<01:45,  3.30s/it]Running inference:  80%|████████  | 126/157 [06:46<01:41,  3.27s/it]Running inference:  81%|████████  | 127/157 [06:50<01:40,  3.35s/it]Running inference:  82%|████████▏ | 128/157 [06:53<01:36,  3.31s/it]Running inference:  82%|████████▏ | 129/157 [06:56<01:31,  3.25s/it]Running inference:  83%|████████▎ | 130/157 [07:00<01:28,  3.26s/it]Running inference:  83%|████████▎ | 131/157 [07:03<01:23,  3.21s/it]Running inference:  84%|████████▍ | 132/157 [07:06<01:20,  3.21s/it]Running inference:  85%|████████▍ | 133/157 [07:09<01:16,  3.18s/it]Running inference:  85%|████████▌ | 134/157 [07:12<01:12,  3.14s/it]Running inference:  86%|████████▌ | 135/157 [07:15<01:10,  3.21s/it]Running inference:  87%|████████▋ | 136/157 [07:18<01:06,  3.15s/it]Running inference:  87%|████████▋ | 137/157 [07:21<01:02,  3.12s/it]Running inference:  88%|████████▊ | 138/157 [07:25<01:00,  3.18s/it]Running inference:  89%|████████▊ | 139/157 [07:28<00:58,  3.24s/it]Running inference:  89%|████████▉ | 140/157 [07:31<00:54,  3.22s/it]Running inference:  90%|████████▉ | 141/157 [07:34<00:51,  3.19s/it]Running inference:  90%|█████████ | 142/157 [07:38<00:48,  3.26s/it]Running inference:  91%|█████████ | 143/157 [07:41<00:45,  3.22s/it]Running inference:  92%|█████████▏| 144/157 [07:44<00:41,  3.21s/it]Running inference:  92%|█████████▏| 145/157 [07:48<00:38,  3.24s/it]Running inference:  93%|█████████▎| 146/157 [07:51<00:35,  3.21s/it]Running inference:  94%|█████████▎| 147/157 [07:54<00:32,  3.24s/it]Running inference:  94%|█████████▍| 148/157 [07:57<00:29,  3.33s/it]Running inference:  95%|█████████▍| 149/157 [07:59<00:22,  2.81s/it]Running inference:  96%|█████████▌| 150/157 [08:00<00:16,  2.29s/it]Running inference:  96%|█████████▌| 151/157 [08:01<00:11,  1.95s/it]Running inference:  97%|█████████▋| 152/157 [08:02<00:08,  1.69s/it]Running inference:  97%|█████████▋| 153/157 [08:04<00:06,  1.52s/it]Running inference:  98%|█████████▊| 154/157 [08:05<00:04,  1.40s/it]Running inference:  99%|█████████▊| 155/157 [08:06<00:02,  1.30s/it]Running inference:  99%|█████████▉| 156/157 [08:07<00:01,  1.25s/it]Running inference: 100%|██████████| 157/157 [08:07<00:00,  1.04it/s]Running inference: 100%|██████████| 157/157 [08:07<00:00,  3.11s/it]
00:08:03 - INFO - [inference_calibration] Duration: 487634.36ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:01<03:41,  1.42s/it]Running inference:   1%|▏         | 2/157 [00:03<05:22,  2.08s/it]Running inference:   2%|▏         | 3/157 [00:07<06:52,  2.68s/it]Running inference:   3%|▎         | 4/157 [00:10<07:33,  2.96s/it]Running inference:   3%|▎         | 5/157 [00:14<07:51,  3.10s/it]Running inference:   4%|▍         | 6/157 [00:17<08:01,  3.19s/it]Running inference:   4%|▍         | 7/157 [00:20<07:54,  3.16s/it]Running inference:   5%|▌         | 8/157 [00:23<07:53,  3.18s/it]Running inference:   6%|▌         | 9/157 [00:26<07:43,  3.13s/it]Running inference:   6%|▋         | 10/157 [00:29<07:37,  3.11s/it]Running inference:   7%|▋         | 11/157 [00:33<07:40,  3.15s/it]Running inference:   8%|▊         | 12/157 [00:36<07:42,  3.19s/it]Running inference:   8%|▊         | 13/157 [00:39<07:55,  3.30s/it]Running inference:   9%|▉         | 14/157 [00:43<07:41,  3.23s/it]Running inference:  10%|▉         | 15/157 [00:46<07:45,  3.28s/it]Running inference:  10%|█         | 16/157 [00:49<07:49,  3.33s/it]Running inference:  11%|█         | 17/157 [00:53<07:39,  3.28s/it]Running inference:  11%|█▏        | 18/157 [00:56<07:33,  3.26s/it]Running inference:  12%|█▏        | 19/157 [00:59<07:34,  3.30s/it]Running inference:  13%|█▎        | 20/157 [01:02<07:23,  3.24s/it]Running inference:  13%|█▎        | 21/157 [01:06<07:23,  3.26s/it]Running inference:  14%|█▍        | 22/157 [01:09<07:26,  3.31s/it]Running inference:  15%|█▍        | 23/157 [01:12<07:21,  3.30s/it]Running inference:  15%|█▌        | 24/157 [01:16<07:26,  3.36s/it]Running inference:  16%|█▌        | 25/157 [01:19<07:20,  3.34s/it]Running inference:  17%|█▋        | 26/157 [01:22<07:13,  3.31s/it]Running inference:  17%|█▋        | 27/157 [01:25<07:05,  3.27s/it]Running inference:  18%|█▊        | 28/157 [01:29<07:00,  3.26s/it]Running inference:  18%|█▊        | 29/157 [01:32<06:58,  3.27s/it]Running inference:  19%|█▉        | 30/157 [01:35<06:59,  3.30s/it]Running inference:  20%|█▉        | 31/157 [01:39<06:56,  3.31s/it]Running inference:  20%|██        | 32/157 [01:42<06:50,  3.28s/it]Running inference:  21%|██        | 33/157 [01:45<06:40,  3.23s/it]Running inference:  22%|██▏       | 34/157 [01:48<06:40,  3.25s/it]Running inference:  22%|██▏       | 35/157 [01:51<06:34,  3.23s/it]Running inference:  23%|██▎       | 36/157 [01:55<06:34,  3.26s/it]Running inference:  24%|██▎       | 37/157 [01:58<06:32,  3.27s/it]Running inference:  24%|██▍       | 38/157 [02:02<06:38,  3.35s/it]Running inference:  25%|██▍       | 39/157 [02:05<06:26,  3.28s/it]Running inference:  25%|██▌       | 40/157 [02:08<06:25,  3.30s/it]Running inference:  26%|██▌       | 41/157 [02:12<06:32,  3.39s/it]Running inference:  27%|██▋       | 42/157 [02:15<06:31,  3.41s/it]Running inference:  27%|██▋       | 43/157 [02:18<06:21,  3.34s/it]Running inference:  28%|██▊       | 44/157 [02:22<06:17,  3.34s/it]Running inference:  29%|██▊       | 45/157 [02:25<06:16,  3.36s/it]Running inference:  29%|██▉       | 46/157 [02:28<06:09,  3.33s/it]Running inference:  30%|██▉       | 47/157 [02:32<06:04,  3.31s/it]Running inference:  31%|███       | 48/157 [02:35<06:00,  3.31s/it]Running inference:  31%|███       | 49/157 [02:38<05:53,  3.27s/it]Running inference:  32%|███▏      | 50/157 [02:41<05:52,  3.30s/it]Running inference:  32%|███▏      | 51/157 [02:45<05:53,  3.33s/it]Running inference:  33%|███▎      | 52/157 [02:48<05:52,  3.35s/it]Running inference:  34%|███▍      | 53/157 [02:51<05:42,  3.29s/it]Running inference:  34%|███▍      | 54/157 [02:55<05:36,  3.26s/it]Running inference:  35%|███▌      | 55/157 [02:58<05:30,  3.24s/it]Running inference:  36%|███▌      | 56/157 [03:01<05:21,  3.18s/it]Running inference:  36%|███▋      | 57/157 [03:04<05:26,  3.27s/it]Running inference:  37%|███▋      | 58/157 [03:07<05:20,  3.24s/it]Running inference:  38%|███▊      | 59/157 [03:10<05:08,  3.15s/it]Running inference:  38%|███▊      | 60/157 [03:14<05:07,  3.17s/it]Running inference:  39%|███▉      | 61/157 [03:17<04:59,  3.12s/it]Running inference:  39%|███▉      | 62/157 [03:19<04:46,  3.02s/it]Running inference:  40%|████      | 63/157 [03:23<04:48,  3.07s/it]Running inference:  41%|████      | 64/157 [03:26<04:44,  3.06s/it]Running inference:  41%|████▏     | 65/157 [03:29<04:42,  3.07s/it]Running inference:  42%|████▏     | 66/157 [03:32<04:42,  3.10s/it]Running inference:  43%|████▎     | 67/157 [03:35<04:33,  3.04s/it]Running inference:  43%|████▎     | 68/157 [03:38<04:30,  3.04s/it]Running inference:  44%|████▍     | 69/157 [03:41<04:34,  3.12s/it]Running inference:  45%|████▍     | 70/157 [03:44<04:30,  3.11s/it]Running inference:  45%|████▌     | 71/157 [03:48<04:34,  3.19s/it]Running inference:  46%|████▌     | 72/157 [03:51<04:34,  3.23s/it]Running inference:  46%|████▋     | 73/157 [03:54<04:31,  3.23s/it]Running inference:  47%|████▋     | 74/157 [03:57<04:24,  3.19s/it]Running inference:  48%|████▊     | 75/157 [04:01<04:27,  3.26s/it]Running inference:  48%|████▊     | 76/157 [04:04<04:28,  3.31s/it]Running inference:  49%|████▉     | 77/157 [04:07<04:13,  3.16s/it]Running inference:  50%|████▉     | 78/157 [04:10<04:08,  3.15s/it]Running inference:  50%|█████     | 79/157 [04:13<04:08,  3.18s/it]Running inference:  51%|█████     | 80/157 [04:17<04:05,  3.19s/it]Running inference:  52%|█████▏    | 81/157 [04:20<04:00,  3.17s/it]Running inference:  52%|█████▏    | 82/157 [04:23<03:54,  3.13s/it]Running inference:  53%|█████▎    | 83/157 [04:26<03:54,  3.17s/it]Running inference:  54%|█████▎    | 84/157 [04:29<03:58,  3.27s/it]Running inference:  54%|█████▍    | 85/157 [04:32<03:46,  3.15s/it]Running inference:  55%|█████▍    | 86/157 [04:36<03:46,  3.19s/it]Running inference:  55%|█████▌    | 87/157 [04:39<03:48,  3.26s/it]Running inference:  56%|█████▌    | 88/157 [04:42<03:48,  3.31s/it]Running inference:  57%|█████▋    | 89/157 [04:46<03:41,  3.26s/it]Running inference:  57%|█████▋    | 90/157 [04:49<03:45,  3.36s/it]Running inference:  58%|█████▊    | 91/157 [04:52<03:33,  3.24s/it]Running inference:  59%|█████▊    | 92/157 [04:55<03:29,  3.23s/it]Running inference:  59%|█████▉    | 93/157 [04:59<03:32,  3.31s/it]Running inference:  60%|█████▉    | 94/157 [05:02<03:32,  3.37s/it]Running inference:  61%|██████    | 95/157 [05:06<03:27,  3.35s/it]Running inference:  61%|██████    | 96/157 [05:09<03:25,  3.37s/it]Running inference:  62%|██████▏   | 97/157 [05:12<03:18,  3.31s/it]Running inference:  62%|██████▏   | 98/157 [05:15<03:13,  3.27s/it]Running inference:  63%|██████▎   | 99/157 [05:19<03:13,  3.34s/it]Running inference:  64%|██████▎   | 100/157 [05:22<03:06,  3.27s/it]Running inference:  64%|██████▍   | 101/157 [05:25<03:02,  3.25s/it]Running inference:  65%|██████▍   | 102/157 [05:29<03:02,  3.31s/it]Running inference:  66%|██████▌   | 103/157 [05:32<03:00,  3.34s/it]Running inference:  66%|██████▌   | 104/157 [05:35<02:53,  3.28s/it]Running inference:  67%|██████▋   | 105/157 [05:39<02:53,  3.34s/it]Running inference:  68%|██████▊   | 106/157 [05:42<02:48,  3.30s/it]Running inference:  68%|██████▊   | 107/157 [05:45<02:39,  3.19s/it]Running inference:  69%|██████▉   | 108/157 [05:48<02:40,  3.28s/it]Running inference:  69%|██████▉   | 109/157 [05:52<02:36,  3.26s/it]Running inference:  70%|███████   | 110/157 [05:55<02:35,  3.31s/it]Running inference:  71%|███████   | 111/157 [05:58<02:33,  3.34s/it]Running inference:  71%|███████▏  | 112/157 [06:02<02:28,  3.30s/it]Running inference:  72%|███████▏  | 113/157 [06:05<02:28,  3.36s/it]Running inference:  73%|███████▎  | 114/157 [06:08<02:23,  3.33s/it]Running inference:  73%|███████▎  | 115/157 [06:11<02:15,  3.23s/it]Running inference:  74%|███████▍  | 116/157 [06:15<02:11,  3.20s/it]Running inference:  75%|███████▍  | 117/157 [06:18<02:06,  3.16s/it]Running inference:  75%|███████▌  | 118/157 [06:21<02:04,  3.18s/it]Running inference:  76%|███████▌  | 119/157 [06:24<02:00,  3.16s/it]Running inference:  76%|███████▋  | 120/157 [06:27<01:58,  3.20s/it]Running inference:  77%|███████▋  | 121/157 [06:30<01:53,  3.14s/it]Running inference:  78%|███████▊  | 122/157 [06:33<01:47,  3.06s/it]Running inference:  78%|███████▊  | 123/157 [06:36<01:42,  3.00s/it]Running inference:  79%|███████▉  | 124/157 [06:39<01:42,  3.10s/it]Running inference:  80%|███████▉  | 125/157 [06:42<01:39,  3.10s/it]Running inference:  80%|████████  | 126/157 [06:45<01:36,  3.10s/it]Running inference:  81%|████████  | 127/157 [06:49<01:32,  3.08s/it]Running inference:  82%|████████▏ | 128/157 [06:52<01:28,  3.06s/it]Running inference:  82%|████████▏ | 129/157 [06:55<01:26,  3.07s/it]Running inference:  83%|████████▎ | 130/157 [06:58<01:25,  3.15s/it]Running inference:  83%|████████▎ | 131/157 [07:01<01:20,  3.08s/it]Running inference:  84%|████████▍ | 132/157 [07:04<01:16,  3.08s/it]Running inference:  85%|████████▍ | 133/157 [07:07<01:12,  3.00s/it]Running inference:  85%|████████▌ | 134/157 [07:10<01:09,  3.02s/it]Running inference:  86%|████████▌ | 135/157 [07:13<01:07,  3.08s/it]Running inference:  87%|████████▋ | 136/157 [07:16<01:03,  3.04s/it]Running inference:  87%|████████▋ | 137/157 [07:19<01:00,  3.03s/it]Running inference:  88%|████████▊ | 138/157 [07:22<00:56,  2.95s/it]Running inference:  89%|████████▊ | 139/157 [07:25<00:52,  2.93s/it]Running inference:  89%|████████▉ | 140/157 [07:28<00:49,  2.91s/it]Running inference:  90%|████████▉ | 141/157 [07:30<00:46,  2.92s/it]Running inference:  90%|█████████ | 142/157 [07:34<00:45,  3.04s/it]Running inference:  91%|█████████ | 143/157 [07:37<00:41,  2.95s/it]Running inference:  92%|█████████▏| 144/157 [07:39<00:37,  2.89s/it]Running inference:  92%|█████████▏| 145/157 [07:42<00:34,  2.91s/it]Running inference:  93%|█████████▎| 146/157 [07:45<00:31,  2.88s/it]Running inference:  94%|█████████▎| 147/157 [07:48<00:28,  2.86s/it]Running inference:  94%|█████████▍| 148/157 [07:51<00:26,  2.90s/it]Running inference:  95%|█████████▍| 149/157 [07:54<00:22,  2.86s/it]Running inference:  96%|█████████▌| 150/157 [07:56<00:19,  2.84s/it]Running inference:  96%|█████████▌| 151/157 [07:59<00:16,  2.83s/it]Running inference:  97%|█████████▋| 152/157 [08:03<00:15,  3.00s/it]Running inference:  97%|█████████▋| 153/157 [08:06<00:12,  3.02s/it]Running inference:  98%|█████████▊| 154/157 [08:09<00:09,  3.01s/it]Running inference:  99%|█████████▊| 155/157 [08:12<00:06,  3.02s/it]Running inference:  99%|█████████▉| 156/157 [08:14<00:02,  2.92s/it]Running inference: 100%|██████████| 157/157 [08:15<00:00,  2.31s/it]Running inference: 100%|██████████| 157/157 [08:15<00:00,  3.16s/it]
00:16:18 - INFO - [inference_test] Duration: 495760.56ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
00:16:18 - INFO -     Inference: 983.40s for 10000 samples (10.17 samples/sec)
00:16:18 - INFO - Initialized ProbabilityExtractor
00:16:18 - INFO -   Temperature: 1.0
00:16:18 - INFO -   Calibration method: None
00:16:19 - INFO - [probability_extraction] Duration: 289.63ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
00:16:19 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_phi-2_drs_float16_base_20251207_231938.npz
00:16:19 - INFO - Initialized LACScorer
00:16:19 - INFO -   Alpha: 0.1
00:16:19 - INFO -   Target coverage: 90.0%
00:16:19 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
00:16:19 - INFO - Initialized PredictionSetGenerator
00:16:19 - INFO -   Methods: ['lac']
00:16:19 - INFO -   Alpha: 0.1
00:16:19 - INFO -   Aggregation: separate
00:16:19 - INFO - Calibrating 1 conformal predictors...
00:16:19 - INFO -   Calibrating LAC...
00:16:19 - INFO - Calibrating with 4999 samples...
00:16:19 - INFO - Calibration complete
00:16:19 - INFO -   Threshold: 0.9799
00:16:19 - INFO -   Score range: [0.0000, 1.0000]
00:16:19 - INFO - Calibration complete
00:16:19 - INFO - Generating prediction sets using LAC...
00:16:19 - INFO - Generating prediction sets for 5001 test instances...
00:16:19 - INFO - Prediction complete
00:16:19 - INFO -   Average set size: 5.25
00:16:19 - INFO -   Coverage rate: 89.56%
00:16:19 - INFO -   Meets coverage guarantee: False
00:16:19 - WARNING - ✗ Coverage guarantee NOT met: 89.56% < 90.00%
00:16:19 - WARNING - LAC does not meet coverage guarantee: 89.56% < 90.00%
00:16:19 - INFO -     LAC: Acc=22.00%, CR=89.56%, SS=5.25
00:16:19 - INFO - Initialized APSScorer
00:16:19 - INFO -   Alpha: 0.1
00:16:19 - INFO -   Target coverage: 90.0%
00:16:19 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
00:16:19 - INFO - Initialized PredictionSetGenerator
00:16:19 - INFO -   Methods: ['aps']
00:16:19 - INFO -   Alpha: 0.1
00:16:19 - INFO -   Aggregation: separate
00:16:19 - INFO - Calibrating 1 conformal predictors...
00:16:19 - INFO -   Calibrating APS...
00:16:19 - INFO - Calibrating with 4999 samples...
00:16:19 - INFO - Calibration complete
00:16:19 - INFO -   Threshold: 1.0000
00:16:19 - INFO -   Score range: [0.2127, 1.0000]
00:16:19 - INFO - Calibration complete
00:16:19 - INFO - Generating prediction sets using APS...
00:16:19 - INFO - Generating prediction sets for 5001 test instances...
00:16:19 - INFO - Prediction complete
00:16:19 - INFO -   Average set size: 5.83
00:16:19 - INFO -   Coverage rate: 98.22%
00:16:19 - INFO -   Meets coverage guarantee: True
00:16:19 - INFO - [PASS] Coverage guarantee met: 98.22% >= 90.00%
00:16:19 - INFO -     APS: Acc=22.00%, CR=98.22%, SS=5.83
00:16:24 - INFO - Unloaded model: phi-2_float16
00:16:25 - INFO - Checkpoint saved after completing: phi-2 | drs | float16
00:16:25 - INFO - 
================================================================================
00:16:25 - INFO - Run 5/5: phi-2 | ds | float16
00:16:25 - INFO - ================================================================================
00:16:25 - INFO - [start_phi-2_ds] GPU State: Allocated: 9.1MB | Reserved: 22.0MB | Free: 81146.6MB | Utilization: 82.0%
00:16:25 - INFO - Loading ds dataset (10000 samples)...
00:16:25 - INFO - Loading HaluSum dataset with 10000 samples...
00:16:26 - INFO - Loaded 10000 HaluSum instances
00:16:26 - INFO - [dataset_loading] Duration: 868.61ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:16:26 - INFO - Processing ds dataset to 6-option format...
00:17:00 - INFO - Processed 10000 instances for ds
00:17:00 - INFO - Option expansion statistics for ds:
00:17:00 - INFO -   Instances expanded (2→4 options): 10000
00:17:00 - INFO -   Total options sampled: 20000
00:17:00 - INFO -   Duplicate options avoided: 0
00:17:00 - INFO -   Fallback options used: 0
00:17:00 - INFO - Splitting ds dataset (calibration: 50%, test: 50%)
00:17:00 - INFO - Split complete:
00:17:00 - INFO -   Calibration: 4999 instances
00:17:00 - INFO -   Test: 5001 instances
00:17:00 - INFO - Answer distribution:
00:17:00 - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
00:17:00 - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
00:17:00 - INFO - [dataset_processing] Duration: 33746.09ms | GPU Memory: 9.1MB -> 9.1MB (delta +0.0MB)
00:17:00 - INFO - Initialized DemonstrationSelector
00:17:00 - INFO -   Strategy: random
00:17:00 - INFO -   Num demonstrations: 5
00:17:00 - INFO - Initialized DemonstrationManager
00:17:00 - INFO - Selecting 1 demonstrations using 'random' strategy
00:17:00 - INFO - Selected and cached 1 demonstrations for ds
00:17:00 - INFO - Loading model: phi-2 (float16)
00:17:00 - INFO - Loading model: phi-2_float16 (microsoft/phi-2)
00:17:00 - INFO - Loading tokenizer from microsoft/phi-2
00:17:00 - INFO - Tokenizer loaded successfully
00:17:00 - INFO -   Vocab size: 50295
00:17:00 - INFO -   Padding side: left
00:17:00 - INFO -   PAD token: <|endoftext|> (ID: 50256)
00:17:00 - INFO - Loading model from microsoft/phi-2
00:17:00 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]
00:17:02 - INFO - Model loaded successfully
00:17:02 - INFO -   GPU Memory: 5.19GB allocated, 5.21GB reserved

Model: phi-2_float16
  ID: microsoft/phi-2
  Type: causal
  Parameters: 2,779,683,840
  Vocab size: 50,295
  Max length: 2048
  Device: cuda:0
  Dtype: torch.float16
  Instruct-tuned: False
00:17:02 - INFO - [model_loading] Duration: 2381.47ms | GPU Memory: 9.1MB -> 5311.0MB (delta +5301.8MB)
00:17:02 - INFO - [after_model_load_phi-2] GPU State: Allocated: 5311.0MB | Reserved: 5334.0MB | Free: 75844.8MB | Utilization: 100.0%
00:17:02 - INFO - Using batch size: 32
00:17:02 - INFO -   Strategy: base
00:17:02 - INFO - Initialized PromptBuilder for task: ds
00:17:02 - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
00:17:02 - INFO - Building 10000 prompts using 'base' strategy with 1 demonstrations
00:17:02 - INFO - Initialized InferenceEngine for phi-2_float16
00:17:02 - INFO -   Device: cuda:0
00:17:02 - INFO -   Batch size: 32
00:17:02 - INFO -   Option tokens: {'A': 317, 'B': 347, 'C': 327, 'D': 360, 'E': 412, 'F': 376}
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:04<10:50,  4.17s/it]Running inference:   1%|▏         | 2/157 [00:08<10:43,  4.15s/it]Running inference:   2%|▏         | 3/157 [00:12<10:39,  4.15s/it]Running inference:   3%|▎         | 4/157 [00:16<10:34,  4.15s/it]Running inference:   3%|▎         | 5/157 [00:20<10:29,  4.14s/it]Running inference:   4%|▍         | 6/157 [00:24<10:25,  4.15s/it]Running inference:   4%|▍         | 7/157 [00:29<10:21,  4.14s/it]Running inference:   5%|▌         | 8/157 [00:33<10:20,  4.17s/it]Running inference:   6%|▌         | 9/157 [00:42<14:02,  5.69s/it]Running inference:   6%|▋         | 10/157 [00:53<17:55,  7.31s/it]Running inference:   7%|▋         | 11/157 [01:03<19:57,  8.20s/it]Running inference:   8%|▊         | 12/157 [01:14<22:04,  9.13s/it]Running inference:   8%|▊         | 13/157 [01:25<23:02,  9.60s/it]Running inference:   9%|▉         | 14/157 [01:36<23:47,  9.98s/it]Running inference:  10%|▉         | 15/157 [01:46<23:56, 10.11s/it]Running inference:  10%|█         | 16/157 [01:56<23:41, 10.08s/it]Running inference:  11%|█         | 17/157 [02:07<23:45, 10.18s/it]Running inference:  11%|█▏        | 18/157 [02:17<23:26, 10.12s/it]Running inference:  12%|█▏        | 19/157 [02:26<23:07, 10.05s/it]Running inference:  13%|█▎        | 20/157 [02:37<23:16, 10.20s/it]Running inference:  13%|█▎        | 21/157 [02:47<22:56, 10.12s/it]Running inference:  14%|█▍        | 22/157 [02:57<22:47, 10.13s/it]Running inference:  15%|█▍        | 23/157 [03:07<22:29, 10.07s/it]Running inference:  15%|█▌        | 24/157 [03:17<22:12, 10.02s/it]Running inference:  16%|█▌        | 25/157 [03:27<22:03, 10.02s/it]Running inference:  17%|█▋        | 26/157 [03:37<21:47,  9.98s/it]Running inference:  17%|█▋        | 27/157 [03:47<21:32,  9.94s/it]Running inference:  18%|█▊        | 28/157 [03:57<21:24,  9.95s/it]Running inference:  18%|█▊        | 29/157 [04:07<21:30, 10.08s/it]Running inference:  19%|█▉        | 30/157 [04:18<21:39, 10.23s/it]Running inference:  20%|█▉        | 31/157 [04:28<21:19, 10.15s/it]Running inference:  20%|██        | 32/157 [04:38<21:19, 10.23s/it]Running inference:  21%|██        | 33/157 [04:48<20:58, 10.15s/it]Running inference:  22%|██▏       | 34/157 [04:58<20:47, 10.14s/it]Running inference:  22%|██▏       | 35/157 [05:08<20:40, 10.17s/it]Running inference:  23%|██▎       | 36/157 [05:18<20:23, 10.11s/it]Running inference:  24%|██▎       | 37/157 [05:28<20:05, 10.04s/it]Running inference:  24%|██▍       | 38/157 [05:38<19:51, 10.01s/it]Running inference:  25%|██▍       | 39/157 [05:48<19:40, 10.01s/it]Running inference:  25%|██▌       | 40/157 [05:59<19:54, 10.21s/it]Running inference:  26%|██▌       | 41/157 [06:09<19:44, 10.21s/it]Running inference:  27%|██▋       | 42/157 [06:19<19:22, 10.11s/it]Running inference:  27%|██▋       | 43/157 [06:29<19:07, 10.07s/it]Running inference:  28%|██▊       | 44/157 [06:36<17:17,  9.18s/it]Running inference:  29%|██▊       | 45/157 [06:40<14:19,  7.67s/it]Running inference:  29%|██▉       | 46/157 [06:44<12:14,  6.61s/it]Running inference:  30%|██▉       | 47/157 [06:48<10:46,  5.88s/it]Running inference:  31%|███       | 48/157 [06:53<09:43,  5.35s/it]Running inference:  31%|███       | 49/157 [06:57<08:58,  4.99s/it]Running inference:  32%|███▏      | 50/157 [07:01<08:27,  4.74s/it]Running inference:  32%|███▏      | 51/157 [07:05<08:03,  4.56s/it]Running inference:  33%|███▎      | 52/157 [07:09<07:45,  4.43s/it]Running inference:  34%|███▍      | 53/157 [07:13<07:31,  4.35s/it]Running inference:  34%|███▍      | 54/157 [07:20<08:52,  5.17s/it]Running inference:  35%|███▌      | 55/157 [07:31<11:30,  6.77s/it]Running inference:  36%|███▌      | 56/157 [07:41<13:15,  7.87s/it]Running inference:  36%|███▋      | 57/157 [07:52<14:20,  8.61s/it]Running inference:  37%|███▋      | 58/157 [08:03<15:33,  9.43s/it]Running inference:  38%|███▊      | 59/157 [08:14<15:59,  9.79s/it]Running inference:  38%|███▊      | 60/157 [08:24<16:06,  9.96s/it]Running inference:  39%|███▉      | 61/157 [08:34<16:09, 10.10s/it]Running inference:  39%|███▉      | 62/157 [08:46<16:49, 10.62s/it]Running inference:  40%|████      | 63/157 [08:58<17:07, 10.93s/it]Running inference:  41%|████      | 64/157 [09:09<16:58, 10.96s/it]Running inference:  41%|████▏     | 65/157 [09:20<16:58, 11.07s/it]Running inference:  42%|████▏     | 66/157 [09:32<17:02, 11.24s/it]Running inference:  43%|████▎     | 67/157 [09:43<16:44, 11.16s/it]Running inference:  43%|████▎     | 68/157 [09:54<16:36, 11.20s/it]Running inference:  44%|████▍     | 69/157 [10:05<16:27, 11.22s/it]Running inference:  45%|████▍     | 70/157 [10:17<16:20, 11.27s/it]Running inference:  45%|████▌     | 71/157 [10:28<16:13, 11.32s/it]Running inference:  46%|████▌     | 72/157 [10:39<15:57, 11.26s/it]Running inference:  46%|████▋     | 73/157 [10:50<15:27, 11.04s/it]Running inference:  47%|████▋     | 74/157 [11:00<14:59, 10.84s/it]Running inference:  48%|████▊     | 75/157 [11:11<14:39, 10.72s/it]Running inference:  48%|████▊     | 76/157 [11:21<14:21, 10.63s/it]Running inference:  49%|████▉     | 77/157 [11:32<14:21, 10.77s/it]Running inference:  50%|████▉     | 78/157 [11:43<14:18, 10.87s/it]Running inference:  50%|█████     | 79/157 [11:54<13:58, 10.75s/it]Running inference:  51%|█████     | 80/157 [12:05<13:48, 10.76s/it]Running inference:  52%|█████▏    | 81/157 [12:16<13:42, 10.82s/it]Running inference:  52%|█████▏    | 82/157 [12:26<13:25, 10.74s/it]Running inference:  53%|█████▎    | 83/157 [12:37<13:17, 10.77s/it]Running inference:  54%|█████▎    | 84/157 [12:47<13:00, 10.70s/it]Running inference:  54%|█████▍    | 85/157 [12:58<12:53, 10.74s/it]Running inference:  55%|█████▍    | 86/157 [13:09<12:36, 10.65s/it]Running inference:  55%|█████▌    | 87/157 [13:19<12:23, 10.62s/it]Running inference:  56%|█████▌    | 88/157 [13:30<12:12, 10.62s/it]Running inference:  57%|█████▋    | 89/157 [13:41<12:14, 10.80s/it]Running inference:  57%|█████▋    | 90/157 [13:53<12:23, 11.10s/it]Running inference:  58%|█████▊    | 91/157 [14:04<12:09, 11.05s/it]Running inference:  59%|█████▊    | 92/157 [14:16<12:10, 11.24s/it]Running inference:  59%|█████▉    | 93/157 [14:26<11:48, 11.07s/it]Running inference:  60%|█████▉    | 94/157 [14:37<11:37, 11.07s/it]Running inference:  61%|██████    | 95/157 [14:49<11:32, 11.17s/it]Running inference:  61%|██████    | 96/157 [15:00<11:22, 11.18s/it]Running inference:  62%|██████▏   | 97/157 [15:10<10:58, 10.98s/it]Running inference:  62%|██████▏   | 98/157 [15:21<10:37, 10.81s/it]Running inference:  63%|██████▎   | 99/157 [15:31<10:20, 10.71s/it]Running inference:  64%|██████▎   | 100/157 [15:42<10:03, 10.59s/it]Running inference:  64%|██████▍   | 101/157 [15:52<09:56, 10.66s/it]Running inference:  65%|██████▍   | 102/157 [16:04<09:52, 10.78s/it]Running inference:  66%|██████▌   | 103/157 [16:14<09:42, 10.79s/it]Running inference:  66%|██████▌   | 104/157 [16:25<09:26, 10.68s/it]Running inference:  67%|██████▋   | 105/157 [16:35<09:11, 10.61s/it]Running inference:  68%|██████▊   | 106/157 [16:46<08:58, 10.56s/it]Running inference:  68%|██████▊   | 107/157 [16:56<08:47, 10.55s/it]Running inference:  69%|██████▉   | 108/157 [17:06<08:33, 10.48s/it]Running inference:  69%|██████▉   | 109/157 [17:17<08:23, 10.49s/it]Running inference:  70%|███████   | 110/157 [17:27<08:12, 10.48s/it]Running inference:  71%|███████   | 111/157 [17:38<08:06, 10.58s/it]Running inference:  71%|███████▏  | 112/157 [17:50<08:07, 10.83s/it]Running inference:  72%|███████▏  | 113/157 [18:00<07:55, 10.81s/it]Running inference:  73%|███████▎  | 114/157 [18:12<07:52, 11.00s/it]Running inference:  73%|███████▎  | 115/157 [18:24<07:52, 11.25s/it]Running inference:  74%|███████▍  | 116/157 [18:35<07:39, 11.21s/it]Running inference:  75%|███████▍  | 117/157 [18:46<07:30, 11.26s/it]Running inference:  75%|███████▌  | 118/157 [18:57<07:08, 10.99s/it]Running inference:  76%|███████▌  | 119/157 [19:08<07:01, 11.08s/it]Running inference:  76%|███████▋  | 120/157 [19:19<06:52, 11.15s/it]Running inference:  77%|███████▋  | 121/157 [19:30<06:41, 11.16s/it]Running inference:  78%|███████▊  | 122/157 [19:41<06:25, 11.01s/it]Running inference:  78%|███████▊  | 123/157 [19:52<06:08, 10.85s/it]Running inference:  79%|███████▉  | 124/157 [20:02<05:58, 10.86s/it]Running inference:  80%|███████▉  | 125/157 [20:13<05:44, 10.75s/it]Running inference:  80%|████████  | 126/157 [20:24<05:34, 10.79s/it]Running inference:  81%|████████  | 127/157 [20:35<05:25, 10.85s/it]Running inference:  82%|████████▏ | 128/157 [20:46<05:16, 10.93s/it]Running inference:  82%|████████▏ | 129/157 [20:57<05:03, 10.85s/it]Running inference:  83%|████████▎ | 130/157 [21:08<04:56, 10.98s/it]Running inference:  83%|████████▎ | 131/157 [21:18<04:42, 10.86s/it]Running inference:  84%|████████▍ | 132/157 [21:29<04:29, 10.78s/it]Running inference:  85%|████████▍ | 133/157 [21:40<04:17, 10.74s/it]Running inference:  85%|████████▌ | 134/157 [21:50<04:06, 10.72s/it]Running inference:  86%|████████▌ | 135/157 [22:01<03:54, 10.66s/it]Running inference:  87%|████████▋ | 136/157 [22:12<03:46, 10.79s/it]Running inference:  87%|████████▋ | 137/157 [22:23<03:35, 10.79s/it]Running inference:  88%|████████▊ | 138/157 [22:34<03:27, 10.90s/it]Running inference:  89%|████████▊ | 139/157 [22:45<03:14, 10.81s/it]Running inference:  89%|████████▉ | 140/157 [22:55<03:03, 10.81s/it]Running inference:  90%|████████▉ | 141/157 [23:07<02:55, 10.97s/it]Running inference:  90%|█████████ | 142/157 [23:17<02:42, 10.84s/it]Running inference:  91%|█████████ | 143/157 [23:28<02:32, 10.89s/it]Running inference:  92%|█████████▏| 144/157 [23:40<02:25, 11.18s/it]Running inference:  92%|█████████▏| 145/157 [23:52<02:16, 11.41s/it]Running inference:  93%|█████████▎| 146/157 [24:03<02:05, 11.38s/it]Running inference:  94%|█████████▎| 147/157 [24:15<01:54, 11.41s/it]Running inference:  94%|█████████▍| 148/157 [24:26<01:41, 11.29s/it]Running inference:  95%|█████████▍| 149/157 [24:37<01:29, 11.24s/it]Running inference:  96%|█████████▌| 150/157 [24:49<01:19, 11.39s/it]Running inference:  96%|█████████▌| 151/157 [25:00<01:08, 11.45s/it]Running inference:  97%|█████████▋| 152/157 [25:11<00:56, 11.23s/it]Running inference:  97%|█████████▋| 153/157 [25:22<00:44, 11.11s/it]Running inference:  98%|█████████▊| 154/157 [25:33<00:33, 11.22s/it]Running inference:  99%|█████████▊| 155/157 [25:45<00:22, 11.35s/it]Running inference:  99%|█████████▉| 156/157 [25:56<00:11, 11.15s/it]Running inference: 100%|██████████| 157/157 [25:58<00:00,  8.51s/it]Running inference: 100%|██████████| 157/157 [25:58<00:00,  9.93s/it]
00:43:01 - INFO - [inference_calibration] Duration: 1558456.42ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
Running inference:   0%|          | 0/157 [00:00<?, ?it/s]Running inference:   1%|          | 1/157 [00:10<27:09, 10.45s/it]Running inference:   1%|▏         | 2/157 [00:20<27:01, 10.46s/it]Running inference:   2%|▏         | 3/157 [00:31<27:13, 10.60s/it]Running inference:   3%|▎         | 4/157 [00:43<27:51, 10.92s/it]Running inference:   3%|▎         | 5/157 [00:53<27:18, 10.78s/it]Running inference:   4%|▍         | 6/157 [01:04<27:09, 10.79s/it]Running inference:   4%|▍         | 7/157 [01:14<26:43, 10.69s/it]Running inference:   5%|▌         | 8/157 [01:25<26:22, 10.62s/it]Running inference:   6%|▌         | 9/157 [01:36<26:11, 10.62s/it]Running inference:   6%|▋         | 10/157 [01:46<25:52, 10.56s/it]Running inference:   7%|▋         | 11/157 [01:56<25:34, 10.51s/it]Running inference:   8%|▊         | 12/157 [02:07<25:42, 10.64s/it]Running inference:   8%|▊         | 13/157 [02:18<25:25, 10.59s/it]Running inference:   9%|▉         | 14/157 [02:28<25:01, 10.50s/it]Running inference:  10%|▉         | 15/157 [02:39<25:03, 10.59s/it]Running inference:  10%|█         | 16/157 [02:49<24:49, 10.56s/it]Running inference:  11%|█         | 17/157 [03:00<24:35, 10.54s/it]Running inference:  11%|█▏        | 18/157 [03:11<24:36, 10.62s/it]Running inference:  12%|█▏        | 19/157 [03:21<24:17, 10.56s/it]Running inference:  13%|█▎        | 20/157 [03:32<24:18, 10.65s/it]Running inference:  13%|█▎        | 21/157 [03:42<23:59, 10.59s/it]Running inference:  14%|█▍        | 22/157 [03:53<23:59, 10.66s/it]Running inference:  15%|█▍        | 23/157 [04:05<24:17, 10.88s/it]Running inference:  15%|█▌        | 24/157 [04:15<23:42, 10.70s/it]Running inference:  16%|█▌        | 25/157 [04:25<23:23, 10.63s/it]Running inference:  17%|█▋        | 26/157 [04:36<23:13, 10.64s/it]Running inference:  17%|█▋        | 27/157 [04:46<22:53, 10.56s/it]Running inference:  18%|█▊        | 28/157 [04:56<22:20, 10.39s/it]Running inference:  18%|█▊        | 29/157 [05:01<18:10,  8.52s/it]Running inference:  19%|█▉        | 30/157 [05:05<15:15,  7.21s/it]Running inference:  20%|█▉        | 31/157 [05:09<13:12,  6.29s/it]Running inference:  20%|██        | 32/157 [05:13<11:46,  5.65s/it]Running inference:  21%|██        | 33/157 [05:17<10:44,  5.20s/it]Running inference:  22%|██▏       | 34/157 [05:21<10:00,  4.88s/it]Running inference:  22%|██▏       | 35/157 [05:25<09:28,  4.66s/it]Running inference:  23%|██▎       | 36/157 [05:30<09:05,  4.51s/it]Running inference:  24%|██▎       | 37/157 [05:34<08:47,  4.40s/it]Running inference:  24%|██▍       | 38/157 [05:38<08:33,  4.32s/it]Running inference:  25%|██▍       | 39/157 [05:42<08:23,  4.26s/it]Running inference:  25%|██▌       | 40/157 [05:46<08:14,  4.23s/it]Running inference:  26%|██▌       | 41/157 [05:50<08:07,  4.21s/it]Running inference:  27%|██▋       | 42/157 [05:54<08:01,  4.19s/it]Running inference:  27%|██▋       | 43/157 [05:59<07:56,  4.18s/it]Running inference:  28%|██▊       | 44/157 [06:03<07:50,  4.17s/it]Running inference:  29%|██▊       | 45/157 [06:07<07:45,  4.16s/it]Running inference:  29%|██▉       | 46/157 [06:11<07:41,  4.15s/it]Running inference:  30%|██▉       | 47/157 [06:15<07:36,  4.15s/it]Running inference:  31%|███       | 48/157 [06:19<07:32,  4.15s/it]Running inference:  31%|███       | 49/157 [06:23<07:27,  4.15s/it]Running inference:  32%|███▏      | 50/157 [06:28<07:24,  4.15s/it]Running inference:  32%|███▏      | 51/157 [06:32<07:20,  4.16s/it]Running inference:  33%|███▎      | 52/157 [06:36<07:16,  4.16s/it]Running inference:  34%|███▍      | 53/157 [06:40<07:11,  4.15s/it]Running inference:  34%|███▍      | 54/157 [06:44<07:07,  4.15s/it]Running inference:  35%|███▌      | 55/157 [06:48<07:03,  4.15s/it]Running inference:  36%|███▌      | 56/157 [06:52<06:59,  4.15s/it]Running inference:  36%|███▋      | 57/157 [06:57<06:54,  4.15s/it]Running inference:  37%|███▋      | 58/157 [07:01<06:50,  4.15s/it]Running inference:  38%|███▊      | 59/157 [07:05<06:46,  4.15s/it]Running inference:  38%|███▊      | 60/157 [07:09<06:42,  4.15s/it]Running inference:  39%|███▉      | 61/157 [07:13<06:38,  4.15s/it]Running inference:  39%|███▉      | 62/157 [07:17<06:33,  4.15s/it]Running inference:  40%|████      | 63/157 [07:21<06:29,  4.15s/it]Running inference:  41%|████      | 64/157 [07:26<06:25,  4.15s/it]Running inference:  41%|████▏     | 65/157 [07:30<06:21,  4.14s/it]Running inference:  42%|████▏     | 66/157 [07:34<06:16,  4.14s/it]Running inference:  43%|████▎     | 67/157 [07:38<06:12,  4.14s/it]Running inference:  43%|████▎     | 68/157 [07:42<06:08,  4.14s/it]Running inference:  44%|████▍     | 69/157 [07:46<06:05,  4.15s/it]Running inference:  45%|████▍     | 70/157 [07:51<06:00,  4.15s/it]Running inference:  45%|████▌     | 71/157 [07:55<05:56,  4.15s/it]Running inference:  46%|████▌     | 72/157 [07:59<05:52,  4.15s/it]Running inference:  46%|████▋     | 73/157 [08:03<05:48,  4.15s/it]Running inference:  47%|████▋     | 74/157 [08:07<05:44,  4.15s/it]Running inference:  48%|████▊     | 75/157 [08:11<05:40,  4.15s/it]Running inference:  48%|████▊     | 76/157 [08:15<05:36,  4.15s/it]Running inference:  49%|████▉     | 77/157 [08:20<05:32,  4.15s/it]Running inference:  50%|████▉     | 78/157 [08:24<05:27,  4.15s/it]Running inference:  50%|█████     | 79/157 [08:28<05:23,  4.15s/it]Running inference:  51%|█████     | 80/157 [08:32<05:19,  4.15s/it]Running inference:  52%|█████▏    | 81/157 [08:36<05:15,  4.15s/it]Running inference:  52%|█████▏    | 82/157 [08:40<05:11,  4.15s/it]Running inference:  53%|█████▎    | 83/157 [08:44<05:06,  4.15s/it]Running inference:  54%|█████▎    | 84/157 [08:49<05:02,  4.15s/it]Running inference:  54%|█████▍    | 85/157 [08:53<04:58,  4.15s/it]Running inference:  55%|█████▍    | 86/157 [08:57<04:54,  4.15s/it]Running inference:  55%|█████▌    | 87/157 [09:01<04:50,  4.15s/it]Running inference:  56%|█████▌    | 88/157 [09:05<04:46,  4.15s/it]Running inference:  57%|█████▋    | 89/157 [09:09<04:42,  4.15s/it]Running inference:  57%|█████▋    | 90/157 [09:14<04:38,  4.16s/it]Running inference:  58%|█████▊    | 91/157 [09:18<04:34,  4.15s/it]Running inference:  59%|█████▊    | 92/157 [09:22<04:30,  4.15s/it]Running inference:  59%|█████▉    | 93/157 [09:26<04:25,  4.15s/it]Running inference:  60%|█████▉    | 94/157 [09:30<04:21,  4.15s/it]Running inference:  61%|██████    | 95/157 [09:34<04:17,  4.15s/it]Running inference:  61%|██████    | 96/157 [09:38<04:12,  4.15s/it]Running inference:  62%|██████▏   | 97/157 [09:43<04:08,  4.15s/it]Running inference:  62%|██████▏   | 98/157 [09:47<04:04,  4.15s/it]Running inference:  63%|██████▎   | 99/157 [09:51<04:00,  4.15s/it]Running inference:  64%|██████▎   | 100/157 [09:55<03:56,  4.16s/it]Running inference:  64%|██████▍   | 101/157 [09:59<03:52,  4.16s/it]Running inference:  65%|██████▍   | 102/157 [10:03<03:48,  4.15s/it]Running inference:  66%|██████▌   | 103/157 [10:07<03:44,  4.15s/it]Running inference:  66%|██████▌   | 104/157 [10:12<03:39,  4.15s/it]Running inference:  67%|██████▋   | 105/157 [10:16<03:35,  4.15s/it]Running inference:  68%|██████▊   | 106/157 [10:20<03:31,  4.15s/it]Running inference:  68%|██████▊   | 107/157 [10:24<03:27,  4.15s/it]Running inference:  69%|██████▉   | 108/157 [10:28<03:23,  4.15s/it]Running inference:  69%|██████▉   | 109/157 [10:32<03:19,  4.15s/it]Running inference:  70%|███████   | 110/157 [10:37<03:14,  4.15s/it]Running inference:  71%|███████   | 111/157 [10:41<03:10,  4.15s/it]Running inference:  71%|███████▏  | 112/157 [10:45<03:06,  4.15s/it]Running inference:  72%|███████▏  | 113/157 [10:49<03:02,  4.15s/it]Running inference:  73%|███████▎  | 114/157 [10:53<02:58,  4.14s/it]Running inference:  73%|███████▎  | 115/157 [10:57<02:53,  4.14s/it]Running inference:  74%|███████▍  | 116/157 [11:01<02:49,  4.14s/it]Running inference:  75%|███████▍  | 117/157 [11:06<02:45,  4.14s/it]Running inference:  75%|███████▌  | 118/157 [11:10<02:41,  4.15s/it]Running inference:  76%|███████▌  | 119/157 [11:14<02:37,  4.15s/it]Running inference:  76%|███████▋  | 120/157 [11:18<02:33,  4.15s/it]Running inference:  77%|███████▋  | 121/157 [11:22<02:29,  4.15s/it]Running inference:  78%|███████▊  | 122/157 [11:26<02:25,  4.15s/it]Running inference:  78%|███████▊  | 123/157 [11:30<02:21,  4.15s/it]Running inference:  79%|███████▉  | 124/157 [11:35<02:16,  4.15s/it]Running inference:  80%|███████▉  | 125/157 [11:39<02:12,  4.15s/it]Running inference:  80%|████████  | 126/157 [11:43<02:08,  4.15s/it]Running inference:  81%|████████  | 127/157 [11:47<02:04,  4.15s/it]Running inference:  82%|████████▏ | 128/157 [11:51<02:00,  4.14s/it]Running inference:  82%|████████▏ | 129/157 [11:55<01:56,  4.14s/it]Running inference:  83%|████████▎ | 130/157 [11:59<01:51,  4.15s/it]Running inference:  83%|████████▎ | 131/157 [12:04<01:47,  4.14s/it]Running inference:  84%|████████▍ | 132/157 [12:08<01:43,  4.14s/it]Running inference:  85%|████████▍ | 133/157 [12:12<01:39,  4.14s/it]Running inference:  85%|████████▌ | 134/157 [12:16<01:35,  4.14s/it]Running inference:  86%|████████▌ | 135/157 [12:20<01:31,  4.14s/it]Running inference:  87%|████████▋ | 136/157 [12:24<01:26,  4.14s/it]Running inference:  87%|████████▋ | 137/157 [12:28<01:22,  4.14s/it]Running inference:  88%|████████▊ | 138/157 [12:33<01:18,  4.14s/it]Running inference:  89%|████████▊ | 139/157 [12:37<01:14,  4.15s/it]Running inference:  89%|████████▉ | 140/157 [12:41<01:10,  4.15s/it]Running inference:  90%|████████▉ | 141/157 [12:45<01:06,  4.15s/it]Running inference:  90%|█████████ | 142/157 [12:49<01:02,  4.15s/it]Running inference:  91%|█████████ | 143/157 [12:53<00:58,  4.15s/it]Running inference:  92%|█████████▏| 144/157 [12:57<00:53,  4.15s/it]Running inference:  92%|█████████▏| 145/157 [13:02<00:49,  4.15s/it]Running inference:  93%|█████████▎| 146/157 [13:06<00:45,  4.15s/it]Running inference:  94%|█████████▎| 147/157 [13:10<00:41,  4.15s/it]Running inference:  94%|█████████▍| 148/157 [13:14<00:37,  4.15s/it]Running inference:  95%|█████████▍| 149/157 [13:18<00:33,  4.15s/it]Running inference:  96%|█████████▌| 150/157 [13:22<00:29,  4.15s/it]Running inference:  96%|█████████▌| 151/157 [13:27<00:24,  4.15s/it]Running inference:  97%|█████████▋| 152/157 [13:31<00:20,  4.15s/it]Running inference:  97%|█████████▋| 153/157 [13:35<00:16,  4.15s/it]Running inference:  98%|█████████▊| 154/157 [13:39<00:12,  4.15s/it]Running inference:  99%|█████████▊| 155/157 [13:43<00:08,  4.15s/it]Running inference:  99%|█████████▉| 156/157 [13:47<00:04,  4.15s/it]Running inference: 100%|██████████| 157/157 [13:48<00:00,  3.26s/it]Running inference: 100%|██████████| 157/157 [13:48<00:00,  5.28s/it]
00:56:50 - INFO - [inference_test] Duration: 828939.55ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
00:56:50 - INFO -     Inference: 2387.40s for 10000 samples (4.19 samples/sec)
00:56:50 - INFO - Initialized ProbabilityExtractor
00:56:50 - INFO -   Temperature: 1.0
00:56:50 - INFO -   Calibration method: None
00:56:50 - INFO - [probability_extraction] Duration: 276.74ms | GPU Memory: 5311.0MB -> 5311.0MB (delta +0.0MB)
00:56:50 - INFO -     Raw probabilities saved to: outputs/results/probabilities/probs_phi-2_ds_float16_base_20251207_231938.npz
00:56:50 - INFO - Initialized LACScorer
00:56:50 - INFO -   Alpha: 0.1
00:56:50 - INFO -   Target coverage: 90.0%
00:56:50 - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
00:56:50 - INFO - Initialized PredictionSetGenerator
00:56:50 - INFO -   Methods: ['lac']
00:56:50 - INFO -   Alpha: 0.1
00:56:50 - INFO -   Aggregation: separate
00:56:50 - INFO - Calibrating 1 conformal predictors...
00:56:50 - INFO -   Calibrating LAC...
00:56:50 - INFO - Calibrating with 4999 samples...
00:56:50 - INFO - Calibration complete
00:56:50 - INFO -   Threshold: 0.9710
00:56:50 - INFO -   Score range: [0.0004, 1.0000]
00:56:50 - INFO - Calibration complete
00:56:50 - INFO - Generating prediction sets using LAC...
00:56:50 - INFO - Generating prediction sets for 5001 test instances...
00:56:50 - INFO - Prediction complete
00:56:50 - INFO -   Average set size: 5.17
00:56:50 - INFO -   Coverage rate: 89.80%
00:56:50 - INFO -   Meets coverage guarantee: False
00:56:50 - WARNING - ✗ Coverage guarantee NOT met: 89.80% < 90.00%
00:56:50 - WARNING - LAC does not meet coverage guarantee: 89.80% < 90.00%
00:56:50 - INFO -     LAC: Acc=32.35%, CR=89.80%, SS=5.17
00:56:50 - INFO - Initialized APSScorer
00:56:50 - INFO -   Alpha: 0.1
00:56:50 - INFO -   Target coverage: 90.0%
00:56:50 - INFO - Initialized APS (Adaptive Prediction Sets) scorer
00:56:50 - INFO - Initialized PredictionSetGenerator
00:56:50 - INFO -   Methods: ['aps']
00:56:50 - INFO -   Alpha: 0.1
00:56:50 - INFO -   Aggregation: separate
00:56:50 - INFO - Calibrating 1 conformal predictors...
00:56:50 - INFO -   Calibrating APS...
00:56:50 - INFO - Calibrating with 4999 samples...
00:56:50 - INFO - Calibration complete
00:56:50 - INFO -   Threshold: 0.9986
00:56:50 - INFO -   Score range: [0.1955, 1.0000]
00:56:50 - INFO - Calibration complete
00:56:50 - INFO - Generating prediction sets using APS...
00:56:50 - INFO - Generating prediction sets for 5001 test instances...
00:56:50 - INFO - Prediction complete
00:56:50 - INFO -   Average set size: 4.94
00:56:50 - INFO -   Coverage rate: 89.28%
00:56:50 - INFO -   Meets coverage guarantee: False
00:56:50 - WARNING - ✗ Coverage guarantee NOT met: 89.28% < 90.00%
00:56:50 - WARNING - APS does not meet coverage guarantee: 89.28% < 90.00%
00:56:50 - INFO -     APS: Acc=32.35%, CR=89.28%, SS=4.94
00:56:55 - INFO - Unloaded model: phi-2_float16
00:56:56 - INFO - Checkpoint saved after completing: phi-2 | ds | float16
00:56:56 - INFO - Generating all visualizations...
00:56:57 - INFO - Saved heatmap to outputs/results/figures/heatmap_accuracy.png
00:56:57 - INFO - Saved heatmap to outputs/results/figures/heatmap_coverage_rate.png
00:56:58 - INFO - Saved heatmap to outputs/results/figures/heatmap_avg_set_size.png
00:56:59 - INFO - Saved dashboard to outputs/results/figures/dashboard.png
00:57:00 - INFO - Saved bar chart to outputs/results/figures/bar_comparison_accuracy.png
00:57:00 - INFO - Saved bar chart to outputs/results/figures/bar_comparison_avg_set_size.png
00:57:01 - INFO - Saved radar chart to outputs/results/figures/radar_chart.png
00:57:01 - INFO - Saved uncertainty analysis to outputs/results/figures/uncertainty_analysis.png
00:57:01 - INFO - Saved summary table to outputs/results/figures/results_summary.md
00:57:01 - INFO - Saved summary table to outputs/results/figures/results_summary_lac.md
00:57:01 - INFO - Saved summary table to outputs/results/figures/results_summary_aps.md
00:57:01 - INFO - All visualizations saved to outputs/results/figures
00:57:01 - INFO - Visualizations saved to: outputs/results/figures
00:57:03 - INFO - Stopped GPU monitoring. Collected 1902 snapshots.

================================================================================
GPU PROFILING SUMMARY
================================================================================

Total Operations: 30
Total Time: 5798066.39ms (5798.07s)

--- Operations Breakdown ---

  [inference_calibration]
    Count: 5
    Total: 2963254.27ms (51.1%)
    Avg: 592650.85ms | Min: 281212.78ms | Max: 1558456.42ms
    Avg Memory Delta: +1.8MB

  [inference_test]
    Count: 5
    Total: 2741973.90ms (47.3%)
    Avg: 548394.78ms | Min: 282117.88ms | Max: 828939.55ms
    Avg Memory Delta: +0.0MB

  [dataset_processing]
    Count: 5
    Total: 67054.93ms (1.2%)
    Avg: 13410.99ms | Min: 224.73ms | Max: 33746.09ms
    Avg Memory Delta: +0.0MB

  [dataset_loading]
    Count: 5
    Total: 13319.22ms (0.2%)
    Avg: 2663.84ms | Min: 868.61ms | Max: 4226.69ms
    Avg Memory Delta: +0.0MB

  [model_loading]
    Count: 5
    Total: 11063.97ms (0.2%)
    Avg: 2212.79ms | Min: 1878.88ms | Max: 2406.98ms
    Avg Memory Delta: +5301.8MB

  [probability_extraction]
    Count: 5
    Total: 1400.11ms (0.0%)
    Avg: 280.02ms | Min: 254.17ms | Max: 322.40ms
    Avg Memory Delta: +0.0MB

--- Memory Statistics ---
  Peak Allocated: 14720.2MB
  Avg Allocated: 8683.5MB
  Avg GPU Utilization: 97.4%

--- Bottlenecks & Recommendations ---

  [WARN] inference_calibration (51.1% of total time)
     -> Inference is slow. Consider: larger batch size, Flash Attention, or quantization.

  [WARN] inference_test (47.3% of total time)
     -> Inference is slow. Consider: larger batch size, Flash Attention, or quantization.

================================================================================
00:57:03 - INFO - Saved GPU profiling report to outputs/results/gpu_profile_20251207_231938.json
00:57:03 - INFO - GPU profiling report saved to: outputs/results/gpu_profile_20251207_231938.json
00:57:03 - INFO - 
================================================================================
00:57:03 - INFO - BENCHMARK COMPLETE
00:57:03 - INFO - ================================================================================
00:57:03 - INFO - Total time: 97.26 minutes
00:57:03 - INFO - Results saved to: outputs/results

================================================================================
FINAL SUMMARY
================================================================================
Total runs: 10
Overall accuracy: 24.44%
Overall coverage: 92.50%
Overall set size: 5.39
Guarantee met: 60.00%
Total time: 97.26 minutes
Log file: outputs/results/logs/benchmark_20251207_231938.log
================================================================================

00:57:03 - INFO - Benchmark completed successfully
00:57:03 - INFO - Total runs: 10
00:57:03 - INFO - Overall accuracy: 24.44%
00:57:03 - INFO - Overall coverage: 92.50%
00:57:03 - INFO - Log file saved to: outputs/results/logs/benchmark_20251207_231938.log
