# BLUQ Benchmark Results

## Accuracy (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| tinyllama-1.1b | 0.2 | 0.2 | 0.2 | 0.2 | 0.2 | **0.2** |

## Coverage Rate (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| tinyllama-1.1b | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | **0.9** |

## Average Set Size

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| tinyllama-1.1b | 5.06 | 5.09 | 5.21 | 5.04 | 4.51 | **4.98** |