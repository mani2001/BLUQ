# BLUQ Benchmark Results - APS

## Accuracy (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| smollm-1.7b | 0.2 | 0.1 | 0.2 | 0.1 | 0.3 | **0.2** |

## Coverage Rate (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| smollm-1.7b | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | **1.0** |

## Average Set Size

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| smollm-1.7b | 6.00 | 5.85 | 5.95 | 6.00 | 5.88 | **5.94** |