# BLUQ Benchmark Results - APS

## Accuracy (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| phi-2 | 0.2 | 0.2 | 0.2 | 0.5 | 0.5 | **0.3** |
| tinyllama-1.1b | 0.2 | 0.2 | 0.2 | 0.4 | 0.5 | **0.3** |

## Coverage Rate (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| phi-2 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | **1.0** |
| tinyllama-1.1b | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | **1.0** |

## Average Set Size

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| phi-2 | 5.98 | 5.95 | 5.97 | 5.73 | 5.05 | **5.74** |
| tinyllama-1.1b | 5.97 | 5.96 | 6.00 | 5.69 | 5.19 | **5.76** |