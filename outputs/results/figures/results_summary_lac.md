# BLUQ Benchmark Results - LAC

## Accuracy (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| phi-2 | 0.2 | 0.2 | 0.2 | 0.5 | 0.5 | **0.3** |
| tinyllama-1.1b | 0.2 | 0.2 | 0.2 | 0.4 | 0.5 | **0.3** |

## Coverage Rate (%)

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| phi-2 | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | **0.9** |
| tinyllama-1.1b | 0.9 | 0.9 | 0.9 | 0.9 | 0.9 | **0.9** |

## Average Set Size

| Model | Question Answering | Reading Comprehension | Commonsense Inference | Dialogue Response | Document Summarization | Avg |
|---|---|---|---|---|---|---|
| phi-2 | 5.24 | 5.16 | 5.12 | 4.83 | 3.92 | **4.85** |
| tinyllama-1.1b | 5.24 | 5.20 | 5.29 | 5.03 | 4.26 | **5.00** |