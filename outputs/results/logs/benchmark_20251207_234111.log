2025-12-07 23:41:11 - __main__ - INFO - Starting benchmark run
2025-12-07 23:41:11 - __main__ - INFO - Log file: outputs/results/logs/benchmark_20251207_234111.log
2025-12-07 23:41:11 - __main__ - INFO - Mode: long, Samples: 10000
2025-12-07 23:41:11 - __main__ - INFO - Models: ['qwen-1.8b']
2025-12-07 23:41:11 - __main__ - INFO - Tasks: ['qa', 'rc', 'ci', 'drs', 'ds']
2025-12-07 23:41:11 - __main__ - INFO - Dtypes: ['float16']
2025-12-07 23:41:13 - __main__ - INFO - Running on: Device: NVIDIA A100 80GB PCIe (cuda)
  Total Memory: 79.25 GB
  Available Memory: 79.25 GB
2025-12-07 23:41:13 - src.utils.gpu - INFO - Detected A100 GPU: NVIDIA A100 80GB PCIe - using optimized A100 settings
2025-12-07 23:41:13 - __main__ - INFO - GPU Tier: a100 | Auto max_batch_size: 192 | Safety margin: 0.93
2025-12-07 23:41:13 - __main__ - INFO - Using user-specified max_batch_size: 32
2025-12-07 23:41:13 - src.utils.gpu - INFO - NVML initialized for GPU utilization monitoring
2025-12-07 23:41:13 - src.utils.gpu - INFO - GPUProfiler initialized (CUDA: True, NVML: True)
2025-12-07 23:41:13 - src.utils.gpu - INFO - Started GPU monitoring
2025-12-07 23:41:13 - __main__ - INFO - GPU profiling enabled
2025-12-07 23:41:13 - __main__ - INFO - 
================================================================================
2025-12-07 23:41:13 - __main__ - INFO - FULL BENCHMARK CONFIGURATION
2025-12-07 23:41:13 - __main__ - INFO - ================================================================================
2025-12-07 23:41:13 - __main__ - INFO - Models (1): ['qwen-1.8b']
2025-12-07 23:41:13 - __main__ - INFO - Tasks (5): ['qa', 'rc', 'ci', 'drs', 'ds']
2025-12-07 23:41:13 - __main__ - INFO - Data types: ['float16']
2025-12-07 23:41:13 - __main__ - INFO - Samples per task: 10000
2025-12-07 23:41:13 - __main__ - INFO - Alpha (error rate): 0.1
2025-12-07 23:41:13 - __main__ - INFO - Strategies: ['base']
2025-12-07 23:41:13 - __main__ - INFO - Conformal methods: ['lac', 'aps']
2025-12-07 23:41:13 - __main__ - INFO - Dynamic batch sizing: False
2025-12-07 23:41:13 - __main__ - INFO - Max batch size: 32 (GPU tier: a100)
2025-12-07 23:41:13 - __main__ - INFO - Output directory: outputs/results
2025-12-07 23:41:13 - __main__ - INFO - 
================================================================================
2025-12-07 23:41:13 - __main__ - INFO - Run 1/5: qwen-1.8b | qa | float16
2025-12-07 23:41:13 - __main__ - INFO - ================================================================================
2025-12-07 23:41:17 - src.utils.gpu - INFO - [start_qwen-1.8b_qa] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 25.0%
2025-12-07 23:41:17 - __main__ - INFO - Loading qa dataset (10000 samples)...
2025-12-07 23:41:17 - src.data.dataset_loader - INFO - Loading MMLU dataset with 10000 samples...
2025-12-07 23:41:21 - src.data.dataset_loader - INFO - Loaded 10000 MMLU instances
2025-12-07 23:41:21 - src.utils.gpu - INFO - [dataset_loading] Duration: 4622.09ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:21 - src.data.dataset_processor - INFO - Processing qa dataset to 6-option format...
2025-12-07 23:41:22 - src.data.dataset_processor - INFO - Processed 10000 instances for qa
2025-12-07 23:41:22 - src.data.data_splitter - INFO - Splitting qa dataset (calibration: 50%, test: 50%)
2025-12-07 23:41:22 - src.data.data_splitter - INFO - Split complete:
2025-12-07 23:41:22 - src.data.data_splitter - INFO -   Calibration: 4998 instances
2025-12-07 23:41:22 - src.data.data_splitter - INFO -   Test: 5002 instances
2025-12-07 23:41:22 - src.data.data_splitter - WARNING - Calibration size 4998 differs from expected 5000
2025-12-07 23:41:22 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 23:41:22 - src.data.data_splitter - INFO -   Calibration: {'A': 1174, 'B': 1230, 'C': 1242, 'D': 1352}
2025-12-07 23:41:22 - src.data.data_splitter - INFO -   Test: {'A': 1175, 'B': 1231, 'C': 1243, 'D': 1353}
2025-12-07 23:41:22 - src.utils.gpu - INFO - [dataset_processing] Duration: 263.68ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:22 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 23:41:22 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 23:41:22 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 23:41:22 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 23:41:22 - src.prompting.demonstration_manager - INFO - Selecting 5 demonstrations using 'random' strategy
2025-12-07 23:41:22 - src.prompting.demonstration_manager - INFO - Selected and cached 5 demonstrations for qa
2025-12-07 23:41:22 - __main__ - INFO - Loading model: qwen-1.8b (float16)
2025-12-07 23:41:22 - src.models.model_loader - INFO - Loading model: qwen-1.8b_float16 (Qwen/Qwen-1_8B)
2025-12-07 23:41:22 - src.models.model_loader - INFO - Loading tokenizer from Qwen/Qwen-1_8B
2025-12-07 23:41:22 - src.models.model_loader - ERROR - Failed to load tokenizer: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:41:22 - src.utils.gpu - INFO - [model_loading] Duration: 175.40ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:22 - __main__ - ERROR - Failed: qwen-1.8b | qa | float16
2025-12-07 23:41:22 - __main__ - ERROR - Error: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
Traceback (most recent call last):
  File "/root/BLUQ/run_benchmark.py", line 337, in run
    results = self._run_single_configuration(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/run_benchmark.py", line 484, in _run_single_configuration
    model, tokenizer, model_info = model_loader.load_model(load_config)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 215, in load_model
    tokenizer = self._load_tokenizer(config)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 236, in _load_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1138, in from_pretrained
    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 604, in get_class_from_dynamic_module
    final_module = get_cached_module_file(
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 427, in get_cached_module_file
    modules_needed = check_imports(resolved_module_file)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 260, in check_imports
    raise ImportError(
ImportError: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:41:22 - __main__ - INFO - 
================================================================================
2025-12-07 23:41:22 - __main__ - INFO - Run 2/5: qwen-1.8b | rc | float16
2025-12-07 23:41:22 - __main__ - INFO - ================================================================================
2025-12-07 23:41:22 - src.utils.gpu - INFO - [start_qwen-1.8b_rc] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 100.0%
2025-12-07 23:41:22 - __main__ - INFO - Loading rc dataset (10000 samples)...
2025-12-07 23:41:22 - src.data.dataset_loader - INFO - Loading CosmosQA dataset with 10000 samples...
2025-12-07 23:41:22 - src.data.dataset_loader - INFO - CosmosQA loaded successfully with standard method
2025-12-07 23:41:24 - src.data.dataset_loader - INFO - Loaded 10000 CosmosQA instances
2025-12-07 23:41:24 - src.utils.gpu - INFO - [dataset_loading] Duration: 2036.53ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:24 - src.data.dataset_processor - INFO - Processing rc dataset to 6-option format...
2025-12-07 23:41:24 - src.data.dataset_processor - INFO - Processed 10000 instances for rc
2025-12-07 23:41:24 - src.data.data_splitter - INFO - Splitting rc dataset (calibration: 50%, test: 50%)
2025-12-07 23:41:24 - src.data.data_splitter - INFO - Split complete:
2025-12-07 23:41:24 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 23:41:24 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 23:41:24 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 23:41:24 - src.data.data_splitter - INFO -   Calibration: {'A': 1240, 'B': 1245, 'C': 1263, 'D': 1251}
2025-12-07 23:41:24 - src.data.data_splitter - INFO -   Test: {'A': 1241, 'B': 1245, 'C': 1264, 'D': 1251}
2025-12-07 23:41:24 - src.utils.gpu - INFO - [dataset_processing] Duration: 35.26ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:24 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 23:41:24 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 23:41:24 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 23:41:24 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 23:41:24 - src.prompting.demonstration_manager - INFO - Selecting 5 demonstrations using 'random' strategy
2025-12-07 23:41:24 - src.prompting.demonstration_manager - INFO - Selected and cached 5 demonstrations for rc
2025-12-07 23:41:24 - __main__ - INFO - Loading model: qwen-1.8b (float16)
2025-12-07 23:41:24 - src.models.model_loader - INFO - Loading model: qwen-1.8b_float16 (Qwen/Qwen-1_8B)
2025-12-07 23:41:24 - src.models.model_loader - INFO - Loading tokenizer from Qwen/Qwen-1_8B
2025-12-07 23:41:24 - src.models.model_loader - ERROR - Failed to load tokenizer: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:41:24 - src.utils.gpu - INFO - [model_loading] Duration: 93.02ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:24 - __main__ - ERROR - Failed: qwen-1.8b | rc | float16
2025-12-07 23:41:24 - __main__ - ERROR - Error: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
Traceback (most recent call last):
  File "/root/BLUQ/run_benchmark.py", line 337, in run
    results = self._run_single_configuration(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/run_benchmark.py", line 484, in _run_single_configuration
    model, tokenizer, model_info = model_loader.load_model(load_config)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 215, in load_model
    tokenizer = self._load_tokenizer(config)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 236, in _load_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1138, in from_pretrained
    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 604, in get_class_from_dynamic_module
    final_module = get_cached_module_file(
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 427, in get_cached_module_file
    modules_needed = check_imports(resolved_module_file)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 260, in check_imports
    raise ImportError(
ImportError: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:41:24 - __main__ - INFO - 
================================================================================
2025-12-07 23:41:24 - __main__ - INFO - Run 3/5: qwen-1.8b | ci | float16
2025-12-07 23:41:24 - __main__ - INFO - ================================================================================
2025-12-07 23:41:24 - src.utils.gpu - INFO - [start_qwen-1.8b_ci] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 100.0%
2025-12-07 23:41:24 - __main__ - INFO - Loading ci dataset (10000 samples)...
2025-12-07 23:41:24 - src.data.dataset_loader - INFO - Loading HellaSwag dataset with 10000 samples...
2025-12-07 23:41:28 - src.data.dataset_loader - INFO - Loaded 10000 HellaSwag instances
2025-12-07 23:41:28 - src.utils.gpu - INFO - [dataset_loading] Duration: 4199.05ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:28 - src.data.dataset_processor - INFO - Processing ci dataset to 6-option format...
2025-12-07 23:41:28 - src.data.dataset_processor - INFO - Processed 10000 instances for ci
2025-12-07 23:41:28 - src.data.data_splitter - INFO - Splitting ci dataset (calibration: 50%, test: 50%)
2025-12-07 23:41:28 - src.data.data_splitter - INFO - Split complete:
2025-12-07 23:41:28 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 23:41:28 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 23:41:28 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 23:41:28 - src.data.data_splitter - INFO -   Calibration: {'A': 1240, 'B': 1242, 'C': 1256, 'D': 1261}
2025-12-07 23:41:28 - src.data.data_splitter - INFO -   Test: {'A': 1240, 'B': 1242, 'C': 1257, 'D': 1262}
2025-12-07 23:41:28 - src.utils.gpu - INFO - [dataset_processing] Duration: 39.76ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:28 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 23:41:28 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 23:41:28 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 23:41:28 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 23:41:28 - src.prompting.demonstration_manager - INFO - Selecting 5 demonstrations using 'random' strategy
2025-12-07 23:41:28 - src.prompting.demonstration_manager - INFO - Selected and cached 5 demonstrations for ci
2025-12-07 23:41:28 - __main__ - INFO - Loading model: qwen-1.8b (float16)
2025-12-07 23:41:28 - src.models.model_loader - INFO - Loading model: qwen-1.8b_float16 (Qwen/Qwen-1_8B)
2025-12-07 23:41:28 - src.models.model_loader - INFO - Loading tokenizer from Qwen/Qwen-1_8B
2025-12-07 23:41:28 - src.models.model_loader - ERROR - Failed to load tokenizer: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:41:28 - src.utils.gpu - INFO - [model_loading] Duration: 84.78ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:28 - __main__ - ERROR - Failed: qwen-1.8b | ci | float16
2025-12-07 23:41:28 - __main__ - ERROR - Error: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
Traceback (most recent call last):
  File "/root/BLUQ/run_benchmark.py", line 337, in run
    results = self._run_single_configuration(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/run_benchmark.py", line 484, in _run_single_configuration
    model, tokenizer, model_info = model_loader.load_model(load_config)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 215, in load_model
    tokenizer = self._load_tokenizer(config)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 236, in _load_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1138, in from_pretrained
    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 604, in get_class_from_dynamic_module
    final_module = get_cached_module_file(
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 427, in get_cached_module_file
    modules_needed = check_imports(resolved_module_file)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 260, in check_imports
    raise ImportError(
ImportError: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:41:28 - __main__ - INFO - 
================================================================================
2025-12-07 23:41:28 - __main__ - INFO - Run 4/5: qwen-1.8b | drs | float16
2025-12-07 23:41:28 - __main__ - INFO - ================================================================================
2025-12-07 23:41:28 - src.utils.gpu - INFO - [start_qwen-1.8b_drs] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 100.0%
2025-12-07 23:41:28 - __main__ - INFO - Loading drs dataset (10000 samples)...
2025-12-07 23:41:28 - src.data.dataset_loader - INFO - Loading HaluDial dataset with 10000 samples...
2025-12-07 23:41:30 - src.data.dataset_loader - INFO - Loaded 10000 HaluDial instances
2025-12-07 23:41:30 - src.utils.gpu - INFO - [dataset_loading] Duration: 1577.29ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:41:30 - src.data.dataset_processor - INFO - Processing drs dataset to 6-option format...
2025-12-07 23:42:01 - src.data.dataset_processor - INFO - Processed 10000 instances for drs
2025-12-07 23:42:01 - src.data.dataset_processor - INFO - Option expansion statistics for drs:
2025-12-07 23:42:01 - src.data.dataset_processor - INFO -   Instances expanded (2→4 options): 10000
2025-12-07 23:42:01 - src.data.dataset_processor - INFO -   Total options sampled: 20000
2025-12-07 23:42:01 - src.data.dataset_processor - INFO -   Duplicate options avoided: 2
2025-12-07 23:42:01 - src.data.dataset_processor - INFO -   Fallback options used: 0
2025-12-07 23:42:01 - src.data.data_splitter - INFO - Splitting drs dataset (calibration: 50%, test: 50%)
2025-12-07 23:42:01 - src.data.data_splitter - INFO - Split complete:
2025-12-07 23:42:01 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 23:42:01 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 23:42:01 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 23:42:01 - src.data.data_splitter - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
2025-12-07 23:42:01 - src.data.data_splitter - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
2025-12-07 23:42:01 - src.utils.gpu - INFO - [dataset_processing] Duration: 30640.06ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:42:01 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 23:42:01 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 23:42:01 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 23:42:01 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 23:42:01 - src.prompting.demonstration_manager - INFO - Selecting 3 demonstrations using 'random' strategy
2025-12-07 23:42:01 - src.prompting.demonstration_manager - INFO - Selected and cached 3 demonstrations for drs
2025-12-07 23:42:01 - __main__ - INFO - Loading model: qwen-1.8b (float16)
2025-12-07 23:42:01 - src.models.model_loader - INFO - Loading model: qwen-1.8b_float16 (Qwen/Qwen-1_8B)
2025-12-07 23:42:01 - src.models.model_loader - INFO - Loading tokenizer from Qwen/Qwen-1_8B
2025-12-07 23:42:01 - src.models.model_loader - ERROR - Failed to load tokenizer: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:42:01 - src.utils.gpu - INFO - [model_loading] Duration: 78.51ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:42:01 - __main__ - ERROR - Failed: qwen-1.8b | drs | float16
2025-12-07 23:42:01 - __main__ - ERROR - Error: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
Traceback (most recent call last):
  File "/root/BLUQ/run_benchmark.py", line 337, in run
    results = self._run_single_configuration(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/run_benchmark.py", line 484, in _run_single_configuration
    model, tokenizer, model_info = model_loader.load_model(load_config)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 215, in load_model
    tokenizer = self._load_tokenizer(config)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 236, in _load_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1138, in from_pretrained
    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 604, in get_class_from_dynamic_module
    final_module = get_cached_module_file(
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 427, in get_cached_module_file
    modules_needed = check_imports(resolved_module_file)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 260, in check_imports
    raise ImportError(
ImportError: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:42:01 - __main__ - INFO - 
================================================================================
2025-12-07 23:42:01 - __main__ - INFO - Run 5/5: qwen-1.8b | ds | float16
2025-12-07 23:42:01 - __main__ - INFO - ================================================================================
2025-12-07 23:42:01 - src.utils.gpu - INFO - [start_qwen-1.8b_ds] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81155.8MB | Utilization: 100.0%
2025-12-07 23:42:01 - __main__ - INFO - Loading ds dataset (10000 samples)...
2025-12-07 23:42:01 - src.data.dataset_loader - INFO - Loading HaluSum dataset with 10000 samples...
2025-12-07 23:42:01 - src.data.dataset_loader - INFO - Loaded 10000 HaluSum instances
2025-12-07 23:42:01 - src.utils.gpu - INFO - [dataset_loading] Duration: 740.38ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:42:01 - src.data.dataset_processor - INFO - Processing ds dataset to 6-option format...
2025-12-07 23:42:33 - src.data.dataset_processor - INFO - Processed 10000 instances for ds
2025-12-07 23:42:33 - src.data.dataset_processor - INFO - Option expansion statistics for ds:
2025-12-07 23:42:33 - src.data.dataset_processor - INFO -   Instances expanded (2→4 options): 10000
2025-12-07 23:42:33 - src.data.dataset_processor - INFO -   Total options sampled: 20000
2025-12-07 23:42:33 - src.data.dataset_processor - INFO -   Duplicate options avoided: 0
2025-12-07 23:42:33 - src.data.dataset_processor - INFO -   Fallback options used: 0
2025-12-07 23:42:33 - src.data.data_splitter - INFO - Splitting ds dataset (calibration: 50%, test: 50%)
2025-12-07 23:42:33 - src.data.data_splitter - INFO - Split complete:
2025-12-07 23:42:33 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 23:42:33 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 23:42:33 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 23:42:33 - src.data.data_splitter - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
2025-12-07 23:42:33 - src.data.data_splitter - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
2025-12-07 23:42:33 - src.utils.gpu - INFO - [dataset_processing] Duration: 31838.40ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:42:33 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 23:42:33 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 23:42:33 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 23:42:33 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 23:42:33 - src.prompting.demonstration_manager - INFO - Selecting 1 demonstrations using 'random' strategy
2025-12-07 23:42:33 - src.prompting.demonstration_manager - INFO - Selected and cached 1 demonstrations for ds
2025-12-07 23:42:33 - __main__ - INFO - Loading model: qwen-1.8b (float16)
2025-12-07 23:42:33 - src.models.model_loader - INFO - Loading model: qwen-1.8b_float16 (Qwen/Qwen-1_8B)
2025-12-07 23:42:33 - src.models.model_loader - INFO - Loading tokenizer from Qwen/Qwen-1_8B
2025-12-07 23:42:33 - src.models.model_loader - ERROR - Failed to load tokenizer: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:42:33 - src.utils.gpu - INFO - [model_loading] Duration: 91.19ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 23:42:33 - __main__ - ERROR - Failed: qwen-1.8b | ds | float16
2025-12-07 23:42:33 - __main__ - ERROR - Error: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
Traceback (most recent call last):
  File "/root/BLUQ/run_benchmark.py", line 337, in run
    results = self._run_single_configuration(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/run_benchmark.py", line 484, in _run_single_configuration
    model, tokenizer, model_info = model_loader.load_model(load_config)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 215, in load_model
    tokenizer = self._load_tokenizer(config)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/src/models/model_loader.py", line 236, in _load_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 1138, in from_pretrained
    tokenizer_class = get_class_from_dynamic_module(class_ref, pretrained_model_name_or_path, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 604, in get_class_from_dynamic_module
    final_module = get_cached_module_file(
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 427, in get_cached_module_file
    modules_needed = check_imports(resolved_module_file)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/BLUQ/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py", line 260, in check_imports
    raise ImportError(
ImportError: This modeling file requires the following packages that were not found in your environment: tiktoken. Run `pip install tiktoken`
2025-12-07 23:42:34 - src.visualization.result_visualizer - INFO - Generating all visualizations...
2025-12-07 23:42:34 - src.visualization.result_visualizer - WARNING - No data available for heatmap
2025-12-07 23:42:34 - src.visualization.result_visualizer - WARNING - No data available for heatmap
2025-12-07 23:42:34 - src.visualization.result_visualizer - WARNING - No data available for heatmap
2025-12-07 23:42:35 - src.visualization.result_visualizer - INFO - Saved dashboard to outputs/results/figures/dashboard.png
2025-12-07 23:42:35 - src.visualization.result_visualizer - WARNING - No data available for bar chart
2025-12-07 23:42:35 - src.visualization.result_visualizer - WARNING - No data available for bar chart
2025-12-07 23:42:35 - src.visualization.result_visualizer - WARNING - No data available for radar chart
2025-12-07 23:42:35 - src.visualization.result_visualizer - WARNING - No data available for uncertainty analysis
2025-12-07 23:42:35 - src.visualization.result_visualizer - INFO - All visualizations saved to outputs/results/figures
2025-12-07 23:42:35 - __main__ - INFO - Visualizations saved to: outputs/results/figures
2025-12-07 23:42:35 - src.utils.gpu - INFO - Stopped GPU monitoring. Collected 41 snapshots.
2025-12-07 23:42:35 - src.utils.gpu - INFO - Saved GPU profiling report to outputs/results/gpu_profile_20251207_234111.json
2025-12-07 23:42:35 - __main__ - INFO - GPU profiling report saved to: outputs/results/gpu_profile_20251207_234111.json
2025-12-07 23:42:35 - __main__ - INFO - 
================================================================================
2025-12-07 23:42:35 - __main__ - INFO - BENCHMARK COMPLETE
2025-12-07 23:42:35 - __main__ - INFO - ================================================================================
2025-12-07 23:42:35 - __main__ - INFO - Total time: 1.35 minutes
2025-12-07 23:42:35 - __main__ - INFO - Results saved to: outputs/results
2025-12-07 23:42:35 - __main__ - INFO - Benchmark completed successfully
2025-12-07 23:42:35 - __main__ - INFO - Total runs: 0
2025-12-07 23:42:35 - __main__ - INFO - Overall accuracy: nan%
2025-12-07 23:42:35 - __main__ - INFO - Overall coverage: nan%
2025-12-07 23:42:35 - __main__ - INFO - Log file saved to: outputs/results/logs/benchmark_20251207_234111.log
