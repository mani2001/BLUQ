2025-12-07 17:26:57 - __main__ - INFO - Starting benchmark run
2025-12-07 17:26:57 - __main__ - INFO - Log file: outputs/results/logs/benchmark_20251207_172657.log
2025-12-07 17:26:57 - __main__ - INFO - Mode: long, Samples: 10000
2025-12-07 17:26:57 - __main__ - INFO - Models: ['tinyllama-1.1b']
2025-12-07 17:26:57 - __main__ - INFO - Tasks: ['qa', 'rc', 'ci', 'drs', 'ds']
2025-12-07 17:26:57 - __main__ - INFO - Dtypes: ['float32']
2025-12-07 17:27:17 - __main__ - INFO - Running on: Device: NVIDIA A100 80GB PCIe (cuda)
  Total Memory: 79.25 GB
  Available Memory: 79.25 GB
2025-12-07 17:27:17 - src.utils.gpu - INFO - Detected A100 GPU: NVIDIA A100 80GB PCIe - using optimized A100 settings
2025-12-07 17:27:17 - __main__ - INFO - GPU Tier: a100 | Auto max_batch_size: 192 | Safety margin: 0.93
2025-12-07 17:27:17 - __main__ - INFO - Auto-detected max_batch_size: 192
2025-12-07 17:27:17 - src.utils.gpu - INFO - Detected A100 GPU: NVIDIA A100 80GB PCIe - using optimized A100 settings
2025-12-07 17:27:17 - src.utils.gpu - INFO - Initialized GPUMemoryManager:
Device: NVIDIA A100 80GB PCIe (cuda)
  Total Memory: 79.25 GB
  Available Memory: 79.25 GB
  GPU Tier: a100
  Safety Margin: 0.93
  Activation Multiplier: 0.4
  Max Batch Size: 192
2025-12-07 17:27:17 - src.utils.gpu - INFO - NVML initialized for GPU utilization monitoring
2025-12-07 17:27:17 - src.utils.gpu - INFO - GPUProfiler initialized (CUDA: True, NVML: True)
2025-12-07 17:27:17 - src.utils.gpu - INFO - Started GPU monitoring
2025-12-07 17:27:17 - __main__ - INFO - GPU profiling enabled
2025-12-07 17:27:17 - __main__ - INFO - 
================================================================================
2025-12-07 17:27:17 - __main__ - INFO - FULL BENCHMARK CONFIGURATION
2025-12-07 17:27:17 - __main__ - INFO - ================================================================================
2025-12-07 17:27:17 - __main__ - INFO - Models (1): ['tinyllama-1.1b']
2025-12-07 17:27:17 - __main__ - INFO - Tasks (5): ['qa', 'rc', 'ci', 'drs', 'ds']
2025-12-07 17:27:17 - __main__ - INFO - Data types: ['float32']
2025-12-07 17:27:17 - __main__ - INFO - Samples per task: 10000
2025-12-07 17:27:17 - __main__ - INFO - Alpha (error rate): 0.1
2025-12-07 17:27:17 - __main__ - INFO - Strategies: ['base']
2025-12-07 17:27:17 - __main__ - INFO - Conformal methods: ['lac', 'aps']
2025-12-07 17:27:17 - __main__ - INFO - Dynamic batch sizing: True
2025-12-07 17:27:17 - __main__ - INFO - Max batch size: 192 (GPU tier: a100)
2025-12-07 17:27:17 - __main__ - INFO - Output directory: outputs/results
2025-12-07 17:27:17 - __main__ - INFO - 
================================================================================
2025-12-07 17:27:17 - __main__ - INFO - Run 1/5: tinyllama-1.1b | qa | float32
2025-12-07 17:27:17 - __main__ - INFO - ================================================================================
2025-12-07 17:27:28 - src.utils.gpu - INFO - [start_tinyllama-1.1b_qa] GPU State: Allocated: 0.0MB | Reserved: 0.0MB | Free: 81152.8MB | Utilization: 0.0%
2025-12-07 17:27:28 - __main__ - INFO - Loading qa dataset (10000 samples)...
2025-12-07 17:27:28 - src.data.dataset_loader - INFO - Loading MMLU dataset with 10000 samples...
2025-12-07 17:29:19 - src.data.dataset_loader - INFO - Loaded 10000 MMLU instances
2025-12-07 17:29:19 - src.utils.gpu - INFO - [dataset_loading] Duration: 110791.28ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 17:29:19 - src.data.dataset_processor - INFO - Processing qa dataset to 6-option format...
2025-12-07 17:29:19 - src.data.dataset_processor - INFO - Processed 10000 instances for qa
2025-12-07 17:29:19 - src.data.data_splitter - INFO - Splitting qa dataset (calibration: 50%, test: 50%)
2025-12-07 17:29:19 - src.data.data_splitter - INFO - Split complete:
2025-12-07 17:29:19 - src.data.data_splitter - INFO -   Calibration: 4998 instances
2025-12-07 17:29:19 - src.data.data_splitter - INFO -   Test: 5002 instances
2025-12-07 17:29:19 - src.data.data_splitter - WARNING - Calibration size 4998 differs from expected 5000
2025-12-07 17:29:19 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 17:29:19 - src.data.data_splitter - INFO -   Calibration: {'A': 1174, 'B': 1230, 'C': 1242, 'D': 1352}
2025-12-07 17:29:19 - src.data.data_splitter - INFO -   Test: {'A': 1175, 'B': 1231, 'C': 1243, 'D': 1353}
2025-12-07 17:29:19 - src.utils.gpu - INFO - [dataset_processing] Duration: 48.75ms | GPU Memory: 0.0MB -> 0.0MB (delta +0.0MB)
2025-12-07 17:29:19 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 17:29:19 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 17:29:19 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 17:29:19 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 17:29:19 - src.prompting.demonstration_manager - INFO - Selecting 5 demonstrations using 'random' strategy
2025-12-07 17:29:19 - src.prompting.demonstration_manager - INFO - Selected and cached 5 demonstrations for qa
2025-12-07 17:29:19 - __main__ - INFO - Loading model: tinyllama-1.1b (float32)
2025-12-07 17:29:19 - src.models.model_loader - INFO - Loading model: tinyllama-1.1b_float32 (TinyLlama/TinyLlama-1.1B-Chat-v1.0)
2025-12-07 17:29:19 - src.models.model_loader - INFO - Loading tokenizer from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 17:29:20 - src.models.model_loader - INFO - Tokenizer loaded successfully
2025-12-07 17:29:20 - src.models.model_loader - INFO -   Vocab size: 32000
2025-12-07 17:29:20 - src.models.model_loader - INFO -   Padding side: left
2025-12-07 17:29:20 - src.models.model_loader - INFO -   PAD token: </s> (ID: 2)
2025-12-07 17:29:20 - src.models.model_loader - INFO - Loading model from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 17:31:03 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-07 17:31:06 - src.models.model_loader - INFO - Model loaded successfully
2025-12-07 17:31:06 - src.models.model_loader - INFO -   GPU Memory: 4.10GB allocated, 4.17GB reserved
2025-12-07 17:31:06 - src.utils.gpu - INFO - [model_loading] Duration: 107084.58ms | GPU Memory: 0.0MB -> 4196.4MB (delta +4196.4MB)
2025-12-07 17:31:06 - src.utils.gpu - INFO - [after_model_load_tinyllama-1.1b] GPU State: Allocated: 4196.4MB | Reserved: 4266.0MB | Free: 76956.4MB | Utilization: 1.0%
2025-12-07 17:31:06 - src.utils.gpu - INFO - Optimal batch size for 1.1B model (float32): 39
  Available memory: 73.70GB
  Model memory: 4.40GB
  Memory per batch item: 1.760GB
2025-12-07 17:31:06 - __main__ - INFO - Using batch size: 39
2025-12-07 17:31:06 - __main__ - INFO -   Strategy: base
2025-12-07 17:31:06 - src.prompting.prompt_builder - INFO - Initialized PromptBuilder for task: qa
2025-12-07 17:31:06 - src.prompting.prompt_builder - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
2025-12-07 17:31:06 - src.prompting.prompt_builder - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
2025-12-07 17:31:06 - src.models.inference_engine - INFO - Initialized InferenceEngine for tinyllama-1.1b_float32
2025-12-07 17:31:06 - src.models.inference_engine - INFO -   Device: cuda:0
2025-12-07 17:31:06 - src.models.inference_engine - INFO -   Batch size: 39
2025-12-07 17:31:06 - src.models.inference_engine - INFO -   Option tokens: {'A': 319, 'B': 350, 'C': 315, 'D': 360, 'E': 382, 'F': 383}
2025-12-07 17:36:11 - src.utils.gpu - INFO - [inference_calibration] Duration: 304584.03ms | GPU Memory: 4196.4MB -> 4204.5MB (delta +8.1MB)
2025-12-07 17:42:15 - src.utils.gpu - INFO - [inference_test] Duration: 364162.44ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 17:42:15 - __main__ - INFO -     Inference: 668.75s for 10000 samples (14.95 samples/sec)
2025-12-07 17:42:15 - src.models.probability_extractor - INFO - Initialized ProbabilityExtractor
2025-12-07 17:42:15 - src.models.probability_extractor - INFO -   Temperature: 1.0
2025-12-07 17:42:15 - src.models.probability_extractor - INFO -   Calibration method: None
2025-12-07 17:42:15 - src.utils.gpu - INFO - [probability_extraction] Duration: 198.95ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Initialized LACScorer
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 17:42:15 - src.conformal.scorers - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Methods: ['lac']
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Calibrating LAC...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Calibrating with 4998 samples...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Threshold: 0.9721
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Score range: [0.0001, 1.0000]
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using LAC...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Generating prediction sets for 5002 test instances...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Average set size: 5.14
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Coverage rate: 89.40%
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: False
2025-12-07 17:42:15 - src.conformal.conformal_base - WARNING - ✗ Coverage guarantee NOT met: 89.40% < 90.00%
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - WARNING - LAC does not meet coverage guarantee: 89.40% < 90.00%
2025-12-07 17:42:15 - __main__ - INFO -     LAC: Acc=22.13%, CR=89.40%, SS=5.14
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Initialized APSScorer
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 17:42:15 - src.conformal.scorers - INFO - Initialized APS (Adaptive Prediction Sets) scorer
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Methods: ['aps']
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO -   Calibrating APS...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Calibrating with 4998 samples...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Threshold: 1.0000
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Score range: [0.2016, 1.0000]
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 17:42:15 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using APS...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Generating prediction sets for 5002 test instances...
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Average set size: 5.96
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Coverage rate: 99.66%
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: True
2025-12-07 17:42:15 - src.conformal.conformal_base - INFO - [PASS] Coverage guarantee met: 99.66% >= 90.00%
2025-12-07 17:42:15 - __main__ - INFO -     APS: Acc=22.13%, CR=99.66%, SS=5.96
2025-12-07 17:42:25 - src.models.model_loader - INFO - Unloaded model: tinyllama-1.1b_float32
2025-12-07 17:42:25 - __main__ - INFO - Checkpoint saved after completing: tinyllama-1.1b | qa | float32
2025-12-07 17:42:25 - __main__ - INFO - 
================================================================================
2025-12-07 17:42:25 - __main__ - INFO - Run 2/5: tinyllama-1.1b | rc | float32
2025-12-07 17:42:25 - __main__ - INFO - ================================================================================
2025-12-07 17:42:25 - src.utils.gpu - INFO - [start_tinyllama-1.1b_rc] GPU State: Allocated: 8.1MB | Reserved: 3946.0MB | Free: 81144.6MB | Utilization: 100.0%
2025-12-07 17:42:25 - __main__ - INFO - Loading rc dataset (10000 samples)...
2025-12-07 17:42:25 - src.data.dataset_loader - INFO - Loading CosmosQA dataset with 10000 samples...
2025-12-07 17:49:26 - src.data.dataset_loader - ERROR - Failed to load CosmosQA dataset: Couldn't reach https://github.com/wilburOne/cosmosqa/raw/master/data/test.jsonl (ConnectTimeout(MaxRetryError("HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /wilburOne/cosmosqa/raw/master/data/test.jsonl (Caused by ConnectTimeoutError(<HTTPSConnection(host='github.com', port=443) at 0x7f49e35a5b40>, 'Connection to github.com timed out. (connect timeout=100)'))")))
2025-12-07 17:49:26 - src.utils.gpu - INFO - [dataset_loading] Duration: 420287.01ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 17:49:26 - __main__ - ERROR - Failed: tinyllama-1.1b | rc | float32
2025-12-07 17:49:26 - __main__ - ERROR - Error: Failed to load CosmosQA dataset: Couldn't reach https://github.com/wilburOne/cosmosqa/raw/master/data/test.jsonl (ConnectTimeout(MaxRetryError("HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /wilburOne/cosmosqa/raw/master/data/test.jsonl (Caused by ConnectTimeoutError(<HTTPSConnection(host='github.com', port=443) at 0x7f49e35a5b40>, 'Connection to github.com timed out. (connect timeout=100)'))")))
If you see 'Dataset scripts are no longer supported', try: pip install 'datasets>=2.10.0,<2.15.0'
Traceback (most recent call last):
  File "/home/ubuntu/BLUQ/src/data/dataset_loader.py", line 325, in load
    dataset = load_dataset("cosmos_qa", cache_dir=self.cache_dir)
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/load.py", line 2153, in load_dataset
    builder_instance.download_and_prepare(
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/builder.py", line 954, in download_and_prepare
    self._download_and_prepare(
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/builder.py", line 1717, in _download_and_prepare
    super()._download_and_prepare(
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/builder.py", line 1027, in _download_and_prepare
    split_generators = self._split_generators(dl_manager, **split_generators_kwargs)
  File "/home/ubuntu/.cache/huggingface/modules/datasets_modules/datasets/cosmos_qa/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157/cosmos_qa.py", line 72, in _split_generators
    dl_dir = dl_manager.download_and_extract(urls_to_download)
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py", line 565, in download_and_extract
    return self.extract(self.download(url_or_urls))
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py", line 428, in download
    downloaded_path_or_paths = map_nested(
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 464, in map_nested
    mapped = [
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 465, in <listcomp>
    _single_map_nested((function, obj, types, None, True, None))
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 367, in _single_map_nested
    return function(data_struct)
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/download/download_manager.py", line 454, in _download
    return cached_path(url_or_filename, download_config=download_config)
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py", line 182, in cached_path
    output_path = get_from_cache(
  File "/home/ubuntu/BLUQ/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py", line 599, in get_from_cache
    raise ConnectionError(f"Couldn't reach {url} ({repr(head_error)})")
ConnectionError: Couldn't reach https://github.com/wilburOne/cosmosqa/raw/master/data/test.jsonl (ConnectTimeout(MaxRetryError("HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /wilburOne/cosmosqa/raw/master/data/test.jsonl (Caused by ConnectTimeoutError(<HTTPSConnection(host='github.com', port=443) at 0x7f49e35a5b40>, 'Connection to github.com timed out. (connect timeout=100)'))")))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/BLUQ/run_benchmark.py", line 319, in run
    results = self._run_single_configuration(
  File "/home/ubuntu/BLUQ/run_benchmark.py", line 417, in _run_single_configuration
    dataset = loader.load(num_samples=self.config.num_samples)
  File "/home/ubuntu/BLUQ/src/data/dataset_loader.py", line 364, in load
    raise RuntimeError(
RuntimeError: Failed to load CosmosQA dataset: Couldn't reach https://github.com/wilburOne/cosmosqa/raw/master/data/test.jsonl (ConnectTimeout(MaxRetryError("HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /wilburOne/cosmosqa/raw/master/data/test.jsonl (Caused by ConnectTimeoutError(<HTTPSConnection(host='github.com', port=443) at 0x7f49e35a5b40>, 'Connection to github.com timed out. (connect timeout=100)'))")))
If you see 'Dataset scripts are no longer supported', try: pip install 'datasets>=2.10.0,<2.15.0'
2025-12-07 17:49:26 - __main__ - INFO - 
================================================================================
2025-12-07 17:49:26 - __main__ - INFO - Run 3/5: tinyllama-1.1b | ci | float32
2025-12-07 17:49:26 - __main__ - INFO - ================================================================================
2025-12-07 17:49:26 - src.utils.gpu - INFO - [start_tinyllama-1.1b_ci] GPU State: Allocated: 8.1MB | Reserved: 3946.0MB | Free: 81144.6MB | Utilization: 48.0%
2025-12-07 17:49:26 - __main__ - INFO - Loading ci dataset (10000 samples)...
2025-12-07 17:49:26 - src.data.dataset_loader - INFO - Loading HellaSwag dataset with 10000 samples...
2025-12-07 17:49:30 - src.data.dataset_loader - INFO - Loaded 10000 HellaSwag instances
2025-12-07 17:49:30 - src.utils.gpu - INFO - [dataset_loading] Duration: 4610.49ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 17:49:30 - src.data.dataset_processor - INFO - Processing ci dataset to 6-option format...
2025-12-07 17:49:30 - src.data.dataset_processor - INFO - Processed 10000 instances for ci
2025-12-07 17:49:30 - src.data.data_splitter - INFO - Splitting ci dataset (calibration: 50%, test: 50%)
2025-12-07 17:49:30 - src.data.data_splitter - INFO - Split complete:
2025-12-07 17:49:30 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 17:49:30 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 17:49:30 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 17:49:30 - src.data.data_splitter - INFO -   Calibration: {'A': 1240, 'B': 1242, 'C': 1256, 'D': 1261}
2025-12-07 17:49:30 - src.data.data_splitter - INFO -   Test: {'A': 1240, 'B': 1242, 'C': 1257, 'D': 1262}
2025-12-07 17:49:30 - src.utils.gpu - INFO - [dataset_processing] Duration: 265.20ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 17:49:30 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 17:49:30 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 17:49:30 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 17:49:30 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 17:49:30 - src.prompting.demonstration_manager - INFO - Selecting 5 demonstrations using 'random' strategy
2025-12-07 17:49:30 - src.prompting.demonstration_manager - INFO - Selected and cached 5 demonstrations for ci
2025-12-07 17:49:30 - __main__ - INFO - Loading model: tinyllama-1.1b (float32)
2025-12-07 17:49:30 - src.models.model_loader - INFO - Loading model: tinyllama-1.1b_float32 (TinyLlama/TinyLlama-1.1B-Chat-v1.0)
2025-12-07 17:49:30 - src.models.model_loader - INFO - Loading tokenizer from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 17:49:31 - src.models.model_loader - INFO - Tokenizer loaded successfully
2025-12-07 17:49:31 - src.models.model_loader - INFO -   Vocab size: 32000
2025-12-07 17:49:31 - src.models.model_loader - INFO -   Padding side: left
2025-12-07 17:49:31 - src.models.model_loader - INFO -   PAD token: </s> (ID: 2)
2025-12-07 17:49:31 - src.models.model_loader - INFO - Loading model from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 17:49:31 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-07 17:49:34 - src.models.model_loader - INFO - Model loaded successfully
2025-12-07 17:49:34 - src.models.model_loader - INFO -   GPU Memory: 4.11GB allocated, 4.17GB reserved
2025-12-07 17:49:34 - src.utils.gpu - INFO - [model_loading] Duration: 3325.22ms | GPU Memory: 8.1MB -> 4204.5MB (delta +4196.4MB)
2025-12-07 17:49:34 - src.utils.gpu - INFO - [after_model_load_tinyllama-1.1b] GPU State: Allocated: 4204.5MB | Reserved: 4266.0MB | Free: 76948.3MB | Utilization: 100.0%
2025-12-07 17:49:34 - src.utils.gpu - INFO - Optimal batch size for 1.1B model (float32): 39
  Available memory: 73.70GB
  Model memory: 4.40GB
  Memory per batch item: 1.760GB
2025-12-07 17:49:34 - __main__ - INFO - Using batch size: 39
2025-12-07 17:49:34 - __main__ - INFO -   Strategy: base
2025-12-07 17:49:34 - src.prompting.prompt_builder - INFO - Initialized PromptBuilder for task: ci
2025-12-07 17:49:34 - src.prompting.prompt_builder - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
2025-12-07 17:49:34 - src.prompting.prompt_builder - INFO - Building 10000 prompts using 'base' strategy with 5 demonstrations
2025-12-07 17:49:34 - src.models.inference_engine - INFO - Initialized InferenceEngine for tinyllama-1.1b_float32
2025-12-07 17:49:34 - src.models.inference_engine - INFO -   Device: cuda:0
2025-12-07 17:49:34 - src.models.inference_engine - INFO -   Batch size: 39
2025-12-07 17:49:34 - src.models.inference_engine - INFO -   Option tokens: {'A': 319, 'B': 350, 'C': 315, 'D': 360, 'E': 382, 'F': 383}
2025-12-07 17:52:06 - src.utils.gpu - INFO - [inference_calibration] Duration: 152389.11ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 17:56:38 - src.utils.gpu - INFO - [inference_test] Duration: 271841.76ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 17:56:38 - __main__ - INFO -     Inference: 424.23s for 10000 samples (23.57 samples/sec)
2025-12-07 17:56:38 - src.models.probability_extractor - INFO - Initialized ProbabilityExtractor
2025-12-07 17:56:38 - src.models.probability_extractor - INFO -   Temperature: 1.0
2025-12-07 17:56:38 - src.models.probability_extractor - INFO -   Calibration method: None
2025-12-07 17:56:38 - src.utils.gpu - INFO - [probability_extraction] Duration: 311.92ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Initialized LACScorer
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 17:56:39 - src.conformal.scorers - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Methods: ['lac']
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Calibrating LAC...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Calibrating with 4999 samples...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Threshold: 0.9762
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Score range: [0.0004, 1.0000]
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using LAC...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Generating prediction sets for 5001 test instances...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Average set size: 5.22
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Coverage rate: 90.20%
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: True
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - [PASS] Coverage guarantee met: 90.20% >= 90.00%
2025-12-07 17:56:39 - __main__ - INFO -     LAC: Acc=20.60%, CR=90.20%, SS=5.22
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Initialized APSScorer
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 17:56:39 - src.conformal.scorers - INFO - Initialized APS (Adaptive Prediction Sets) scorer
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Methods: ['aps']
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO -   Calibrating APS...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Calibrating with 4999 samples...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Threshold: 1.0000
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Score range: [0.1997, 1.0000]
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 17:56:39 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using APS...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Generating prediction sets for 5001 test instances...
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Average set size: 6.00
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Coverage rate: 100.00%
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: True
2025-12-07 17:56:39 - src.conformal.conformal_base - INFO - [PASS] Coverage guarantee met: 100.00% >= 90.00%
2025-12-07 17:56:39 - __main__ - INFO -     APS: Acc=20.60%, CR=100.00%, SS=6.00
2025-12-07 17:56:48 - src.models.model_loader - INFO - Unloaded model: tinyllama-1.1b_float32
2025-12-07 17:56:48 - __main__ - INFO - Checkpoint saved after completing: tinyllama-1.1b | ci | float32
2025-12-07 17:56:48 - __main__ - INFO - 
================================================================================
2025-12-07 17:56:48 - __main__ - INFO - Run 4/5: tinyllama-1.1b | drs | float32
2025-12-07 17:56:48 - __main__ - INFO - ================================================================================
2025-12-07 17:56:48 - src.utils.gpu - INFO - [start_tinyllama-1.1b_drs] GPU State: Allocated: 8.1MB | Reserved: 3946.0MB | Free: 81144.6MB | Utilization: 100.0%
2025-12-07 17:56:48 - __main__ - INFO - Loading drs dataset (10000 samples)...
2025-12-07 17:56:48 - src.data.dataset_loader - INFO - Loading HaluDial dataset with 10000 samples...
2025-12-07 17:57:05 - src.data.dataset_loader - INFO - Loaded 10000 HaluDial instances
2025-12-07 17:57:05 - src.utils.gpu - INFO - [dataset_loading] Duration: 16726.98ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 17:57:05 - src.data.dataset_processor - INFO - Processing drs dataset to 6-option format...
2025-12-07 17:57:40 - src.data.dataset_processor - INFO - Processed 10000 instances for drs
2025-12-07 17:57:40 - src.data.dataset_processor - INFO - Option expansion statistics for drs:
2025-12-07 17:57:40 - src.data.dataset_processor - INFO -   Instances expanded (2→4 options): 10000
2025-12-07 17:57:40 - src.data.dataset_processor - INFO -   Total options sampled: 20000
2025-12-07 17:57:40 - src.data.dataset_processor - INFO -   Duplicate options avoided: 2
2025-12-07 17:57:40 - src.data.dataset_processor - INFO -   Fallback options used: 0
2025-12-07 17:57:40 - src.data.data_splitter - INFO - Splitting drs dataset (calibration: 50%, test: 50%)
2025-12-07 17:57:40 - src.data.data_splitter - INFO - Split complete:
2025-12-07 17:57:40 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 17:57:40 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 17:57:40 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 17:57:40 - src.data.data_splitter - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
2025-12-07 17:57:40 - src.data.data_splitter - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
2025-12-07 17:57:40 - src.utils.gpu - INFO - [dataset_processing] Duration: 35345.24ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 17:57:40 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 17:57:40 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 17:57:40 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 17:57:40 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 17:57:40 - src.prompting.demonstration_manager - INFO - Selecting 3 demonstrations using 'random' strategy
2025-12-07 17:57:40 - src.prompting.demonstration_manager - INFO - Selected and cached 3 demonstrations for drs
2025-12-07 17:57:40 - __main__ - INFO - Loading model: tinyllama-1.1b (float32)
2025-12-07 17:57:40 - src.models.model_loader - INFO - Loading model: tinyllama-1.1b_float32 (TinyLlama/TinyLlama-1.1B-Chat-v1.0)
2025-12-07 17:57:40 - src.models.model_loader - INFO - Loading tokenizer from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 17:57:40 - src.models.model_loader - INFO - Tokenizer loaded successfully
2025-12-07 17:57:40 - src.models.model_loader - INFO -   Vocab size: 32000
2025-12-07 17:57:40 - src.models.model_loader - INFO -   Padding side: left
2025-12-07 17:57:40 - src.models.model_loader - INFO -   PAD token: </s> (ID: 2)
2025-12-07 17:57:40 - src.models.model_loader - INFO - Loading model from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 17:57:40 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-07 17:57:43 - src.models.model_loader - INFO - Model loaded successfully
2025-12-07 17:57:43 - src.models.model_loader - INFO -   GPU Memory: 4.11GB allocated, 4.17GB reserved
2025-12-07 17:57:43 - src.utils.gpu - INFO - [model_loading] Duration: 3282.32ms | GPU Memory: 8.1MB -> 4204.5MB (delta +4196.4MB)
2025-12-07 17:57:43 - src.utils.gpu - INFO - [after_model_load_tinyllama-1.1b] GPU State: Allocated: 4204.5MB | Reserved: 4266.0MB | Free: 76948.3MB | Utilization: 100.0%
2025-12-07 17:57:43 - src.utils.gpu - INFO - Optimal batch size for 1.1B model (float32): 39
  Available memory: 73.70GB
  Model memory: 4.40GB
  Memory per batch item: 1.760GB
2025-12-07 17:57:43 - __main__ - INFO - Using batch size: 39
2025-12-07 17:57:43 - __main__ - INFO -   Strategy: base
2025-12-07 17:57:43 - src.prompting.prompt_builder - INFO - Initialized PromptBuilder for task: drs
2025-12-07 17:57:43 - src.prompting.prompt_builder - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
2025-12-07 17:57:43 - src.prompting.prompt_builder - INFO - Building 10000 prompts using 'base' strategy with 3 demonstrations
2025-12-07 17:57:43 - src.models.inference_engine - INFO - Initialized InferenceEngine for tinyllama-1.1b_float32
2025-12-07 17:57:43 - src.models.inference_engine - INFO -   Device: cuda:0
2025-12-07 17:57:43 - src.models.inference_engine - INFO -   Batch size: 39
2025-12-07 17:57:43 - src.models.inference_engine - INFO -   Option tokens: {'A': 319, 'B': 350, 'C': 315, 'D': 360, 'E': 382, 'F': 383}
2025-12-07 18:00:51 - src.utils.gpu - INFO - [inference_calibration] Duration: 187671.88ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 18:04:02 - src.utils.gpu - INFO - [inference_test] Duration: 191230.40ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 18:04:02 - __main__ - INFO -     Inference: 378.90s for 10000 samples (26.39 samples/sec)
2025-12-07 18:04:02 - src.models.probability_extractor - INFO - Initialized ProbabilityExtractor
2025-12-07 18:04:02 - src.models.probability_extractor - INFO -   Temperature: 1.0
2025-12-07 18:04:02 - src.models.probability_extractor - INFO -   Calibration method: None
2025-12-07 18:04:02 - src.utils.gpu - INFO - [probability_extraction] Duration: 290.04ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 18:04:02 - src.conformal.conformal_base - INFO - Initialized LACScorer
2025-12-07 18:04:02 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 18:04:02 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 18:04:03 - src.conformal.scorers - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Methods: ['lac']
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Calibrating LAC...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Calibrating with 4999 samples...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Threshold: 0.9800
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Score range: [0.0000, 1.0000]
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using LAC...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Generating prediction sets for 5001 test instances...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Average set size: 5.19
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Coverage rate: 89.68%
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: False
2025-12-07 18:04:03 - src.conformal.conformal_base - WARNING - ✗ Coverage guarantee NOT met: 89.68% < 90.00%
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - WARNING - LAC does not meet coverage guarantee: 89.68% < 90.00%
2025-12-07 18:04:03 - __main__ - INFO -     LAC: Acc=21.44%, CR=89.68%, SS=5.19
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Initialized APSScorer
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 18:04:03 - src.conformal.scorers - INFO - Initialized APS (Adaptive Prediction Sets) scorer
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Methods: ['aps']
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO -   Calibrating APS...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Calibrating with 4999 samples...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Threshold: 1.0000
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Score range: [0.2082, 1.0000]
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 18:04:03 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using APS...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Generating prediction sets for 5001 test instances...
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Average set size: 5.90
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Coverage rate: 98.48%
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: True
2025-12-07 18:04:03 - src.conformal.conformal_base - INFO - [PASS] Coverage guarantee met: 98.48% >= 90.00%
2025-12-07 18:04:03 - __main__ - INFO -     APS: Acc=21.44%, CR=98.48%, SS=5.90
2025-12-07 18:04:12 - src.models.model_loader - INFO - Unloaded model: tinyllama-1.1b_float32
2025-12-07 18:04:12 - __main__ - INFO - Checkpoint saved after completing: tinyllama-1.1b | drs | float32
2025-12-07 18:04:12 - __main__ - INFO - 
================================================================================
2025-12-07 18:04:12 - __main__ - INFO - Run 5/5: tinyllama-1.1b | ds | float32
2025-12-07 18:04:12 - __main__ - INFO - ================================================================================
2025-12-07 18:04:12 - src.utils.gpu - INFO - [start_tinyllama-1.1b_ds] GPU State: Allocated: 8.1MB | Reserved: 3946.0MB | Free: 81144.6MB | Utilization: 100.0%
2025-12-07 18:04:12 - __main__ - INFO - Loading ds dataset (10000 samples)...
2025-12-07 18:04:12 - src.data.dataset_loader - INFO - Loading HaluSum dataset with 10000 samples...
2025-12-07 18:04:14 - src.data.dataset_loader - INFO - Loaded 10000 HaluSum instances
2025-12-07 18:04:14 - src.utils.gpu - INFO - [dataset_loading] Duration: 1517.12ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 18:04:14 - src.data.dataset_processor - INFO - Processing ds dataset to 6-option format...
2025-12-07 18:04:53 - src.data.dataset_processor - INFO - Processed 10000 instances for ds
2025-12-07 18:04:53 - src.data.dataset_processor - INFO - Option expansion statistics for ds:
2025-12-07 18:04:53 - src.data.dataset_processor - INFO -   Instances expanded (2→4 options): 10000
2025-12-07 18:04:53 - src.data.dataset_processor - INFO -   Total options sampled: 20000
2025-12-07 18:04:53 - src.data.dataset_processor - INFO -   Duplicate options avoided: 0
2025-12-07 18:04:53 - src.data.dataset_processor - INFO -   Fallback options used: 0
2025-12-07 18:04:53 - src.data.data_splitter - INFO - Splitting ds dataset (calibration: 50%, test: 50%)
2025-12-07 18:04:53 - src.data.data_splitter - INFO - Split complete:
2025-12-07 18:04:53 - src.data.data_splitter - INFO -   Calibration: 4999 instances
2025-12-07 18:04:53 - src.data.data_splitter - INFO -   Test: 5001 instances
2025-12-07 18:04:53 - src.data.data_splitter - INFO - Answer distribution:
2025-12-07 18:04:53 - src.data.data_splitter - INFO -   Calibration: {'A': 1258, 'B': 1203, 'C': 1264, 'D': 1274}
2025-12-07 18:04:53 - src.data.data_splitter - INFO -   Test: {'A': 1258, 'B': 1204, 'C': 1265, 'D': 1274}
2025-12-07 18:04:53 - src.utils.gpu - INFO - [dataset_processing] Duration: 38926.52ms | GPU Memory: 8.1MB -> 8.1MB (delta +0.0MB)
2025-12-07 18:04:53 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationSelector
2025-12-07 18:04:53 - src.prompting.demonstration_manager - INFO -   Strategy: random
2025-12-07 18:04:53 - src.prompting.demonstration_manager - INFO -   Num demonstrations: 5
2025-12-07 18:04:53 - src.prompting.demonstration_manager - INFO - Initialized DemonstrationManager
2025-12-07 18:04:53 - src.prompting.demonstration_manager - INFO - Selecting 1 demonstrations using 'random' strategy
2025-12-07 18:04:53 - src.prompting.demonstration_manager - INFO - Selected and cached 1 demonstrations for ds
2025-12-07 18:04:53 - __main__ - INFO - Loading model: tinyllama-1.1b (float32)
2025-12-07 18:04:53 - src.models.model_loader - INFO - Loading model: tinyllama-1.1b_float32 (TinyLlama/TinyLlama-1.1B-Chat-v1.0)
2025-12-07 18:04:53 - src.models.model_loader - INFO - Loading tokenizer from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 18:04:53 - src.models.model_loader - INFO - Tokenizer loaded successfully
2025-12-07 18:04:53 - src.models.model_loader - INFO -   Vocab size: 32000
2025-12-07 18:04:53 - src.models.model_loader - INFO -   Padding side: left
2025-12-07 18:04:53 - src.models.model_loader - INFO -   PAD token: </s> (ID: 2)
2025-12-07 18:04:53 - src.models.model_loader - INFO - Loading model from TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-12-07 18:04:53 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-07 18:04:56 - src.models.model_loader - INFO - Model loaded successfully
2025-12-07 18:04:56 - src.models.model_loader - INFO -   GPU Memory: 4.11GB allocated, 4.17GB reserved
2025-12-07 18:04:56 - src.utils.gpu - INFO - [model_loading] Duration: 3272.08ms | GPU Memory: 8.1MB -> 4204.5MB (delta +4196.4MB)
2025-12-07 18:04:56 - src.utils.gpu - INFO - [after_model_load_tinyllama-1.1b] GPU State: Allocated: 4204.5MB | Reserved: 4266.0MB | Free: 76948.3MB | Utilization: 100.0%
2025-12-07 18:04:56 - src.utils.gpu - INFO - Optimal batch size for 1.1B model (float32): 39
  Available memory: 73.70GB
  Model memory: 4.40GB
  Memory per batch item: 1.760GB
2025-12-07 18:04:56 - __main__ - INFO - Using batch size: 39
2025-12-07 18:04:56 - __main__ - INFO -   Strategy: base
2025-12-07 18:04:56 - src.prompting.prompt_builder - INFO - Initialized PromptBuilder for task: ds
2025-12-07 18:04:56 - src.prompting.prompt_builder - INFO -   Available strategies: ['base', 'shared_instruction', 'task_specific']
2025-12-07 18:04:56 - src.prompting.prompt_builder - INFO - Building 10000 prompts using 'base' strategy with 1 demonstrations
2025-12-07 18:04:56 - src.models.inference_engine - INFO - Initialized InferenceEngine for tinyllama-1.1b_float32
2025-12-07 18:04:56 - src.models.inference_engine - INFO -   Device: cuda:0
2025-12-07 18:04:56 - src.models.inference_engine - INFO -   Batch size: 39
2025-12-07 18:04:56 - src.models.inference_engine - INFO -   Option tokens: {'A': 319, 'B': 350, 'C': 315, 'D': 360, 'E': 382, 'F': 383}
2025-12-07 18:13:39 - src.utils.gpu - INFO - [inference_calibration] Duration: 522867.65ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 18:22:55 - src.utils.gpu - INFO - [inference_test] Duration: 556304.31ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 18:22:55 - __main__ - INFO -     Inference: 1079.17s for 10000 samples (9.27 samples/sec)
2025-12-07 18:22:55 - src.models.probability_extractor - INFO - Initialized ProbabilityExtractor
2025-12-07 18:22:55 - src.models.probability_extractor - INFO -   Temperature: 1.0
2025-12-07 18:22:55 - src.models.probability_extractor - INFO -   Calibration method: None
2025-12-07 18:22:56 - src.utils.gpu - INFO - [probability_extraction] Duration: 460.93ms | GPU Memory: 4204.5MB -> 4204.5MB (delta +0.0MB)
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Initialized LACScorer
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 18:22:56 - src.conformal.scorers - INFO - Initialized LAC (Least Ambiguous set-valued Classifiers) scorer
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Methods: ['lac']
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Calibrating LAC...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Calibrating with 4999 samples...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Threshold: 0.9398
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Score range: [0.0031, 1.0000]
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using LAC...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Generating prediction sets for 5001 test instances...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Average set size: 4.37
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Coverage rate: 89.80%
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: False
2025-12-07 18:22:56 - src.conformal.conformal_base - WARNING - ✗ Coverage guarantee NOT met: 89.80% < 90.00%
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - WARNING - LAC does not meet coverage guarantee: 89.80% < 90.00%
2025-12-07 18:22:56 - __main__ - INFO -     LAC: Acc=22.62%, CR=89.80%, SS=4.37
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Initialized APSScorer
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Alpha: 0.1
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Target coverage: 90.0%
2025-12-07 18:22:56 - src.conformal.scorers - INFO - Initialized APS (Adaptive Prediction Sets) scorer
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Initialized PredictionSetGenerator
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Methods: ['aps']
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Alpha: 0.1
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Aggregation: separate
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Calibrating 1 conformal predictors...
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO -   Calibrating APS...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Calibrating with 4999 samples...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Calibration complete
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Threshold: 0.9786
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Score range: [0.1955, 1.0000]
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Calibration complete
2025-12-07 18:22:56 - src.conformal.prediction_set_generator - INFO - Generating prediction sets using APS...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Generating prediction sets for 5001 test instances...
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - Prediction complete
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Average set size: 5.26
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Coverage rate: 97.22%
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO -   Meets coverage guarantee: True
2025-12-07 18:22:56 - src.conformal.conformal_base - INFO - [PASS] Coverage guarantee met: 97.22% >= 90.00%
2025-12-07 18:22:56 - __main__ - INFO -     APS: Acc=22.62%, CR=97.22%, SS=5.26
2025-12-07 18:23:05 - src.models.model_loader - INFO - Unloaded model: tinyllama-1.1b_float32
2025-12-07 18:23:05 - __main__ - INFO - Checkpoint saved after completing: tinyllama-1.1b | ds | float32
2025-12-07 18:23:05 - src.visualization.result_visualizer - INFO - Generating all visualizations...
2025-12-07 18:23:06 - src.visualization.result_visualizer - INFO - Saved heatmap to outputs/results/figures/heatmap_accuracy.png
2025-12-07 18:23:06 - src.visualization.result_visualizer - INFO - Saved heatmap to outputs/results/figures/heatmap_coverage_rate.png
2025-12-07 18:23:07 - src.visualization.result_visualizer - INFO - Saved heatmap to outputs/results/figures/heatmap_avg_set_size.png
2025-12-07 18:23:09 - src.visualization.result_visualizer - INFO - Saved dashboard to outputs/results/figures/dashboard.png
2025-12-07 18:23:09 - src.visualization.result_visualizer - INFO - Saved bar chart to outputs/results/figures/bar_comparison_accuracy.png
2025-12-07 18:23:10 - src.visualization.result_visualizer - INFO - Saved bar chart to outputs/results/figures/bar_comparison_avg_set_size.png
2025-12-07 18:23:10 - src.visualization.result_visualizer - INFO - Saved radar chart to outputs/results/figures/radar_chart.png
2025-12-07 18:23:11 - src.visualization.result_visualizer - INFO - Saved uncertainty analysis to outputs/results/figures/uncertainty_analysis.png
2025-12-07 18:23:11 - src.visualization.result_visualizer - INFO - Saved summary table to outputs/results/figures/results_summary.md
2025-12-07 18:23:11 - src.visualization.result_visualizer - INFO - Saved summary table to outputs/results/figures/results_summary_lac.md
2025-12-07 18:23:11 - src.visualization.result_visualizer - INFO - Saved summary table to outputs/results/figures/results_summary_aps.md
2025-12-07 18:23:11 - src.visualization.result_visualizer - INFO - All visualizations saved to outputs/results/figures
2025-12-07 18:23:11 - __main__ - INFO - Visualizations saved to: outputs/results/figures
2025-12-07 18:23:12 - src.utils.gpu - INFO - Stopped GPU monitoring. Collected 1237 snapshots.
2025-12-07 18:23:12 - src.utils.gpu - INFO - Saved GPU profiling report to outputs/results/gpu_profile_20251207_172657.json
2025-12-07 18:23:12 - __main__ - INFO - GPU profiling report saved to: outputs/results/gpu_profile_20251207_172657.json
2025-12-07 18:23:12 - __main__ - INFO - 
================================================================================
2025-12-07 18:23:12 - __main__ - INFO - BENCHMARK COMPLETE
2025-12-07 18:23:12 - __main__ - INFO - ================================================================================
2025-12-07 18:23:12 - __main__ - INFO - Total time: 55.79 minutes
2025-12-07 18:23:12 - __main__ - INFO - Results saved to: outputs/results
2025-12-07 18:23:12 - __main__ - INFO - Benchmark completed successfully
2025-12-07 18:23:12 - __main__ - INFO - Total runs: 8
2025-12-07 18:23:12 - __main__ - INFO - Overall accuracy: 21.69%
2025-12-07 18:23:12 - __main__ - INFO - Overall coverage: 94.31%
2025-12-07 18:23:12 - __main__ - INFO - Log file saved to: outputs/results/logs/benchmark_20251207_172657.log
